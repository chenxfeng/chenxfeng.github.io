[{"title":"分布式系统的容错技术(下)","slug":"parellel_and_distributed_computing/distributed_compute6","date":"2017-06-12T16:00:00.000Z","updated":"2017-06-13T11:46:20.000Z","comments":true,"path":"2017/06/13/parellel_and_distributed_computing/distributed_compute6/","link":"","permalink":"https://chenfeng.github.io/2017/06/13/parellel_and_distributed_computing/distributed_compute6/","excerpt":"(并行与分布式计算十) 故障模型和拜占庭故障的概念故障模型 初始死进程: 如果在局部算法中没执行过一步，则称进程为初始死进程 损毁模型(crash model): 如果进程正确地执行局部算法到某一时刻，此后并不进一步执行，则称它是损毁的 Byzantine行为(Byzantine behavior): 如果进程执行了与局部算法不一致的任意步，则称进程是Byzantine的。尤其是Byzantine进发送的消息可能包含任意内容","text":"(并行与分布式计算十) 故障模型和拜占庭故障的概念故障模型 初始死进程: 如果在局部算法中没执行过一步，则称进程为初始死进程 损毁模型(crash model): 如果进程正确地执行局部算法到某一时刻，此后并不进一步执行，则称它是损毁的 Byzantine行为(Byzantine behavior): 如果进程执行了与局部算法不一致的任意步，则称进程是Byzantine的。尤其是Byzantine进发送的消息可能包含任意内容 健壮算法提出的正确性要求总是指正确进程的局部状态(或者输出)。初始死进程从不会产生输出，且它的状态总是等于它的初始状态。如果损毁进程有输出，则它的输出是正确的，因为到损毁发生时，进程的行为是正确的。一个Byzantine进程的局部状态或者输出可以使任意的，任何算法都不满足Byzantine进程的非平凡性要求 故障模型的层次 可将错误模型分为三个层次 初始死进程课看作损毁进程的特例 损毁出现在进程的第一个事件之前 损毁进程可看作Byzantine进程的特例 对Byzantine进程假设的任意行为包括根本不执行任何一步 容忍损毁要比容忍初始死进程要困难，容忍Byzantine进程更困难 由于规定不同，健壮Byzantine算法也是健壮损毁算法，健壮损毁算法也是健壮初始死进程算法 健壮初始死进程算法的不可能性蕴含着健壮损毁算法的不可能性，而健壮损毁算法的不可能性蕴含着健壮Byzantine算法的不可能性。 拜占庭故障的恢复 进程组的内部结构： 平面结构：所有的进程是平等的，没有任何一个进程处于领导地位，任何决定都是共同做出的。 层次结构：在最简单的层次结构的进程组中，一个进程是协调者，其他所有的进程为工作者。无论是进程组外的一个顾客，还是进程组中的一个工作者向进程组发出一个工作请求，由协调者决定哪一个工作者最适合这项工作，并且将此工作请求转交给它。 进程组管理：对于进程组通信来说，需要一定的办法进行进程组的创建和删除，同时还要允许进程能加入到一个进程组中去以及允许一个进程离开一个进程组。 集中式管理：设置一个进程组服务员，所有的服务请求都发送给进程组服务员。进程组服务员使用一个数据库来保存所有进程组的信息和一个进程组中所有成员的有关信息。 分布式管理：另外一个进程组管理的办法是采用分布式的方式管理进程组。例如当一个组外的进程要加入到这个进程组时，它向这个进程组中的所有成员发送一个报文，申明自己要加入到这个进程组。 利用进程组屏蔽错误：进程组是构造容错系统问题的一部分。特别是，如果用相同的进程来构成一个进程组，那么就能够屏蔽进程组中一个或多个出错的进程。也就是说，我们可以用多个相同的进程构造一个进程组，用这个容错的进程组取代相对脆弱的单个进程。 利用进程组进行容错需要多少个进程副本： 故障—停止型故障：如果进程组中有k+1个进程，那么就足以提供k故障容错。 拜占庭式故障：那么为了取得k故障容错，那么至少需要2k+1个进程。 利用进程副本实现的分布式容错: 对于本质上不是分布式却要求高可靠性的计算机应用设计，部分故障性质使得利用分布式(“复制的”)体系结构称为有吸引力的选择。航天飞机的主计算机系统就是一个例子。Spector和Gifford[SG84]描述了它的研制。飞机主要由不需定制的微处理器控制，在设计中主要关注的是它在航行过程中处理器发生故障的可能性。最终控制系统由4个相同处理器组成。 每个处理器只进行同样的计算，激励者号对结果进行投票，即使一个处理器发生故障，也能完全控制系统。(激励者号的物理实现表明，即使第二个处理器后来发生故障，系统也能继续运行。)尽管复制是增加可靠性的有吸引力的一种选择，但是需要协调一群(不可靠)的处理器的算法设计远非那么简单。 容错系统中的一致性算法简介 分布式一致算法基本目标：是使得对于某个问题来说，所有非出错的进程能够达成一致，并且能够在有限的步骤内达成一致。 分布式一致算法的正确性条件： (1) 一致性。所有正确的进程取得一致的结果，而且是最后的结果； (2) 合法性。所有进程同意的结果必须来自某个正确的进程的输入； (3) 有限性。每个进程在有限的步骤内取得一致的结果。 交互一致性：系统中的每个非出错进程都使用来自进程Pi的同样的值来进行决策。这样，一般的一致性问题就变为系统中的进程都同意一个特殊的进程(比如P0)的值。确切地说： 所有非出错进程都使用进程P0的同样的值v0。 如果发送进程P0是非出错的，那么所有非出错进程都使用P0发送的值。 结论：在有k个出错节点的情况下，只有进程的总数至少为3k+1时才能获得一致。 LAMPORT交互一致性算法IC 该算法是一个递归算法，存在多个递归轮次。 算法IC(m)，m&lt;k，开始时m=0，S={}： 发送者将它的值和发送者列表S发送给其他的进程，共(n-1-m)个； 设v_i是进程P_i从发送者接收到的值或者是如果没有收到值时使用的缺省值。在IC(m+1≠k)时进程P_i作为发送者，将结果v_i和发送者列表S∪{P_i}发送给其他不在发送者列表中的n-2-m个进程。如果m+1=k，则调用IC(k)； 对每个进程P_i，设v_j是进程P_j接收到的值(但是由P_j转发给P_i)。节点使用值majority(v_j)，$j \\in S$； 算法IC(k)： 发送者将它的值发送给其他n-k-1个进程； 每个进程使用从接收者收到的值，或者，如果它没有收到任何值，就使用缺省值。 结论：上述算法中，被交换的报文总数为(n-1)(n-2)…(n-k-1)，其复杂度为O(n^k)，k可以是(n-1)/3。 实例：具有7个进程的例子，P_i，0≤i≤6。假定k=2，即最多有2个故障，n=7。设P_0是初始发送者，发送值为1。不妨设P_5和P_6是出错进程，它向其他进程发送不确定的值。在这个例子中共需要k+1=3轮信息交换： P_0将{V_0,S}={1,{P_0}}发送给进程P_1，P_2，…，P_6 P_1至P_6中每个进程都接收到报文{1,{P_0}} ，它们将所收到的报文转发给除了开始的发送者和它本身之外的所有其他的进程。例如P_1向P_2至P_6发送报文{1,{P_0,P_1}}。它分别从P_2至P_6处接收到报文{1,{P_0,P_2}}、{1,{P_0,P_3}}、{1,{P_0,P_4}}、{d,{P_0,P_5}}、{d,{P_0,P_6}} 在第三轮中，P_1将报文{1,{P_0,P_2}}以{1,{P_0,P_2,P_1}}的形式分别发送给进程P_3、P_4、P_5、P_6，将报文{1,{P_0,P_3}}以{1,{P_0,P_3,P_1}}的形式分别发送给进程P_2、P_4、P_5、P_6，将报文{1,{P_0,P_4}}以{1,{P_0,P_4,P_1}}的形式分别发送给进程P_2、P_3、P_5、P_6，将报文{d,{P_0,P_5}}以{d,{P_0,P_5,P_1}}的形式分别发送给进程P_2、P_3、P_4、P_6，将报文{d,{P_0,P_6}}以{d,{P_0,P_6,P_1}}的形式分别发送给进程P_2、P_3、P_4、P_5。第三轮递归结束，返回第二轮 进程P1收到报文{1,{P_0,P_2,P_3}}、{1,{P_0,P_2,P_4}}、{d,{P_0,P_2,P_5}}、{d,{P_0,P_2,P_6}}，连同在第二轮中收到的报文{1,{P_0,P_2}}，将这5个报文中的值执行majority(1,1,d,d,1)=1，得到的这个新值1作为报文{1,{P_0,P_2}}的新值，记为新报文{1,{P_0,P_2}}’。同样的道理，得到新报文{1,{P_0,P_3}}’、{1,{P_0,P_4}}’、{1,{P_0,P_5}}’、{1,{P_0,P_6}}’。第二轮递归结束，返回第1轮 P1对6个报文{1,{P_0}}、{1,{P_0,P_2}}’、{1,{P_0,P_3}}’、{1,{P_0,P_4}}’、{1,{P_0,P_5}}’、{1,{P_0,P_6}}’ 中的值执行majority(1,1,1,1,1,1)=1，这个新值是P1所确信的最终值。 可以通过对每个发送者都重复同样的协议将交互一致性扩展到多个发送者的情况。 扩展的方法：在第k轮收到的值将被发送到所有的其他节点，而不仅仅是那些没有被发送过的节点。 实例：假定有4位将军，其中有一个叛徒。将军之间相互通报自己的人数，忠诚的将军说实话，叛徒恶意地将不同的值通报给其他将军。不失一般性，设将军P1是叛徒，它分别向其他3位将军谎报自己军队的人数是x、y、z，将军P2向所有的将军通报自己的人数是4000，将军P3向所有的将军通报自己的人数是5000，将军P4向所有的将军通报自己的人数是6000。 分析： P_i要对每个P_j的值做判定 判定的方法是根据其它进程的内一轮的判定来取多数值（majority） P_i对于每个P_j来做的判定，如果系统中存在k个错误，则在IC算法的最内轮次至少需要2k+1个进程的投票才能实现可靠的判定（因为有k个投票可能是错的）","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"分布式系统的容错技术(上)","slug":"parellel_and_distributed_computing/distributed_compute5","date":"2017-06-05T16:00:00.000Z","updated":"2017-06-06T16:40:54.000Z","comments":true,"path":"2017/06/06/parellel_and_distributed_computing/distributed_compute5/","link":"","permalink":"https://chenfeng.github.io/2017/06/06/parellel_and_distributed_computing/distributed_compute5/","excerpt":"(并行与分布式计算十三) 分布式系统容错的基本概念 可用性：可用性反映的是系统随时可被用户使用的特性。 可靠性：可靠性指的是在错误存在的情况下，系统持续服务的能力。 安全性：安全性指的是在系统出现暂时错误的情况下，不出现灾难性后果的能力。 可维护性：可维护性指的是系统一旦出现故障，系统易于修复的能力。 保密性：保密性要求系统资源不被非法用户访问。 按错误的时间特性来看，错误可分为：暂时性的(transient)、间歇性的(intermittent)和永久性的(permanent)。","text":"(并行与分布式计算十三) 分布式系统容错的基本概念 可用性：可用性反映的是系统随时可被用户使用的特性。 可靠性：可靠性指的是在错误存在的情况下，系统持续服务的能力。 安全性：安全性指的是在系统出现暂时错误的情况下，不出现灾难性后果的能力。 可维护性：可维护性指的是系统一旦出现故障，系统易于修复的能力。 保密性：保密性要求系统资源不被非法用户访问。 按错误的时间特性来看，错误可分为：暂时性的(transient)、间歇性的(intermittent)和永久性的(permanent)。 基本的故障模型 容错是建立在冗余的基础上的，下面是四种冗余类型： (1) 硬件冗余。附加额外的处理器、I/O设备等。 (2) 软件冗余。附加软件模块的额外版本等。 (3) 信息冗余。如使用了额外位数的错误检测代码等。 (4) 时间冗余。如用来完成系统功能的额外时间。 有些研究者将冗余分为三类，即物理冗余、信息冗余和时间冗余。物理冗余可以用硬件冗余的方式或软件冗余的方式来实现，因为硬件和软件在逻辑上是等同的。 故障的基本处理方法： (1) 主动复制。所有的复制模块协同进行，并且它们的状态紧密同步。 (2) 被动复制。只有一个模块处于动态，其他模块的交互状态由这一模块的检查点定期更新。 (3) 半主动复制。是主动复制和被动复制的混合方法。此种方法所需的恢复开销相对较低。 失效的检测可分为外部检测和内部检测两类： 外部检测是指将检测节点失效的职责赋予被检测节点的外部附件。 内部检测将节点的失效检测机制置于该节点内部，通常检测部件被假定为一个可以完全信赖的“硬核”。 容错系统的基本构件坚固存储器： 坚固存储器是对一个可以经受系统失效的特定存储器的逻辑抽象，也就是说，坚固存储器里的内容不会被一个失效所毁坏。 坚固存储器的实现方法： 磁盘镜像：坚固存储器可以用一对普通磁盘来实现。坚固存储器中的每一个块由两个独立的磁盘块组成，分别位于不同的驱动器上，使得它们同时由于硬件故障受到损坏的机会最小。 RAID：另一种实现坚固存储器的方法是使用廉价磁盘冗余阵列(RAID)。RAID是通过运用位交错技术将数据分布到多个磁盘中，从而提供高I/O性能。可以用一个或几个磁盘来检测或屏蔽错误，RAID与传统磁盘相比有显著的优点，并可承受多个失效。 故障—停止处理器： 当一个处理器失效，最可能的是它不进行任何不正确的操作，并且简单地停止运行，这样的处理器被称为故障—停止处理器，一个故障—停止处理器由多个处理器组成。 失效的效果：当出现一个故障时，故障—停止处理器会有以下效果： (a)处理器停止运行； (b)易失性存储器的内容丢失，而坚固存储器不受影响； (c)任何其他处理器均可以检测到故障—停止处理器的失效状态。 故障—停止处理器的实现： 现有一个可靠的坚固存储器、一个可靠的存储处理器(控制存储媒介的处理器)以及k+1个处理器，将它们转变成故障—停止处理器的方法如下： k+1个处理器中的每一个都运行同样的程序并通过存储处理器访问同一个坚固存储器。 如果任何一个请求是不同的，或者任何一个请求没有在指定的期间到达，则意味着检测到一个失效事件，因而应该丢弃所有请求。 因为系统表现为一个故障—停止处理器，这一方法产生一个k—故障—停止处理器，除非系统中k+1个或更多的部件失效。 原子操作 一个原子操作就是由硬件独立执行的一系列动作。也就是说，每一个动作或者被完全彻底地执行，或者所有的动作根本没有执行，系统的状态保持不变。 原子操作中的每一个动作都是孤立的，当执行这一动作时，在进程中感觉不到外界活动的存在，也意识不到外界状态的变化。与此相似，任何外界的进程均感觉不到一个孤立的原子操作的内在状态的变化。这就是所谓的原子操作的“全有或全无”的性质，即一个原子操作要么全部完成，要么在执行过程中出现错误的时候相当于根本没有执行。 原子操作失效时，可以通过简单地重做来恢复。 节点故障的处理向前式恢复和向后式恢复： 在向前式恢复中，假定可以完全准确地得到系统中的故障和损失的性质，这样就有可能去掉这些故障从而使得系统继续向前执行。 向后式恢复适用于系统的故障无法预知和去掉的情况，在这种情况下，要定时地存储系统的状态，这样当失效导致系统处于不一致的状态时，系统可以恢复到从前没有发生故障的状态，在此状态下重新执行。 向后式恢复： 检查点：在向后式恢复中进程被恢复到一个先前的正确的状态。进程执行中的一些点被称为“检查点”(checkpoint)，在以后发生错误的情况下，进程可以被恢复到这些点。在检查点的实现过程中，需要考虑两个主要问题：检查点的存储和检查点的更新。 有两种方法来保存检查点： (1)每一个检查点被组播到每一个备份模块； (2)每个检查点被存储在它的本地坚固存储器中。当进程正确地从一个旧的检查点运行到一个新的检查点时，旧的检查点就要被新的检查点替换。当进程执行到两个检查点之间时发生错误，那么进程应该卷回到旧的检查点处重新执行。 检查点的原子更新：当使用新的检查点替换旧的检查点的过程中，系统也会发生失效。这可以通过检查点的原子更新过程来解决，也就是说，在检查点的更新中，要么旧的检查点被新的检查点替换，要么旧的检查点被完整地保留。 检查点原子更新的实现： 假设库A和库B现在保存的检查点是C1，现在要用检查点C2取代库A和库B的内容。在取代前，假设Ta1=Ta2=Tb1=Tb2=1，检查点的更新过程如下： (1) 为了更新库A，先置Ta1=2； (2) 将库A的内容用检查点C2取代； (3) 库A更新完毕，置Ta2=2； (4) 为了更新库B，先置Tb1=2； (5) 将库B的内容用检查点C2取代； (6) 库B更新完毕，置Tb2=2； 识别在检查点更新过程中发生的失效 ： 基于影像页面技术的恢复方案：在基于影像页面技术的方案中，当进程需要修改一个页面时，系统复制该页并保留在坚固存储器中。系统中每个页面都有两个拷贝，当进程在执行的过程中，只有其中的一个拷贝被进程修改，另一个拷贝就作为影像页面。如果进程失效，则丢弃被修改的拷贝，系统根据影像页面进行恢复。如果进程成功运行，则每一份影像页面被相应的修改后的页面替换。 向前式恢复： 一个进程或任务的初始拷贝由不同的处理器来运行。 这些版本的结果在检查点进行表决或比较，如果表决结果是成功的，则可以获得一个储存在坚固存储器中的正确结果。 如果表决结果是失败的，对以前的任务进行一次回卷执行。也就是说，在后备处理器上再运行以前的任务，目的是获得正确的结果。 尽管在所有版本都失效(所有结果都不正确)或者表决也不能获得正确结果的情况下，回卷运行是不可避免的，但由于利用了现存的正确结果而不必从头重新开始，还是节省了回卷时间。 向前式恢复方案的实例：Ii，Ii+1和Ii+2是检查点间隔。两进程X和Y均运行一个进程的同一个版本。在每个检查点之前，需要对结果进行比较并确认是否正确。S是一个后备处理器，对两个间隔Ii和Ii+1进行验证。有以下四种可能： (1) 没有并发重试。如果X和Y都在间隔Ii正确运行，那么X和Y在间隔Ii所得的结果是相同的，S不进行并发重试。 (2) 有非回卷的并发重试。在Ii中出现了错误，但在两个合法的检查点间隔Ii+1和Ii+2中间没有错误。 如果我们用(Xi,Yi,Si)代表在间隔Ii之中X、Y和S的状态，并且用0代表错误，1代表正确，d代表没有关系(也就是说，或者错误或者正常)。(Xi,Yi,Si)就有两种情况：(1,0,1)和(0,1,1)，无论哪种情况，系统都可以判断哪个进程是正确的，所以不用回卷。 (3) 在一次并发重试的间隔后进行回卷。这种情况对应于在Ii中有两个进程(X、Y和S中的两个)有错误的情况。 如果我们用(Xi,Yi,Si)代表在间隔Ii之中X、Y和S的状态，那我们就得到三种情况：(1,0,0)，(0,1,0)，(0,0,d)。这三种情况是在一次并发重试的间隔后进行回卷。系统卷回到Ii的开始处。 (4) 在并发重试的两次间隔之后回卷。该情况下在检查点间隔Ii+1处出现了一个额外的错误。 如果我们用(Xi,Yi,Si,Xi+1,Yi+1,Si+1)代表在间隔Ii和Ii+1中X、Y和S的状态，这种情况对应于以下描述的四种情形：(1,0,1,d,d,0)，(1,0,1,0,d,d)，(0,1,1,d,d,0)，(0,1,1,d,0,d)。可以确定间隔Ii中哪个进程是正确的，但是不能确定间隔Ii+1中哪个进程是正确的。系统卷回到间隔Ii+1的起始处。 分布式检查点算法一致性检查点 全局状态：一种全局状态的定义是一系列局部状态的集合，这里的局部状态就是一个进程的检查点，每个局部进程有一个局部状态。 局部检查点可能组成如下两种不一致的全局状态： 丢失报文。进程Pi的检查点状态显示它给进程Pj发送了报文m，但是进程Pj并没有关于该报文的纪录。 孤儿报文。进程Pj的检查点状态显示它收到了一个来自进程Pi的报文m，但是进程Pi的状态显示它没有向进程Pj发送过报文m。 不一致全局状态实例： 多米诺效应(domino effect) 为了解决孤儿报文的问题，进程Pj回卷到上一个检查点时，要清除对孤儿报文的纪录。然而，这样一来有可能出现这样一种情况：在最近的检查点和上一个检查点之间，Pj向Pi发送了一个报文n，假定Pi在当前检查点之前收到了报文n，现在这个报文n成了孤儿报文。这样，Pi需要进一步回卷。这种由于一个进程的回卷导致另外一个或多个进程的回卷的效应叫做多米诺效应。 一个强一致(strongly consistent)的检查点集合是由一系列的没有孤儿报文和没有丢失报文的局部检查点组成。 一个一致的检查点集合是由一系列没有孤儿报文的局部检查点组成。 显然一个强一致的检查点集合包括一系列局部检查点，在这些检查点之间，进程之间没有报文传送。如果每个进程都在发送一个报文之后生成一个检查点，那么最近的检查点集合将永远是一致的。 恢复线和切割线：当一个进程或系统失效的时候要求利用这些局部状态重新构造一个全局一致的状态。一个分布式快照对应一个全局一致的状态，这个分布式快照可以作为一个恢复线(recovery line)用于恢复。一个恢复线对应于最近的一个一致性切割线。 异步检查点 异步检查点算法中程序中检查点状态的保存过程较为简单，程序中各进程周期性地相互独立地保存自己的运行状态，程序各进程之间不需要相互协商。 在恢复过程中，各进程之间则需要相互协商通过复杂的回卷算法各自回卷到合适的检查点时刻以使整个程序的各个进程恢复到最近的一个一致的全局状态。 一致检查点的检测方法： 比较发送的和接收的报文数量来检测孤儿报文的存在。如果接收到的报文数目和任何发送报文的进程发送的报文的数目是一致的，那么就可以认为找到了一个局部检查点的一致集合。 使用间隔依赖图来进行检测。如果每个进程i的向量时钟是LCi，一个检查点集合是一致的，当且仅当不存在i和j满足LCi＜LCj。 异步检查点算法的优缺点： 优点是允许分布式程序的各个进程拥有最大程度的自治性，因而算法的延迟较小。 缺点之一是由于每个进程需要保存若干时刻的检查点信息，空间开销较大； 缺点之二是在恢复过程中可能会重复回卷，甚至出现多米诺效应，使程序一直回卷到初始状态。 另一个缺点是需要大量存储空间 同步检查点 在同步检查点算法中，各相关的进程协调它们的局部检查点的建立行为，以保证所有的最近的检查点都是一致的。 在同步检查点中，只有最近的一致的检查点集合才需要被维护和保存。 由于使用同步检查点算法，各进程的局部检查点组成的集合是一个全局一致的状态，所以在恢复时各个进程只需要简单地从检查点处重新开始执行。 同步检查点算法的优点是每个进程只需保存最近时刻的检查点信息，空间开销较小，且在恢复的时候没有多米诺效应。 其缺点是，在建立检查点时，各进程间的同步使程序运行中止时间较长，且牺牲了分布式程序的自治性。 同步检查点算法 Sync-and-Stop(SNS)算法中有一个进程pc负责管理全局检查点建立过程。 各进程的检查点建立过程如下： pc向所有进程广播检查点开始报文Mb(第一次同步开始)； 任一个进程接收到报文Mb后停止运行，并在自己所发送的报文全部到达接收者后向pc进程发送报文Ms1； pc接收到所有进程发送的报文Ms1后，即意味着第一次同步结束。pc向各进程广播报文Mchk，第二次同步开始； 任一个进程接收到报文Mchk后，立即作局部检查点，检查点建立完成之后向pc发送报文Ms2； pc接收到所有进程发送的报文Ms2后，意味着第二次同步结束。pc向所有进程广播报文Me； 各进程接收到报文Me后，删除旧的检查点，仅保留新的检查点，然后继续执行。SNS算法的恢复过程十分简单，只需回卷到检查点处继续执行。 经过第一次同步之后，任何进程所发送的报文都已经被对应的接收进程接收到，任何进程之间不会存在孤儿报文，满足一致性的要求。 Chandy-Lamport(CL)算法： 机器mc与m1之间有通道直接相连，机器mc与m1之间可直接相互发送报文，机器mc与m1称为直接相连；机器mc与m2之间没有直接通道相连，机器mc与m2之间相互发送的报文要通过m1转发，机器mc与m2称为间接相连。 建立检查点的过程可由任一个进程pc发起，pc进程停止运行，并向与其所在机器直接相连的机器上的进程广播报文Mb，然后进程pc建立局部检查点； 进程p接收到报文Mb后，若进程p还未开始建立检查点，则进程p停止运行并立即向与其所在机器直接相连的机器上的进程广播报文Mb，然后进程p建立局部检查点； 进程p开始建立检查点后，若接收到其他进程发送的非检查点控制报文m，则保存报文m； 当进程p完成局部检查点的建立，并且接收到与其所在机器直接相连的机器上的所有进程发送的报文Mb后，进程p向pc进程发送报文Ms； 当进程pc接收到所有进程发送的报文Ms后，pc进程向所有进程发送报文Me，并删除本进程旧的检查点，进程pc继续执行； 其他进程p接收到报文Me后，删除本进程旧的检查点，继续执行。 在恢复过程中，CL算法在回卷到当前检查点重新执行的同时还必须重发过程(3)中保存的报文m。与SNS算法相比，CL算法减少了两次全局同步的开销。CL算法的缺点是其控制报文的数目与机器间的拓扑结构有关。 混合检查点 其基本思想是在一个较长的时间段中使用同步检查点，而在较短的时间段内使用异步检查点。 也就是说，在一个同步时间段里，会有若干个异步时间段。 因此，我们可以有一个可以控制的回卷，从而保证不会在建立检查点的过程中引入过多的开销。 例如：准同步检查点。这个方法允许每个进程异步地设置检查点，从而保证了进程的独立性。同时，对恢复线的扩展采用发起通信的检查点协调方法，从而可以限制恢复过程中回卷的传播。 报文日志 报文日志：为了减少回卷时撤销的计算工作量，所有接收的和发送的报文都可以记录下来。前者叫做接收者日志，后者叫做发送者日志。 当Pj的检查点被恢复到一个没有孤儿报文，而且所有要发送的报文都已经发送的一致状态的时候，可以用Pj的接收者日志减少回卷工作量，即只需要将Pj所收到的报文重新向Pj发送一遍即可。 如果进程Pj记录了报文m的接收者日志，那么Pi和Pj的当前检查点集合就可以看作是一致的。一旦由于Pj由于失效回卷到当前检查点重新执行的时候，报文m就可以通过Pj的接收者日志重新发送给进程Pj，不会引起进程Pi的任何回卷。 如果Pi在发送完报文m后失效，那么当进程Pi恢复到当前检查点后，它会根据发送者日志的纪录知道曾经发送过报文m，这样就没有必要再发送一次了。如果接收者Pj失效，而且没有接收者日志，它仍然可以根据从发送者日志中得到的报文正确恢复。 Alvisi和Marzullo的报文日志方案 报文格式：每个报文m包含有一个报文头用于存放重发这个报文和正确处理这个报文所必需的一些信息，例如，该报文的发送者和接收者，用于识别报文重复的序列号，另外还有一个传输号用于决定何时该报文需要传递给接收进程。 坚固的报文：如果一个报文不再会丢失，则称这个报文是坚固的，例如当一个报文已经被写入到坚固存储器中，就可以说这个报文是坚固的。坚固的报文可以重新发送给失效后重新恢复的进程。 进程集合DEP(m) 的组成：一个报文m对应于一个进程集合DEP(m) ，该集合包含了与报文m传输有关的所有进程。 DEP(m)包含了所有接收该报文m的进程； 如果另外一个报文m’和报文m有因果依赖性关系，并且m’是传递给进程Q的，那么DEP(m)集合中应该包含进程Q。 因果依赖性关系： 如果m’和m是由同一个进程发送的，并且m的发送先于m’的发送，则说m’和报文m的传输有因果依赖性关系。 同样地，如果m”和m’有因果依赖性关系，m’和m有因果依赖性关系，则说m”和m有因果依赖性关系。 进程集合COPY(m) 的组成：如果一个进程有报文m的一个拷贝，但是这个拷贝还没有写入到它的局部坚固存储器中的话，该进程就属于集合COPY(m)。当一个进程发送了报文m，它也属于集合COPY(m)。值得注意的是COPY(m)集合中所包含的进程是那些拥有报文m的拷贝，并且在出现失效的时候，能够重新传输报文m的进程。当COPY(m)中的所有进程都失效时，显然报文m就不能被重新传输。 孤儿进程：假设在一个分布式系统中，某个或某些进程失效了，Q是一个存活下来的进程。有一个报文m，如果进程Q是集合DEP(m)中的一个元素，而集合COPY(m)中的所有进程都失效了，那么Q就是一个孤儿进程。也就是说，当一个进程依赖于报文m，但是无法向该进程重发报文m，该进程就是一个孤儿进程。 避免孤儿进程的出现：需要确保当集合COPY(m)中的进程都失效的时候，DEP(m)中没有存活的进程。也就是说，DEP(m)中的进程也必须全部失效。这可以通过如下的强制方式得以实现，当一个进程成为DEP(m)中的一个成员的时候，我们强制它也成为COPY(m)的一个成员。也就是说，当一个进程依赖于报文m的传输的时候，它将保持报文m的一个副本。 悲观的日志协议：每一个非坚固的报文m，确保最多只有一个进程依赖于报文m。也就是说，对于每一个非坚定的报文m，悲观的日志协议确保该报文最多只传给了一个进程。值得注意的是，一旦一个非坚定的报文m传递给了进程P，P就成为集合COPY(m)的一个成员。 最坏的情况是在报文m写入到坚固存储器之前，进程P失效了。因为在悲观的日志协议下，在报文m写入到坚固存储器之前，不允许P发送任何报文，所以不会有其他进程依赖于报文m，也就不会有重发报文m的可能性。所以，使用悲观的日志协议避免了孤儿进程的问题。 乐观的日志协议：在乐观的日志协议下，实际的工作是在失效发生之后进行的。假定对某个报文m来说，如果集合COPY(m)中的每个进程都失效了，DEP(m)中的每个孤儿进程一直要回卷到以前的某个状态，在这个状态下，该进程不再是集合DEP(m)中的一个成员。很明显，乐观的日志协议需要保持追踪依赖性关系，从而使得它的实现变得复杂。","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"","slug":"algoDesign/dp","date":"2017-06-04T12:02:38.198Z","updated":"2017-06-03T02:09:16.000Z","comments":true,"path":"2017/06/04/algoDesign/dp/","link":"","permalink":"https://chenfeng.github.io/2017/06/04/algoDesign/dp/","excerpt":"动态规划题目[转载]整理自http://www.cppblog.com/menjitianya/archive/2015/10/23/212084.html 递推 [例题1]在一个3 X N的长方形方格中，铺满1X2的骨牌（骨牌个数不限制），给定N，求方案数（图一 -1-1为N=2的所有方案），所以N=2时方案数为3。 二维状态 状态转移方程 f[i][0] = f[i-2][0] + f[i-1][1] + f[i-2][2] f[i][1] = f[i-1][2] f[i][2] = f[i][0] + f[i-1][1] 边界条件 f[0][0] = f[1][1] = f[0][2] = 1","text":"动态规划题目[转载]整理自http://www.cppblog.com/menjitianya/archive/2015/10/23/212084.html 递推 [例题1]在一个3 X N的长方形方格中，铺满1X2的骨牌（骨牌个数不限制），给定N，求方案数（图一 -1-1为N=2的所有方案），所以N=2时方案数为3。 二维状态 状态转移方程 f[i][0] = f[i-2][0] + f[i-1][1] + f[i-2][2] f[i][1] = f[i-1][2] f[i][2] = f[i][0] + f[i-1][1] 边界条件 f[0][0] = f[1][1] = f[0][2] = 1 [例题2]对一个“01”串进行一次μ变换被定义为：将其中的”0”变成”10”，”1”变成”01”，初始串为”1”，求经过N(N &lt;= 1000)次μ变换后的串中有多少对”00” 要出现”00”，一定是”10”和”01”相邻产生的 设A = “10”, B = “01”，构造出的树形递推图如图所示，如果要出现”00”，一定是AB（”1001”） FA[i]为A经过i次μ变换后”00”的数量，FA[0] = 0; FB[i]为B经过i次μ变换后”00”的数量，FB[0] = 0 以A为根的树，它的左子树的最右端点一定是B，也就是说无论经过多少次变换，两棵子树的交界处都不可能产生AB，所以FA[i] = FB[i-1] + FA[i-1]（直接累加两棵子树的”00”的数量）；而以B为根的树，它的左子树的右端点一定是A，而右子树的左端点呈BABABA…交替排布，所以隔代产生一次AB，于是FB[i] = FA[i-1] + FB[i-1] + (i mod 2) 。最后要求的答案就是FB[N-1]，递推求解 记忆化搜索 [例题3]这个问题直接给出了一段求函数w(a, b, c)的伪代码：12345function w(a, b, c): if a &lt;=0 or b &lt;=0 or c &lt;=0, then returns:1 if a &gt;20or b &gt;20or c &gt;20, then returns: w(20,20,20) if a &lt; b and b &lt; c, then returns: w(a, b, c-1)+ w(a, b-1, c-1)- w(a, b-1, c) otherwise it returns: w(a-1, b, c)+ w(a-1, b-1, c)+ w(a-1, b, c-1) 要求给定a, b, c，求w(a, b, c)的值 这个函数的时间复杂度是指数级的（尽管这个三元组的最大元素只有20，这是个陷阱）。对于任意一个三元组(a, b, c)，w(a, b, c)可能被计算多次，而对于固定的(a, b, c)，w(a, b, c)其实是个固定的值，没必要多次计算，所以只要将计算过的值保存在f[a][b][c]中，整个计算就只有一次了，总的时间复杂度就是O(n^3)，这个问题的n只有20 状态和状态转移 最优化原理和最优子结构 【例题4】给定一个长度为n(1 &lt;= n &lt;= 1000)的整数序列a[i]，求它的一个子序列(子序列即在原序列任意位置删除0或多个元素后的序列)，满足如下条件： 该序列单调递增； 在所有满足条件1的序列中长度是最长的； 最长单调子序列 枚举（DFS），即枚举a[i]这个元素取或不取，所有取的元素组成一个合法的子序列，枚举的时候需要满足单调递增这个限制，那么对于一个n个元素的序列，最坏时间复杂度自然就是O(2^n) 假设第i个数取的情况下已经搜索出的最大长度记录在数组d中，即用d[i]表示当前搜索到的以a[i]结尾的最长单调子序列的长度，那么如果下次搜索得到的序列长度小于等于d[i]，就不必往下搜索了（因为即便继续往后枚举，能够得到的解必定不会比之前更长）；反之，则需要更新d[i]的值 对于任意的i，d[i] 一定等于 d[j] + 1 ( j &lt; i )，而且还得满足 a[j] &lt; a[i] 状态转移方程： d[i] = max{ d[j] | j &lt; i &amp;&amp; a[j] &lt; a[i] } + 1 时间复杂度是O(n^2) 决策和无后效性： 一个状态演变到另一个状态，往往是通过“决策”来进行的。有了“决策”，就会有状态转移。而无后效性，就是一旦某个状态确定后，它之前的状态无法对它之后的状态产生“效应”（影响） [例题5]老王想在未来的n年内每年都持有电脑，m(y, z)表示第y年到第z年的电脑维护费用，其中y的范围为[1, n]，z的范围为[y, n]，c表示买一台新的电脑的固定费用。 给定矩阵m，固定费用c，求在未来n年都有电脑的最少花费 考虑第 i 年是否要换电脑，换和不换是不一样的决策，那么我们定义一个二元组(a, b)，其中 a &lt; b，它表示了第a年和第b年都要换电脑（第a年和第b年之间不再换电脑），如果假设我们到第a年为止换电脑的最优方案已经确定，那么第a年以前如何换电脑的一些列步骤变得不再重要，因为它并不会影响第b年的情况，这就是无后效性 令d[i]表示在第i年买了一台电脑的最小花费(由于这台电脑能用多久不确定，所以第i年的维护费用暂时不计在这里面)，如果上一次更换电脑的时间在第j年，那么第j年更换电脑到第i年之前的总开销就是c + m(j, i-1)，于是有状态转移方程： d[i] = min{ d[j] + m(j, i-1) | 1 &lt;= j &lt; i } + c 漏算了第i年到第n年的维护费用，所以最后问题的答案： ans = min{ d[i] + m(i, n) | 1 &lt;= i &lt; n } 可以假设第n+1年必须换电脑，并且第n+1年换电脑的费用为0，那么整个阶段的状态转移方程就是： d[i] = min{ d[j] + m(j, i-1) | 1 &lt;= j &lt; i } + w(i) 其中w(i) = (i==n+1)?0:c; d[n+1]就是需要求的最小费用 经典模型线性模型 线性模型的是动态规划中最常用的模型，上文讲到的最长单调子序列就是经典的线性模型，这里的线性指的是状态的排布是呈线性的 [例题6]在一个夜黑风高的晚上，有n（n &lt;= 50）个小朋友在桥的这边，现在他们需要过桥，但是由于桥很窄，每次只允许不大于两人通过，他们只有一个手电筒，所以每次过桥的两个人需要把手电筒带回来，i号小朋友过桥的时间为T[i]，两个人过桥的总时间为二者中时间长者。问所有小朋友过桥的总时间最短是多少 先将所有人按花费时间递增进行排序，假设前i个人过河花费的最少时间为opt[i] 考虑前i-1个人过河的情况，即河这边还有1个人，河那边有i-1个人，并且这时候手电筒肯定在对岸，所以 opt[i] = opt[i-1] + a[1] + a[i] (让花费时间最少的人把手电筒送过来，然后和第i个人一起过河) 如果河这边还有两个人，一个是第i号，另外一个无所谓，河那边有i-2个人，并且手电筒肯定在对岸，所以 opt[i] = opt[i-2] + a[1] + a[i] + 2*a[2] (让花费时间最少的人把电筒送过来，然后第i个人和另外一个人一起过河，由于花费时间最少的人在这边，所以下一次送手电筒过来的一定是花费次少的，送过来后花费最少的和花费次少的一起过河，解决问题) opt[i] = min{ opt[i-1] + a[1] + a[i] , opt[i-2] + a[1] + a[i] + 2*a[2] } 区间模型 区间模型的状态表示一般为d[i][j]，表示区间[i, j]上的最优解，然后通过状态转移计算出[i+1, j]或者[i, j+1]上的最优解，逐步扩大区间的范围，最终求得[1, len]的最优解 典型的区间模型，回文串拥有很明显的子结构特征，即当字符串X是一个回文串时，在X两边各添加一个字符’a’后，aXa仍然是一个回文串 用d[i][j]来表示A[i…j]这个子串变成回文串所需要添加的最少的字符数 对于A[i] == A[j]的情况，很明显有 d[i][j] = d[i+1][j-1] （这里需要明确一点，当i+1 &gt; j-1时也是有意义的，它代表的是空串，空串也是一个回文串，所以这种情况下d[i+1][j-1] = 0） 当A[i] != A[j]时，我们将它变成更小的子问题求解，我们有两种决策： 1、在A[j]后面添加一个字符A[i]； 2、在A[i]前面添加一个字符A[j]； 根据两种决策列出状态转移方程为： d[i][j] = min{ d[i+1][j], d[i][j-1] } + 1;(每次状态转移，区间长度增加1) 空间复杂度O(n^2)，时间复杂度O(n^2) 背包模型 0/1背包 有N种物品（每种物品1件）和一个容量为V的背包。放入第i种物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大。 f[i][v]表示前i种物品恰好放入一个容量为v的背包可以获得的最大价值 决策为第i个物品在前i-1个物品放置完毕后，是选择放还是不放，状态转移方程为： f[i][v] = max{ f[i-1][v], f[i-1][v - Ci] +Wi } 时间复杂度O(VN)，空间复杂度O(VN) （空间复杂度可利用滚动数组进行优化达到O(V)，下文会介绍滚动数组优化） 完全背包 有N种物品（每种物品无限件）和一个容量为V的背包。放入第i种物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大。 f[i][v]表示前i种物品恰好放入一个容量为v的背包可以获得的最大价值。 f[i][v] = max{ f[i-1][v - kCi] + kWi | 0 &lt;= k &lt;= v/Ci } (当k的取值为0,1时，这就是01背包的状态转移方程） 时间复杂度O( VNsum{V/Ci} )，空间复杂度在用滚动数组优化后可以达到O( V )。 进行优化后（此处省略500字），状态转移方程变成： f[i][v] = max{ f[i-1][v], f[i][v - Ci] +Wi }，时间复杂度降为O(VN)。 多重背包 有N种物品（每种物品Mi件）和一个容量为V的背包。放入第i种物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大。 f[i][v]表示前i种物品恰好放入一个容量为v的背包可以获得的最大价值。 f[i][v] = max{ f[i-1][v - kCi] + kWi | 0 &lt;= k &lt;= Mi } 时间复杂度O( Vsum(Mi) )，空间复杂度仍然可以用滚动数组优化后可以达到O(V)。 优化：采用二进制拆分物品，将Mi个物品拆分成容量为1、2、4、8、… 2^k、Mi-( 2^(k+1) - 1 ) 个对应价值为Wi、2Wi、4Wi、8Wi、…、2^kWi、（Mi-( 2^(k+1) - 1 )）Wi的物品，然后采用01背包求解。 这样做的时间复杂度降为O(Vsum(logMi)) [例题8]一群强盗想要抢劫银行，总共N(N &lt;= 100)个银行，第i个银行的资金为Bi亿，抢劫该银行被抓概率Pi，问在被抓概率小于p的情况下能够抢劫的最大资金是多少？ p表示的是强盗在抢银行时至少有一次被抓概率的上限，那么选择一些银行，并且计算抢劫这些银行都不被抓的的概率pc，则需要满足1 - pc &lt; p 这里的pc是所有选出来的银行的抢劫时不被抓概率（即1 - Pi）的乘积，于是我们用资金作为背包物品的容量，概率作为背包物品的价值，求01背包 状态转移方程为：f[j] = max{ f[j], f[j - pack[i].B] * (1-pack[i].p) } 最后得到的f[i]表示的是抢劫到i亿资金的最大不被抓概率。 令所有银行资金总和为V，那么从V-0进行枚举，第一个满足1 - f[i] &lt; p的i就是我们所要求的被抓概率小于p的最大资金。 状态压缩模型 [例题9]对于一条n(n &lt;= 11)个点的哈密尔顿路径C1C2…CN（经过每个点一次的路径）的值由三部分组成： 1、每个顶点的权值Vi的和 2、对于路径上相邻的任意两个顶点CiC{i+1}，累加权值乘积 Vi*V{i+1} 3、对于相邻的三个顶点CiC{i+1}C{i+2}，如果Ci和C{i+2}之间有边，那么累加权值三乘积 Vi*V{i+1}*V_{i+2} 求值最大的哈密尔顿路径的权值 和 这样的路径的个数。 枚举所有路径，判断找出值最大的，复杂度为O(n!)，不可行 由于点数较少，采用二进制表示状态，用d[i][j][k]表示某条哈密尔顿路径的最大权值，其中i是一个二进制整数，它的第t位为1表示t这个顶点在这条哈密尔顿路径上，为0表示不在路径上。j和k分别为路径的最后两个顶点 状态转移方程：d[i][j][k] = max{ d[i ^ (1&lt;&lt;k)][t][j] + w(t, j, k) | (i &amp; (1&lt;&lt;t)) != 0 } 几个位运算:i ^ (1&lt;","categories":[],"tags":[]},{"title":"","slug":"algoDesign/backpack","date":"2017-06-04T12:02:36.938Z","updated":"2017-06-03T03:06:18.000Z","comments":true,"path":"2017/06/04/algoDesign/backpack/","link":"","permalink":"https://chenfeng.github.io/2017/06/04/algoDesign/backpack/","excerpt":"背包[转载]整理自背包九讲 01背包问题 [题目]有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是C_i，得到的价值是W_i。求解将哪些物品装入背包可使价值总和最大","text":"背包[转载]整理自背包九讲 01背包问题 [题目]有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是C_i，得到的价值是W_i。求解将哪些物品装入背包可使价值总和最大 基本思路 最基础的背包问题，特点是：每种物品仅有一件，可以选择放或不放 子问题定义状态: F[i,v]表示前i件物品恰放入一个容量为v的背包可以获得的最大价值 其状态转移方程便是： $F[i,v]=max{F[i−1,v],F[i−1,v−C_i] + W_i}$ 将前i件物品放入容量为v的背包中”这个子问题, 若只考虑第i件物品的策略（放或不放），那么就可以转化为一个只和前i−1件物品相关的问题 如果不放第i件物品，那么问题就转化为“前i−1件物品放入容量为v的背包中”，价值为F[i−1,v] 如果放第i件物品，那么问题就转化为“前i−1件物品放入剩下的容量为v−C_i的背包中”，此时能获得的最大价值就是F[i−1,v−C_i]再加上通过放入第i件物品获得的价值W 伪代码如下： 1234F[0,0..V]=0for i=1 to N for v=C_i to V F[i,v] = max&#123;F[i−1,v], F[i−1,v−C_i] + W_i&#125; 优化空间复杂度 1234F[0..V]=0for i=1 to N for v=V to C_i F[v] = max&#123;F[v], F[v−C_i] + W_i&#125; 初始化的细节问题 “恰好装满背包”时的最优解 在初始化时除了F[0,0]为0，其它F[0,1..V]均设为−∞，这样就可以保证最终得到的F[V]是一种恰好装满背包的最优解 没有要求必须把背包装满 初始化时应该将F[0,0..V]全部设为0 初始化的F数组事实上就是在没有任何物品可以放入背包时的合法状态。如果要求背包恰好装满，那么此时只有容量为0的背包可以在什么也不装且价值为0的情况下被“恰好装满”，其它容量的背包均没有合法的解，属于未定义的状态，应该被赋值为-∞了。如果背包并非必须被装满，那么任何容量的背包都有一个合法解“什么都不装”，这个解的价值为0，所以初始时状态的值也就全部为0了 完全背包问题 [题目]有N种物品和一个容量为V的背包，每种物品都有无限件可用。放入第i种物品的耗费的空间是C_i，得到的价值是W_i。求解：将哪些物品装入背包，可使这些物品的耗费的空间总和不超过背包容量，且价值总和最大 基本思路 每种物品有无限件 从每种物品的角度考虑，与它相关的策略已并非取或不取两种，而是有取0件、取1件、取2件……直至取⌊V/Ci⌋件等 按照解01背包时的思路，令F[i,v]表示前i种物品恰放入一个容量为v的背包的最大权值 $F[i,v] = max{F[i−1, v−kC_i] + kW_i|0≤kC_i≤v}$ 有O(VN)个状态需要求解，求解每个状态的时间已经不是常数了，求解状态F[i,v]的时间是O(v C_i)，总的复杂度可以认为是O(NV ΣV/C_i)，比较大 一个简单有效的优化 完全背包问题有一个很简单有效的优化，是这样的：若两件物品i、j满足C_i≤C_j且W_i≥W_j，则将可以将物品j直接去掉，不用考虑 并不能改善最坏情况的复杂度 O(N2)地实现 转化为01背包问题求解 最简单的想法是，考虑到第i种物品最多选⌊V/C_i⌋ 件，于是可以把第i种物品转化为⌊V/C_i⌋件费用及价值均不变的物品，然后求解这个01背包问题 没有改进时间复杂度 指明了将完全背包问题转化为01背包问题的思路：将一种物品拆成多件只能选0件或1件的01背包中的物品 更高效的转化方法：把第i种物品拆成费用为C_i2^k、价值为W_i2^k的若干件物品，其中k取遍满足C_i2^k≤V的非负整数 O(VN)的算法 1234F[0..V]=0for i=1 to N for v=C_i to V F[v] = max(F[v], F[v−C_i] + W_i 与01背包问题的伪代码只有v的循环次序不同而已 01背包中要按照v递减的次序来循环是为了保证第i次循环中的状态F[i,v]是由状态F[i−1,v−C_i]递推而来; 保证每件物品只选一次，保证在考虑“选入第i件物品”这件策略时，依据的是一个绝无已经选入第i件物品的子结果F[i−1,v−C_i] 完全背包的特点恰是每种物品可选无限件，所以在考虑“加选一件第i种物品”这种策略时，却正需要一个可能已选入第i种物品的子结果F[i,v−C_i]，所以就可以并且必须采用v递增的顺序循环 两层for循环的次序可以颠倒, 有可能会带来算法时间常数上的优化 多重背包问题 [题目]有N种物品和一个容量为V的背包。第i种物品最多有M_i件可用，每件耗费的空间是C_i，价值是W_i。求解将哪些物品装入背包可使这些物品的耗费的空间总和不超过背包容量，且价值总和最大 基本算法 对于第i种物品有Mi+1种策略：取0件，取1件……取Mi件。令F[i,v]表示前i种物品恰放入一个容量为v的背包的最大价值，则有状态转移方程： $F[i, v] = max{F[i−1, v−kC_i]+kW_i|0≤k≤M_i}$ 复杂度是O(VΣM_i) 转化为01背包问题 把第i种物品换成Mi件01背包中的物品，则得到了物品数为ΣM_i的01背包问题 复杂度仍然是O(VΣM_i) 二进制的思想 将第i种物品分成若干件01背包中的物品，其中每件物品有一个系数。这件物品的费用和价值均是原来的费用和价值乘以这个系数。令这些系数分别为1,2,2^2…2^{k−1},M_i−2^k+1，且k是满足M_i−2^k+1&gt;0的最大整数 分成的这几件物品的系数和为M_i，表明不可能取多于M_i件的第i种物品 这种方法也能保证对于0…M_i间的每一个整数，均可以用若干个系数的和表示 正确性的证明可以分0…2^{k−1}和2^k…M_i两段来分别讨论得出 将第i种物品分成了O(logM_i)种物品，将原问题转化为了复杂度为O(VΣlogM_i)的01背包问题 O(VN)的算法 基于基本算法的状态转移方程，但应用单调队列的方法使每个状态的值可以以均摊O(1)的时间求解 混合三种背包问题 [问题]如果将前面的三种背包问题混合起来。也就是说，有的物品只可以取一次（01背包），有的物品可以取无限次（完全背包），有的物品可以取的次数有一个上限（多重背包）。应该怎么求解 01背包与完全背包的混合 如果只有两类物品：一类物品只能取一次，另一类物品可以取无限次，那么只需在对每个物品应用转移方程时，根据物品的类别选用顺序或逆序的循环即可 复杂度是O(VN) 1234567for i=1 to N if 第i件物品属于01背包 for v=V to C_i F[v] = max(F[v], F[v−C_i] + W_i) else if 第i件物品属于完全背包 for v=C_i to V F[v] = max(F[v], F[v−C_i] + W_i) 加上多重背包 加上最多可以取有限次的多重背包式的物品，那么利用单调队列，也可以给出均摊O(VN)的解法 不考虑单调队列算法，用将每个这类物品分成O(logM_i)个01背包的物品的方法也已经很优 1234567891011121314151617181920212223242526def ZeroOnePack(F,C,W) for v=V to C F[v] = max(F[v], f[v−C] + W)def CompletePack(F,C,W) for v=C to V F[v] = max&#123;F[v], f[v−C] + W)def MultiplePack(F,C,W,M) if C·M ≥ V CompletePack(F,C,W) return k := 1 while k&lt;M ZeroOnePack(kC,kW) M := M − k k := 2k ZeroOnePack(C·M,W·M)for i=1 to N if 第i件物品属于01背包 ZeroOnePack(F,C_i,W_i) else if 第i件物品属于完全背包 CompletePack(F,C_i,W_i) else if 第i件物品属于多重背包 MultiplePack(F,C_i,W_i,N_i) 二维费用的背包问题 [问题]二维费用的背包问题是指：对于每件物品，具有两种不同的空间耗费，选择这件物品必须同时付出这两种代价。对于每种代价都有一个可付出的最大值（背包容量）。问怎样选择物品可以得到最大的价值。 设这两种代价分别为代价一和代价二，第i件物品所需的两种代价分别为C_i和D_i。两种代价可付出的最大值（两种背包容量）分别为V和U。物品的价值为W_i 算法 费用加了一维，只需状态也加一维。设F[i,v,u]表示前i件物品付出两种代价分别为v和u时可获得的最大价值。状态转移方程就是： $F[i,v,u] = max{F[i−1,v,u], F[i−1,v−C_i,u−D_i] + Wi}$ 优化空间复杂度的方法，可以只使用二维的数组：当每件物品只可以取一次时变量v和u采用逆序的循环，当物品有如完全背包问题时采用顺序的循环，当物品有如多重背包问题时拆分物品 物品总个数限制 有时“二维费用”的条件是以这样一种隐含的方式给出的：最多只能取U件物品 事实上相当于每件物品多了一种“件数”的费用，每个物品的件数费用均为1，可以付出的最大件数费用为U 设F[v,u]表示付出费用v、最多选u件时可得到的最大价值，则根据物品的类型（01、完全、多重）用不同的方法循环更新，最后在f[0…V,0…U]范围内寻找答案 复整数域上的背包问题 另一种看待二维背包问题的思路是：将它看待成复整数域上的背包问题。背包的容量以及每件物品的费用都是一个复整数 常见的一维背包问题则是自然数域上的背包问题 一维背包的种种思想方法，往往可以应用于二维背包问题的求解中，因为只是数域扩大了而已 分组的背包问题 [问题]有N件物品和一个容量为V的背包。第i件物品的费用是C_i，价值是W_i。这些物品被划分为K组，每组中的物品互相冲突，最多选一件。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大 算法 每组物品有若干种策略：是选择本组的某一件，还是一件都不选 设F[k,v]表示前k组物品花费费用v能取得的最大权值，则有： $F[k,v] = max{F[k−1,v], F[k−1, v−C_i] + W_i|item \\ i \\in group \\ k}$ 1234for k=1 to K for v=V to 0 for item i in group k F[v] = max&#123;F[v], F[v−C_i] + W_i&#125; 三层循环的顺序保证了每一组内的物品最多只有一个会被添加到背包中 有依赖的背包问题 [简化的问题]这种背包问题的物品间存在某种“依赖”的关系。物品i依赖于物品j，表示若选物品i，则必须选物品j。为了简化起见，我们先设没有某个物品既依赖于别的物品，又被别的物品所依赖；另外，没有某件物品同时依赖多件物品 算法 将不依赖于别的物品的物品称为“主件”，依赖于某主件的物品称为“附件”。由这个问题的简化条件可知所有的物品由若干主件和依赖于每个主件的一个附件集合组成 按照背包问题的一般思路，仅考虑一个主件和它的附件集合。可用的策略非常多，包括：一个也不选，仅选择主件，选择主件后再选择一个附件，选择主件后再选择两个附件 无法用状态转移方程来表示如此多的策略。事实上，设有n个附件，则策略有2^n+1个，为指数级 考虑到所有这些策略都是互斥的（只能选择一种策略），所以一个主件和它的附件集合实际上对应于分组的背包问题中的一个物品组，每个选择了主件又选择了若干个附件的策略对应于这个物品组中的一个物品，其费用和价值都是这个策略中的物品的值的和 仅仅是这一步转化并不能给出一个好的算法，因为物品组中的物品还是像原问题的策略一样多 考虑对每组内的物品应用一个简单有效的优化中的优化 对于第k个物品组中的物品，所有费用相同的物品只留一个价值最大的，不影响结果 可以对主件k的“附件集合”先进行一次01背包，得到费用依次为0…V−C_k所有这些值时相应的最大价值F_k[0…V−C_k] 这个主件及它的附件集合相当于V−C_k+1个物品的物品组，其中费用为v的物品的价值为F_k[v−C_k]+W_k，v的取值范围是C_k≤v≤V 原来指数级的策略中，有很多策略都是冗余的，通过一次01背包后，将主件k及其附件转化为V−C_k+1个物品的物品组，就可以直接应用分组的背包问题的算法解决问题了 较一般的问题 依赖关系以图论中“森林”的形式给出。主件的附件仍然可以具有自己的附件集合。限制只是每个物品最多只依赖于一个物品（只有一个主件）且不出现循环依赖 可以用将每个主件及其附件集合转化为物品组的方式 唯一不同的是，由于附件可能还有附件，就不能将每个附件都看作一个一般的01背包中的物品 若这个附件也有附件集合，则它必定要被先转化为物品组，然后用分组的背包问题解出主件及其附件集合所对应的附件组中各个费用的附件所对应的价值 一种树形动态规划，其特点是，在用动态规划求每个父节点的属性之前，需要对它的各个儿子的属性进行一次动态规划式的求值 泛化物品 [定义]考虑这样一种物品，它并没有固定的费用和价值，而是它的价值随着你分配给它的费用而变化 在背包容量为V的背包问题中，泛化物品是一个定义域为0…V中的整数的函数h，当分配给它的费用为v时，能得到的价值就是h(v) 一个费用为c价值为w的物品，如果它是01背包中的物品，那么把它看成泛化物品，它就是除了h(c)=w外，其它函数值都为0的一个函数 完全背包中的物品，可以看成这样一个函数，仅当v被c整除时有h(v)=w·v/c，其它函数值均为0 多重背包中重复次数最多为m的物品，对应的泛化物品的函数有h(v)=w·v/c仅当v被c整除且v/c≤n，其它情况函数值均为0 一个物品组可以看作一个泛化物品h。对于一个0…V中的v，若物品组中不存在费用为v的物品，则h(v)=0，否则h(v)取值为所有费用为v的物品的最大价值 泛化物品的和 给定了两个泛化物品h和l，要用一定的费用从这两个泛化物品中得到最大的价值 对于一个给定的费用v，只需枚举将这个费用如何分配给两个泛化物品 对于0…V中的每一个整数v，可以求得费用v分配到h和l中的最大价值f(v)。也即 $f(v) = max{h(k)+l(v−k)|0≤k≤v}$ 这里的f是一个由泛化物品h和l决定的定义域为0…V的函数，也就是说，f是一个由泛化物品h和l决定的泛化物品 将f定义为泛化物品h和l的和：h、l都是泛化物品，若函数f满足以上关系式，则称f是h与l的和。泛化物品和运算的时间复杂度取决于背包的容量，是O(V^2) 泛函？ 背包问题的泛化物品 一个背包问题中，可能会给出很多条件，包括每种物品的费用、价值等属性，物品之间的分组、依赖等关系等。但肯定能将问题对应于某个泛化物品 给定了所有条件以后，就可以对每个非负整数v求得：若背包容量为v，将物品装入背包可得到的最大价值是多少，这可以认为是定义在非负整数集上的一件泛化物品 背包问题问法的变化……","categories":[],"tags":[]},{"title":"数据链路层和局域网(The Link Layer and LANs)","slug":"computer_network/computer_network_5","date":"2017-05-30T16:00:00.000Z","updated":"2017-06-04T11:59:28.000Z","comments":true,"path":"2017/05/31/computer_network/computer_network_5/","link":"","permalink":"https://chenfeng.github.io/2017/05/31/computer_network/computer_network_5/","excerpt":"introduction, servicesLink layer: introductionterminology: hosts and routers: nodes communication channels that connect adjacent nodes along communication path: links wired links wireless links LANs layer-2 packet: frame([链路层]帧), encapsulates datagram","text":"introduction, servicesLink layer: introductionterminology: hosts and routers: nodes communication channels that connect adjacent nodes along communication path: links wired links wireless links LANs layer-2 packet: frame([链路层]帧), encapsulates datagram data-link layer has responsibility of transferring datagram from one node to physically adjacent node over a link Link layer: context datagram transferred by different link protocols over different links: e.g., Ethernet on first link, frame relay on intermediate links, 802.11 on last link each link protocol provides different services e.g., may or may not provide rdt over link transportation analogy: trip from Princeton to Lausanne limo: Princeton to JFK plane: JFK to Geneva train: Geneva to Lausanne tourist = datagram transport segment = communication link transportation mode = link layer protocol travel agent = routing algorithm Link layer services framing, link access: encapsulate datagram into frame, adding header, trailer channel access if shared medium “MAC” addresses used in frame headers to identify source, destination different from IP address! reliable delivery between adjacent nodes we learned how to do this already (chapter 3) seldom used on low bit-error link (fiber, some twisted pair) wireless links: high error rates Q: why both link-level and end-end reliability? flow control: pacing between adjacent sending and receiving nodes error detection: errors caused by signal attenuation, noise. receiver detects presence of errors: signals sender for retransmission or drops frame error correction: receiver identifies and corrects bit error(s) without resorting to retransmission half-duplex and full-duplex with half duplex, nodes at both ends of link can transmit, but not at same time Where is the link layer implemented in each and every host link layer implemented in “adaptor” (aka network interface card NIC) or on a chip Ethernet card, 802.11 card; Ethernet chipset implements link, physical layer attaches into host’s system buses combination of hardware, software, firmware Adaptors communicating sending side: encapsulates datagram in frame adds error checking bits, rdt, flow control, etc. receiving side looks for errors, rdt, flow control, etc. extracts datagram, passes to upper layer at receiving side error detection, correctionError detection EDC = Error Detection and Correction bits (redundancy)D = Data protected by error checking, may include header fields Error detection not 100% reliable! protocol may miss some errors, but rarely larger EDC field yields better detection and correction Parity checkingsingle bit parity: detect single bit errors two-dimensional bit parity: detect and correct single bit errors Cyclic redundancy check more powerful error-detection coding view data bits, D, as a binary number choose r+1 bit pattern (generator), G goal: choose r CRC bits, R, such that exactly divisible by G (modulo 2) receiver knows G, divides by G. If non-zero remainder: error detected! can detect all burst errors less than r+1 bits widely used in practice (Ethernet, 802.11 WiFi, ATM) CRC example want: D.2r XOR R = nG equivalently: D.2r = nG XOR R equivalently: if we divide D.2r by G, want remainder R to satisfy: $R = remainder[\\frac{D.2^r}{G}]$ multiple access protocolstwo types of “links”: point-to-point PPP for dial-up access point-to-point link between Ethernet switch, host broadcast (shared wire or medium) old-fashioned Ethernet upstream HFC 802.11 wireless LAN Multiple access protocols single shared broadcast channel two or more simultaneous transmissions by nodes: interference collision if node receives two or more signals at the same time multiple access protocol distributed algorithm that determines how nodes share channel, i.e., determine when node can transmit communication about channel sharing must use channel itself! no out-of-band channel for coordination An ideal multiple access protocol given: broadcast channel of rate R bps desiderata: when one node wants to transmit, it can send at rate R. when M nodes want to transmit, each can send at average rate R/M fully decentralized: no special node to coordinate transmissions no synchronization of clocks, slots simple MAC protocolstaxonomy(分类) three broad classes: channel partitioning divide channel into smaller “pieces” (time slots, frequency, code) allocate piece to node for exclusive use random access channel not divided, allow collisions “recover” from collisions “taking turns” nodes take turns, but nodes with more to send can take longer turns Channel partitioning MAC protocols TDMA: time division multiple access access to channel in “rounds” each station gets fixed length slot (length = packet transmission time) in each round unused slots go idle example: 6-station LAN, 1,3,4 have packets to send, slots 2,5,6 idle FDMA: frequency division multiple access channel spectrum divided into frequency bands each station assigned fixed frequency band unused transmission time in frequency bands go idle example: 6-station LAN, 1,3,4 have packet to send, frequency bands 2,5,6 idle Random access protocols when node has packet to send transmit at full channel data rate R. no a priori coordination among nodes two or more transmitting nodes ➜ “collision”, random access MAC protocol specifies: how to detect collisions how to recover from collisions (e.g., via delayed retransmissions) examples of random access MAC protocols: slotted ALOHA ALOHA CSMA, CSMA/CD, CSMA/CA Slotted ALOHA assumptions: all frames same size time divided into equal size slots (time to transmit 1 frame) nodes start to transmit only slot beginning nodes are synchronized if 2 or more nodes transmit in slot, all nodes detect collision operation: when node obtains fresh frame, transmits in next slot if no collision: node can send new frame in next slot if collision: node retransmits frame in each subsequent slot with prob. p until success Pros: single active node can continuously transmit at full rate of channel highly decentralized: only slots in nodes need to be in sync simple Cons: collisions, wasting slots idle slots nodes may be able to detect collision in less than time to transmit packet clock synchronization efficiency: long-run fraction of successful slots (many nodes, all with many frames to send) suppose: N nodes with many frames to send, each transmits in slot with probability p prob that given node has success in a slot = p(1-p)N-1 prob that any node has a success = Np(1-p)N-1 max efficiency: find p* that maximizes Np(1-p)N-1 for many nodes, take limit of Np(1-p)^{N-1} as N goes to infinity, gives: max efficiency = 1/e = .37 at best: channel used for useful transmissions 37% of time Pure (unslotted) ALOHA unslotted Aloha: simpler, no synchronization when frame first arrives transmit immediately collision probability increases: frame sent at t0 collides with other frames sent in [t0-1,t0+1] Pure ALOHA efficiency 1234567P(success by given node) = P(node transmits) . P(no other node transmits in [t0-1,t0] . P(no other node transmits in [t0,t0+1] = p . (1-p)^&#123;N-1&#125; . (1-p)^&#123;N-1&#125; = p . (1-p)^&#123;2(N-1)&#125; … choosing optimum p and then letting n -&gt; \\infinite = 1/(2e) = .18 even worse than slotted Aloha CSMA collisions collisions can still occur: propagation delay means two nodes may not hear each other’s transmission collision: entire packet transmission time wasted distance &amp; propagation delay play role in determining collision probability CSMA/CD (collision detection) CSMA/CD: carrier sensing, deferral as in CSMA collisions detected within short time colliding transmissions aborted, reducing channel wastage Ethernet CSMA/CD algorithm: NIC receives datagram from network layer, creates frame If NIC senses channel idle, starts frame transmission. If NIC senses channel busy, waits until channel idle, then transmits. If NIC transmits entire frame without detecting another transmission, NIC is done with frame ! If NIC detects another transmission while transmitting, aborts and sends jam signal After aborting, NIC enters binary (exponential) backoff: after mth collision, NIC chooses K at random from {0,1,2, …, 2^m-1}. NIC waits K·512 bit times, returns to Step 2 longer backoff interval with more collisions CSMA/CD efficiency: $t_{prop}$ = max prop delay between 2 nodes in LAN $t_{trans}$ = time to transmit max-size frame $efficiency = \\frac{1}{1 + 5t{prop}/t{trans}}$ efficiency goes to 1 as $t_{prop}$ goes to 0 as $t_{trans}$ goes to infinity better performance than ALOHA: and simple, cheap, decentralized “Taking turns” MAC protocols channel partitioning MAC protocols: share channel efficiently and fairly at high load inefficient at low load: delay in channel access, 1/N bandwidth allocated even if only 1 active node! random access MAC protocols efficient at low load: single node can fully utilize channel high load: collision overhead “taking turns” protocols look for best of both worlds! polling(轮询): master node “invites” slave nodes to transmit in turn typically used with “dumb” slave devices concerns: polling overhead latency single point of failure (master) token(令牌) passing: control token passed from one node to next sequentially. token message concerns: token overhead latency single point of failure (token) Cable access network multiple 40Mbps downstream (broadcast) channels single CMTS transmits into channels multiple 30 Mbps upstream channels multiple access: all users contend for certain upstream channel time slots (others assigned) DOCSIS: data over cable service interface spec FDM over upstream, downstream frequency channels TDM upstream: some slots assigned, some have contention downstream MAP frame: assigns upstream slots request for upstream slots (and data) transmitted random access (binary backoff) in selected slots Summary of MAC protocols channel partitioning, by time, frequency or code Time Division, Frequency Division random access(dynamic), ALOHA, S-ALOHA, CSMA, CSMA/CD carrier sensing: easy in some technologies (wire), hard in others (wireless) CSMA/CD used in Ethernet CSMA/CA used in 802.11 taking turns polling from central site, token passing Bluetooth, FDDI, token ring LANsMAC addresses32-bit IP address: network-layer address for interface used for layer 3 (network layer) forwarding MAC (or LAN or physical or Ethernet) address: function: used ‘locally” to get frame from one interface to another physically-connected interface (same network, in IP-addressing sense) 48 bit MAC address (for most LANs) burned in NIC ROM, also sometimes software settable e.g.: 1A-2F-BB-76-09-AD hexadecimal (base 16) notation(each “numeral” represents 4 bits) each adapter on LAN has unique LAN address MAC address allocation administered by IEEE manufacturer buys portion of MAC address space (to assure uniqueness) analogy: MAC address: like Social Security Number IP address: like postal address MAC flat address ➜ portability can move LAN card from one LAN to another IP hierarchical address not portable address depends on IP subnet to which node is attached ARP: address resolution protocolQuestion: how to determine interface’s MAC address, knowing its IP address? ARP table: each IP node (host, router) on LAN has table IP/MAC address mappings for some LAN nodes: &lt; IP address; MAC address; TTL&gt; TTL (Time To Live): time after which address mapping will be forgotten (typically 20 min) ARP protocol: same LAN A wants to send datagram to B B’s MAC address not in A’s ARP table. A broadcasts ARP query packet, containing B’s IP address destination MAC address = FF-FF-FF-FF-FF-FF all nodes on LAN receive ARP query B receives ARP packet, replies to A with its (B’s) MAC address frame sent to A’s MAC address (unicast) A caches (saves) IP-to-MAC address pair in its ARP table until information becomes old (times out) soft state: information that times out (goes away) unless refreshed ARP is “plug-and-play”(即插即用): nodes create their ARP tables without intervention from net administrator Addressing: routing to another LAN walkthrough: send datagram from A to B via R focus on addressing – at IP (datagram) and MAC layer (frame) assume A knows B’s IP address assume A knows IP address of first hop router, R (how?) assume A knows R’s MAC address (how?) A creates IP datagram with IP source A, destination B A creates link-layer frame with R’s MAC address as destination address, frame contains A-to-B IP datagram frame sent from A to R frame received at R, datagram removed, passed up to IP R forwards datagram with IP source A, destination B R creates link-layer frame with B’s MAC address as destination address, frame contains A-to-B IP datagram Ethernet “dominant” wired LAN technology: single chip, multiple speeds (e.g., Broadcom BCM5761) first widely used LAN technology simpler, cheap kept up with speed race: 10 Mbps – 10 Gbps Ethernet: physical topology bus: popular through mid 90s all nodes in same collision domain (can collide with each other) star: prevails today active switch in center each “spoke” runs a (separate) Ethernet protocol (nodes do not collide with each other) Ethernet frame structure sending adapter encapsulates IP datagram (or other network layer protocol packet) in Ethernet frame preamble: 7 bytes with pattern 10101010 followed by one byte with pattern 10101011 used to synchronize receiver, sender clock rates addresses: 6 byte source, destination MAC addresses if adapter receives frame with matching destination address, or with broadcast address (e.g. ARP packet), it passes data in frame to network layer protocol otherwise, adapter discards frame type: indicates higher layer protocol (mostly IP but others possible, e.g., Novell IPX, AppleTalk) CRC: cyclic redundancy check at receiver error detected: frame is dropped Ethernet: unreliable, connectionless connectionless: no handshaking between sending and receiving NICs unreliable: receiving NIC doesn’t send acks or nacks to sending NIC data in dropped frames recovered only if initial sender uses higher layer rdt (e.g., TCP), otherwise dropped data lost Ethernet’s MAC protocol: unslotted CSMA/CD with binary backoff 802.3 Ethernet standards: link &amp; physical layers many different Ethernet standards common MAC protocol and frame format different speeds: 2 Mbps, 10 Mbps, 100 Mbps, 1Gbps, 10 Gbps, 40 Gbps different physical layer media: fiber, cable Ethernet switch link-layer device: takes an active role store, forward Ethernet frames examine incoming frame’s MAC address, selectively forward frame to one-or-more outgoing links when frame is to be forwarded on segment, uses CSMA/CD to access segment transparent hosts are unaware of presence of switches plug-and-play, self-learning switches do not need to be configured Switch: multiple simultaneous transmissions hosts have dedicated, direct connection to switch switches buffer packets Ethernet protocol used on each incoming link, but no collisions; full duplex each link is its own collision domain switching: A-to-A’ and B-to-B’ can transmit simultaneously, without collisions Switch forwarding table Q: how does switch know A’ reachable via interface 4, B’ reachable via interface 5? A: each switch has a switch table, each entry: (MAC address of host, interface to reach host, time stamp) looks like a routing table Switch: self-learning Q: how are entries created, maintained in switch table? something like a routing protocol? switch learns which hosts can be reached through which interfaces when frame received, switch “learns” location of sender: incoming LAN segment records sender/location pair in switch table Switch: frame filtering/forwarding when frame received at switch: record incoming link, MAC address of sending host index switch table using MAC destination address 12345678if entry found for destination then &#123; if destination on segment from which frame arrived then drop frame else forward frame on interface indicated by entry &#125; else flood /* forward on all interfaces except arriving interface */ example: frame destination, A’, location unknown: flood destination A location known: selectively send on just one link Interconnecting switches self-learning switches can be connected together: Q: sending from A to G - how does S1 know to forward frame destined to G via S4 and S3? A: self learning! (works exactly the same as in single-switch case!) Self-learning multi-switch example: Suppose C sends frame to I, I responds to C Q: show switch tables and packet forwarding in S1, S2, S3, S4 ? Switches vs. routers both are store-and-forward: routers: network-layer devices (examine network-layer headers) switches: link-layer devices (examine link-layer headers) both have forwarding tables: routers: compute tables using routing algorithms, IP addresses switches: learn forwarding table using flooding, learning, MAC addresses VLANs: motivation consider: CS user moves office to EE, but wants connect to CS switch? single broadcast domain: all layer-2 broadcast traffic (ARP, DHCP, unknown location of destination MAC address) must cross entire LAN security/privacy, efficiency issues Virtual Local Area Network: switch(es) supporting VLAN capabilities can be configured to define multiple virtual LANS over single physical LAN infrastructure. port-based VLAN: switch ports grouped (by switch management software) so that single physical switch operates as multiple virtual switches traffic isolation: frames to/from ports 1-8 can only reach ports 1-8 can also define VLAN based on MAC addresses of endpoints, rather than switch port dynamic membership: ports can be dynamically assigned among VLANs forwarding between VLANS: done via routing (just as with separate switches) in practice vendors sell combined switches plus routers VLANS spanning multiple switches trunk port: carries frames between VLANS defined over multiple physical switches frames forwarded within VLAN between switches can’t be vanilla 802.1 frames (must carry VLAN ID info) 802.1q protocol adds/removed additional header fields for frames forwarded between trunk ports 802.1Q VLAN frame format link virtualization: MPLSMultiprotocol label switching (MPLS): initial goal: high-speed IP forwarding using fixed length label (instead of IP address) fast lookup using fixed length identifier (rather than shortest prefix matching) borrowing ideas from Virtual Circuit (VC) approach but IP datagram still keeps IP address! MPLS capable routers a.k.a. label-switched router forward packets to outgoing interface based only on label value (don’t inspect IP address) MPLS forwarding table distinct from IP forwarding tables MPLS versus IP paths IP routing: path to destination determined by destination address alone MPLS routing: path to destination can be based on source and destination address fast reroute: precompute backup routes in case of link failure MPLS signaling: modify OSPF, IS-IS link-state flooding protocols to carry info used by MPLS routing, e.g., link bandwidth, amount of “reserved” link bandwidth entry MPLS router uses RSVP-TE signaling protocol to set up MPLS forwarding at downstream routers MPLS forwarding tables:","categories":[],"tags":[{"name":"computer network","slug":"computer-network","permalink":"https://chenfeng.github.io/tags/computer-network/"}]},{"title":"金融市场","slug":"economics/finacial_market","date":"2017-05-28T16:00:00.000Z","updated":"2017-05-29T11:46:12.000Z","comments":true,"path":"2017/05/29/economics/finacial_market/","link":"","permalink":"https://chenfeng.github.io/2017/05/29/economics/finacial_market/","excerpt":"The Demand for Money Money, used for transactions, pays no interest (货币可以用于交易, 没有利率) 两种货币: 通货(currency, coins and bills), 支票(checkable deposits, the bank deposits on which you can write checks) bonds pay a positive interest rate, i, cannot be used for transactions (债券无法用于交易, 一定正利率)","text":"The Demand for Money Money, used for transactions, pays no interest (货币可以用于交易, 没有利率) 两种货币: 通货(currency, coins and bills), 支票(checkable deposits, the bank deposits on which you can write checks) bonds pay a positive interest rate, i, cannot be used for transactions (债券无法用于交易, 一定正利率) The proportions of money and bonds you wish to hold depend mainly on two variables: Your level of transactions The interest rate on bonds Income is what you earn from working plus what you receive in interest and dividends. It is a flow—that is, it is expressed per unit of timeSaving is that part of after-tax income that is not spent. It is also a flow. Savings is sometimes used as a synonym for wealth (a term we will not use in this book)Your financial wealth, or simply wealth, is the value of all your financial assets minus all your financial liabilities. In contrast to income or saving, which are flow variables, financial wealth is a stock variableInvestment is a term economists reserve for the purchase of new capital goods, from machines to plants to office buildings. When you want to talk about the purchase of shares or other financial assets, you should refer them as a financial investment Deriving the Demand for Money 货币需求函数 $M^d = $Y L(i)$ $M^d$: 货币需求量, $$Y$: 名义收入, $L(i)$: 流动性(liquidity), $i$: 利率 The demand for money: increases in proportion to nominal income ($Y) depends negatively on the interest rate (L(i) and the negative sign underneath) For a given level of nominal income, a lower interest rate increases the demand for money. At a given interest rate, an increase in nominal income shifts the demand for money to the right: The Determination of the Interest Rate, IMoney Demand, Money Supply, and the Equilibrium Interest Rate 货币供给量由央行决定(central bank) 货币是交易的润滑剂最大的作用是促进交易市场上货币量应当与实体经济运行的状况相当，不能脱节(过多或过少) 金融市场的运转通过货币政策控制货币的发行量 实体经济(商品市场)和金融市场就像两个同心的轮子，外缘以有弹性的铰链相连使金融市场运转的速度稍快于实体经济的有利于带动实体经济，过慢反之会拖慢实体经济的增长速度但是金融市场运转速度过快，和实体经济脱节是没有意义的 Equilibrium in financial markets requires that money supply be equal to money demand: $M^s = M^d$, equilibrium condition is: $M = $Y L(i)$(LM relation) The interest rate must be such that the supply of money (which is independent of the interest rate) is equal to the demand for money (which does depend on the interest rate): An increase in nominal income leads to an increase in the interest rate: An increase in the supply of money leads to a decrease in the interest rate: Monetary Policy(金融政策，货币政策) and Open Market Operations Open market operations(公开市场操作): take place in the “open market” for bonds, are the standard method central banks use to change the money stock in modern economies If the central bank buys bonds, this operation is called an expansionary(扩展性) open market operation because the central bank increases (expands) the supply of money(回收债券，投放货币) If the central bank sells bonds, this operation is called a contractionary(紧缩性) open market operation because the central bank decreases (contracts) the supply of money(发行债券，回收货币) The assets of the central bank are the bonds it holds. The liabilities are the stock of money in the economy. An open market operation in which the central bank buys bonds and issues money increases both assets and liabilities by the same amount： Bond Prices and Bond Yields Treasury bills, or T-bills are issued by the U.S. government promising payment in a year or less. If you buy the bond today and hold it for a year, the rate of return (or interest) on holding a $100 bond for a year is $ ($100 - $P_B)/$P_B $ A decision by the central bank to lower the interest rate from i to i’ is equivalent to increasing the money supply. What Banks Do Banks receive funds from people and firms who either deposit funds directly or have funds sent to their checking accounts. The liabilities of the banks are therefore equal to the value of these checkable deposits Banks keep as reserves(准备金) some of the funds they receive Banks hold reserves for three reasons: On any given day, some depositors withdraw cash from their checking accounts, while others deposit cash into their accounts. In the same way, on any given day, people with accounts at the bank write checks to people with accounts at other banks, and people with accounts at other banks write checks to people with accounts at the bank. Banks are subject to reserve requirements. The actual reserve ratio – the ratio of bank reserves to bank checkable deposits – is about 10% in the United States today. The assets of the central bank are the bonds it holds. The liabilities of the central bank are the money it has issued, central bank money. The new feature is that not all of central bank money is held as currency by the public. Some of held as reserves by banks. Rumors that a bank is not doing well and some loans will not be repaid, will lead people to close their accounts at that bank. If enough people do so, the bank will run out of reserves—a bank run. To avoid bank runs, the U.S. government provides federal deposit insurance. An alternative solution is narrow banking, which would restrict banks to holding liquid, safe, government bonds, such as T-bills. The Supply and the Demand for Central Bank Money demand for money $M^d = $Y L(i)$ demand for checkable deposits $D^d = (1 - c)M^d$ demand for currency $CU^d = c M^d$ demand for reserves $R = \\theta D$, reserves(R), deposits(D) The larger the amount of checkable deposits, the larger the amount of reserves the banks must hold, for both precautionary and regulatory reasons The demand for reserves by banks is $R^d = \\theta(1 - c)M^d$ The demand for central bank money is equal to the sum of the demand for currency and the demand dfot reserves: $H^d = CU^d + R^d$ $H^d = cM^d + \\theta(1 - c)M^d = [c + \\theta(1 - c)]M^d$ $H^d = cM^d + \\theta(1 - c)M^d = [c + \\theta(1 - c)]$Y L(i)$ In equilibrium the supply of central bank money(H) is equal to the demand for central bank money($H^d$): $H = H^d$ The equilibrium interest rate is such that the supply of central bank money is equal to the demand for central bank money: \\frac{1}{[c + \\theta(1 - c)]}H = \\$Y L(i) 派生存款乘数：$\\frac{1}{[c + \\theta(1 - c)]}$ 央行主要的作用(任务)： 促进经济增长 抑制通货膨胀 通货膨胀率不是越低越好，适度有利于刺激实体经济增长 [主要的]货币政策 公开市场操作(我国债券市场规模较小；企业发债受限) [调整]法定存款准备金(reserve requirements)率(规避风险，防挤兑)：一笔存款保留不放贷的部分的比重(由央行保留，不付利息) 发挥周期长，作用见效慢 [调整]贴现率(discount rate)：央行向银行发放贷款的利率 央行向银行发放贷款 不一定见效","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]},{"title":"商品市场","slug":"economics/good_market","date":"2017-05-28T16:00:00.000Z","updated":"2017-05-29T12:57:10.000Z","comments":true,"path":"2017/05/29/economics/good_market/","link":"","permalink":"https://chenfeng.github.io/2017/05/29/economics/good_market/","excerpt":"GDP目标：衡量福利水平 提高GDP不一定提高福利水 比较极端的例子：犯罪活动可以增加GDP，但不利于福利","text":"GDP目标：衡量福利水平 提高GDP不一定提高福利水 比较极端的例子：犯罪活动可以增加GDP，但不利于福利 the composition of GDPconsumption(C): goods and services purchased by consumers investment(I): fixed investment, purchases of capital goods. the sum of nonreisdential investment and residential investment government spending(G): the purchases of goods and services by the fedaral, state, and local governments. not include government transfers, nor interest payments on the goverment debt imports(IM): the purchases of foreigh goods and services by consumers, business firms, and the U.S. goverment exports(X): the purchases of U.S. goods and services by foreighers net exports(X - IM): the difference between exports and imports, trade balance exports = imports &lt;-&gt; trade balance exports &gt; imports &lt;-&gt; trade surplus exports &lt; imports &lt;-&gt; trade deficit inventory investment: the difference between production and sales(购买未来用于生产其他物品的物品：资本设备、建筑物和存货) The Demand for Goods total demand for goods: $ Z \\equiv C + I + G + X - IM $ 假设所有公司生产相同goods，能被消费者消费，被公司、政府投资 假设公司都愿意在一个给定的价格P供应任意数额的goods 假设经济体不是开放的，不和外界交易，进出口都为零 X = IM = 0，则：Z \\equiv C + I + G consumption(C) disposable income(可支配收入，即税后收入) $Y_D$ cunsumption function(a behavioral equation, captures the behavior of consumers): $C = C(Y_D)$ $C = c_0 + c_1 Y_D$ $c_0$ is the intercept of the cunsumption function(短期内就算无收入也必须支出的部分) $c_1$: the (marginal) propensity of consume(边际消费倾向), or the effect of an additional dollar of disposable income on consumption; 与消费者信心指数(consumer confidance index)相关, 即消费者预期经济增长趋势的信心越高则边际消费倾向越大 边际消费倾向实际上是递减的 $Y_D \\equiv Y - T$ (T是政府税收等) $ C = c_0 + c_1(Y - T) $ investment(I) depend on other variables within the model are called endogenous(内生变量). here treated as an exogenous variable(外生变量), taken as given: $I = \\overline I$ Government Spending(G) together with taxes, T, describes fiscal policy(财政政策): the choice of taxes and spending by the government assume G is an exogenous variable We shall assume that G and T are also exogenous for two reasons: Governments do not behave with the same regularity as consumers or firms. Macroeconomists must think about the implications of alternative spending and tax decisions of the government. The Determination of Equilibrium OutputAssuming that exports and imports are both zero, the demand for goods is the sum of consumption, investment, and government spending: $Z \\equiv C + I + G$, then $Z = c_0 + c_1(Y - T) + \\overline I + G$ Equilibrium in the goods market requires that production, Y, be equal to the demand for goods, Z: $Y = Z$, then $Y = c_0 + c_1(Y - T) + \\overline I + G$ Macroeconomists always use these three tools: Algebra to make sure that the logic is correct Graphs to build the intuition Words to explain the results using Algebra $(1 - c_1)Y = c_0 + \\overline I + G - c_1 T$ $Y = \\frac{1}{1 - c_1}[c_0 + \\overline I + G + c_1 T]$ Autonomous Spending : $c_0 + \\overline I + G + c_1 T$, the part of the demand for goods that does not depend on output $c_1$比较大时对Y刺激大，鼓励消费(有助于[短期]经济增长) using a GraphZ = (c_0 + \\overline I + G + c_1 T) + c_1 Y An increase in autonomous spending($c_0 + \\overline I + G - c_1 T$) has a more than onefor-one effect on equilibrium output: 也就是需求增加，供给侧有剩余产能，供给增加达到新的商品市场的均衡 45度角的线横纵坐标相同，代表需求等于供给 The first-round increase in demand, shown by the distance AB equals $1 billion. This first-round increase in demand leads to an equal increase in production, or $1 billion, which is also shown by the distance in AB. This first-round increase in production leads to an equal increase in income, shown by the distance in BC, also equal to $1 billion. using Words An increase in demand leads to an increase in production and a corresponding increase in income. The end result is an increase in output that is larger than the initial shift in demand, by a factor equal to the multiplier. $Y = \\frac{1}{1 - c_1}[c_0 + \\overline I + G + c_1 T]$ How Long Does It Take for Output to Adjust?Describing formally the adjustment of output over time is what economists call the dynamics of adjustment. Suppose that firms make decisions about their production levels at the beginning of each quarter. Now suppose consumers decide to spend more, that they increase $c_0$ Having observed an increase in demand, firms are likely to set a higher level of production in the following quarter. In response to an increase in consumer spending, output does not jump to the new equilibrium, but rather increases over time. Investment Equals Saving: An Alternative Way of Thinking about Goods-Market EquilibriumSaving is the sum of private plus public saving private saving(私人储蓄, S) is the saving by consumers, $S = Y_D - C$, $S = Y - T - C$ public saving equals taxes minus government spending(T - G) T &gt; G : budget surplus T &lt; G : budget deficit(赤字) $Y = C + I + G$, $Y - C - T = I + G - T$, $S = Y - T - C = I + G - T$, $I = S + (T - G)$ The equation above states that equilibrium in the goods market requires that investment equals saving — the sum of private plus public saving. This equilibrium condition for the goods market is called the IS relation. What firms want to invest must be equal to what people and the government want to save. Consumption and saving decisions are one and the same:$S = Y - T - C$, $S = Y - T - c_0 - c_1(Y - T) = -c_0 + (1 - c_1)(Y - T)$ (The term (1-c1) is called the propensity to save) 均衡时, $I = S + (T - G) = -c_0 + (1 - c_1)(Y - T) + (T - G)$, 即: Y = \\frac{1}{1 - c_1}[c_0 + I + G - c_1 T] 和产出公式相同 节俭悖论：每个人都消费很少，经济体会进入一种恶性循环 The paradox of saving (or the paradox of thrift) is that as people attempt to save more, the result is both a decline in output and unchanged saving. Is the Government Omnipotent(政府是万能的吗) Changing government spending or taxes is not always easy. The responses of consumption, investment, imports, etc, are hard to assess with much certainty. Anticipations are likely to matter. Achieving a given level of output can come with unpleasant side effects. Budget deficits and public debt may have adverse implications in the long run 经济增长短期靠需求，中期靠供给，长期靠政府质量 短期靠需求 短期通过刺激需求，通过供需关系供给增加，产出增加 $Y = c_0 + c_1(Y - T) + \\overline I + G$ 可以通过使$c_1$增大，促进经济正向循环 中期靠供给 刺激需求拉动经济增长可行的前提是供给侧有剩余产能供给能跟得上需求 因此供给侧需要持续投入，产能能不断提高 关键在于供给侧的生产效率 效率取决于技术 供给侧改革的目标就是促进技术进步 长期靠政府质量 从根本上，技术的上限是人的素质、能力 引入竞争才能充分发掘人的潜力","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]},{"title":"商品市场及金融市场：IS-LM模型","slug":"economics/Goods_And_Financial_Market_IS_LM_model","date":"2017-05-28T16:00:00.000Z","updated":"2017-06-29T08:51:52.179Z","comments":true,"path":"2017/05/29/economics/Goods_And_Financial_Market_IS_LM_model/","link":"","permalink":"https://chenfeng.github.io/2017/05/29/economics/Goods_And_Financial_Market_IS_LM_model/","excerpt":"The Goods Market and the IS Relation Equilibrium in the goods market exists when production, Y, is equal to the demand for goods, Z. This condition is called the IS relation. In the simple model developed previously, the interest rate did not affect the demand for goods. The equilibrium condition was given by: $Y = C(Y - T) + \\overline I + G$","text":"The Goods Market and the IS Relation Equilibrium in the goods market exists when production, Y, is equal to the demand for goods, Z. This condition is called the IS relation. In the simple model developed previously, the interest rate did not affect the demand for goods. The equilibrium condition was given by: $Y = C(Y - T) + \\overline I + G$ Investment, Sales, and the Interest Rate Investment depends primarily on two factors: The level of sales (+) The interest rate (-) $I = I(Y, i)$(Y是销售水平, i是利率) Determining Output Taking into account the investment relation, the equilibrium condition in the goods market becomes: $Y = C(Y - T) + I(Y, i) + G$ For a given value of the interest rate i, demand is an increasing function of output An increase in output leads to an increase in income and also to an increase in disposable income An increase in output also leads to an increase in investment The demand for goods is an increasing function of output. Equilibrium requires that the demand for goods be equal to output: two characteristics of ZZ(需求函数): Because it’s assumed that the consumption and investment relations in Equation $Y = C(Y - T) + I(Y, i) + G$ are linear, ZZ is, in general, a curve rather than a line ZZ is drawn flatter than a 45-degree line because it’s assumed that an increase in output leads to a less than one-for-one increase in demand Deriving the IS Curve The Derivation of the IS Curve An increase in the interest rate decreases the demand for goods at any level of output, leading to a decrease in the equilibrium level of output Equilibrium in the goods market implies that an increase in the interest rate leads to a decrease in output. The IS curve is therefore downward sloping Shifts of the IS Curve Changes in factors that decrease the demand for goods, given the interest rate, shift the IS curve to the left. Changes in factors that increase the demand for goods, given the interest rate, shift the IS curve to the right. An increase in taxes shifts the IS curve to the left: 使IS曲线向右移动的做法：增加政府支出，减税，扩张性财政政策(利率下降)等 Financial Markets and the LM Relation The interest rate is determined by the equality of the supply of and the demand for money: $M = $YL(i)$ M = nominal money stock $YL(i) = demand for money $Y = nominal income i = nominal interest rate The LM relation: In equilibrium, the real money supply is equal to the real money demand, which depends on real income, Y, and the interest rate, i: $\\frac{M}{P} = YL(i)$ Nominal GDP = Real GDP multiplied by the GDP deflator: $$Y = YP$, equivalently: $\\frac{$Y}{P} = Y$ Deriving the LM Curve The Derivation of the LM Curve An increase in income leads, at a given interest rate, to an increase in the demand for money. Given the money supply, this increase in the demand for money leads to an increase in the equilibrium interest rate Equilibrium in the financial markets implies that an increase in income leads to an increase in the interest rate. The LM curve is therefore upward sloping Shifts of the LM Curve An increase in money causes the LM curve to shift down: An increase in the money supply shifts the LM curve down; a decrease in the money supply shifts the LM curve up 国家增加货币供给会使LM曲线向下移 Putting the IS and the LM Relations Together IS relation: $Y = C(Y - T) + I(Y, i) + G$ LM relation: $\\frac{M}{P} = YL(i)$ Equilibrium in the goods market implies that an increase in the interest rate leads to a decrease in output. This is represented by the IS curve. Equilibrium in financial markets implies that an increase in output leads to an increase in the interest rate. This is represented by the LM curve. Only at point A, which is on both curves, are both goods and financial markets in equilibrium. Fiscal Policy, Activity, and the Interest Rate Fiscal contraction(紧缩性财政政策), or fiscal consolidation, refers to fiscal policy that reduces the budget deficit(削减赤字, 减小政府支出) An increase in the deficit is called a fiscal expansion(扩张性财政政策) Taxes affect the IS curve, not the LM curve 对$Y = c(Y - T) + I(Y, i) + G$中G的调控和对c(Y - T)的调控 Monetary contraction(紧缩性货币政策), or monetary tightening, refers to a decrease in the money supply(减少货币供给) An increase in the money supply is called monetary expansion(扩张性货币政策) Monetary policy does not affect the IS curve, only the LM curve A monetary expansion leads to higher output and a lower interest rate: Using a Policy Mix Investment = Private saving + Public saving I = S + (T – G) A fiscal contraction may decrease investment. Or, looking at the reverse policy, a fiscal expansion — a decrease in taxes or an increase in spending—may actually increase investment How Does the IS-LM Model Fit the Facts? Consumers are likely to take some time to adjust their consumption following a change in disposable income Firms are likely to take some time to adjust investment spending following a change in their sales Firms are likely to take some time to adjust investment spending following a change in the interest rate Firms are likely to take some time to adjust production following a change in their sales","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]},{"title":"网络层(Network Layer)","slug":"computer_network/computer_network_4","date":"2017-05-23T16:00:00.000Z","updated":"2017-05-28T06:37:06.000Z","comments":true,"path":"2017/05/24/computer_network/computer_network_4/","link":"","permalink":"https://chenfeng.github.io/2017/05/24/computer_network/computer_network_4/","excerpt":"transport segment from sending to receiving host on sending side encapsulates segments into datagrams on receiving side, delivers segments to transport layer network layer protocols in every host, router router examines header fields in all IP datagrams passing through it network-layer functions: forwarding: move packets from router’s input to appropriate router output routing: determine route taken by packets from source to destination(routing algorithms)","text":"transport segment from sending to receiving host on sending side encapsulates segments into datagrams on receiving side, delivers segments to transport layer network layer protocols in every host, router router examines header fields in all IP datagrams passing through it network-layer functions: forwarding: move packets from router’s input to appropriate router output routing: determine route taken by packets from source to destination(routing algorithms) analogy: taking a trip forwarding: process of getting through single interchange routing: process of planning trip from source to destination Data plane local, per-router function determines how datagram arriving on router input port is forwarded to router output port forwarding function Control plane network-wide logic determines how datagram is routed among routers along end-end path from source host to destination host two control-plane approaches: traditional routing algorithms: implemented in routers software-defined networking (SDN): implemented in (remote) servers Per-router control plane Individual routing algorithm components in each and every router interact in the control plane Logically centralized control plane Q: What service model for “channel” transporting datagrams from sender to receiver? example services for individual datagrams: guaranteed delivery guaranteed delivery with less than 40 msec delay example services for a flow of datagrams: in-order datagram delivery guaranteed minimum bandwidth to flow restrictions on changes in inter-packet spacing Data planeRouterRouter architecture overviewhigh-level view of generic router architecture: Input port functionsdecentralized switching: using header field values, lookup output port using forwarding table in input port memory (“match plus action”) goal: complete input port processing at ‘line speed’ queuing: if datagrams arrive faster than forwarding rate into switch fabric destination-based forwarding: forward based only on destination IP address (traditional) generalized forwarding: forward based on any set of header field values Longest prefix matchingwhen looking for forwarding table entry for given destination address, use longest address prefix that matches destination address. we’ll see why longest prefix matching is used shortly, when we study addressing longest prefix matching: often performed using ternary content addressable memories (TCAMs) content addressable: present address to TCAM: retrieve address in one clock cycle, regardless of table size Cisco Catalyst: can up ~1M routing table entries in TCAM Switching fabricstransfer packet from input buffer to appropriate output buffer switching rate: rate at which packets can be transfer from inputs to outputs often measured as multiple of input/output line rate N inputs: switching rate N times line rate desirable three types of switching fabrics memory first generation routers: traditional computers with switching under direct control of CPU packet copied to system’s memory speed limited by memory bandwidth (2 bus crossings per datagram) bus datagram from input port memory to output port memory via a shared bus bus contention: switching speed limited by bus bandwidth 32 Gbps bus, Cisco 5600: sufficient speed for access and enterprise routers interconnection network overcome bus bandwidth limitations banyan networks, crossbar, other interconnection nets initially developed to connect processors in multiprocessor advanced design: fragmenting datagram into fixed length cells, switch cells through the fabric. Cisco 12000: switches 60 Gbps through the interconnection network Input port queuingfabric slower than input ports combined -&gt; queueing may occur at input queues queueing delay and loss due to input buffer overflow! Head-of-the-Line (HOL) blocking: queued datagram at front of queue prevents others in queue from moving forward Output ports(This slide in HUGELY important!) buffering required when datagrams arrive from fabric faster than the transmission rate Datagram (packets) can be lost due to congestion, lack of buffers scheduling discipline chooses among queued datagrams for transmission Priority scheduling – who gets best performance, network neutrality Output port queueing buffering when arrival rate via switch exceeds output line speed queueing (delay) and loss due to output port buffer overflow! How much buffering RFC 3439 rule of thumb: average buffering equal to “typical” RTT (say 250 msec) times link capacity C e.g., C = 10 Gpbs link: 2.5 Gbit buffer recent recommendation: with N flows, buffering equal to \\frac{RTT * C}{\\sqrt{N}}Scheduling mechanismsscheduling: choose next packet to send on link FIFO (first in first out) scheduling: send in order of arrival to queue real-world example? discard policy: if packet arrives to full queue: who to discard? tail drop: drop arriving packet priority: drop/remove on priority basis random: drop/remove randomly Scheduling policies priority scheduling: send highest priority queued packet multiple classes, with different priorities class may depend on marking or other header info, e.g. IP source/dest, port numbers, etc. real world example? Round Robin (RR) scheduling: multiple classes cyclically scan class queues, sending one complete packet from each class (if available) real world example? Weighted Fair Queuing (WFQ): generalized Round Robin each class gets weighted amount of service in each cycle real-world example? IP: Internet Protocolhost, router network layer functions: IP datagram format IP fragmentation, reassembly network links have MTU (max.transfer size) - largest possible link-level frame different link types, different MTUs large IP datagram divided (“fragmented”) within net one datagram becomes several datagrams “reassembled” only at final destination IP header bits used to identify, order related fragments example: 4000 byte datagram MTU = 1500 bytes IP addressingIP address: 32-bit identifier for host, router interface interface: connection between host/router and physical link router’s typically have multiple interfaces host typically has one or two interfaces (e.g., wired Ethernet, wireless 802.11) IP addresses associated with each interface Q: how are interfaces actually connected? A: we’ll learn about that in chapter 5, 6. A: wired Ethernet interfaces connected by Ethernet switches A: wireless WiFi interfaces connected by WiFi base station For now: don’t need to worry about how one interface is connected to another (with no intervening router) Subnets IP address: subnet part - high order bits host part - low order bits what’s a subnet? device interfaces with same subnet part of IP address can physically reach each other without intervening router to determine the subnets, detach each interface from its host or router, creating islands of isolated networks each isolated network is called a subnet CIDR CIDR: Classless InterDomain Routing subnet portion of address of arbitrary length address format: a.b.c.d/x, where x is # bits in subnet portion of address Q: How does a host get IP address? hard-coded by system admin in a file Windows: control-panel-&gt;network-&gt;configuration-&gt;tcp/ip-&gt;properties UNIX: /etc/rc.config DHCP: Dynamic Host Configuration Protocol dynamically get address from as server “plug-and-play” DHCP: Dynamic Host Configuration Protocol goal: allow host to dynamically obtain its IP address from network server when it joins network can renew its lease on address in use allows reuse of addresses (only hold address while connected/“on”) support for mobile users who want to join network (more shortly) DHCP overview: host broadcasts “DHCP discover” msg [optional] DHCP server responds with “DHCP offer” msg [optional] host requests IP address: “DHCP request” msg DHCP server sends address: “DHCP ack” msg DHCP can return more than just allocated IP address on subnet: address of first-hop router for client name and IP address of DNS sever network mask (indicating network versus host portion of address) Hierarchical addressing: route aggregation Q: how does network get subnet part of IP addr? A: gets allocated portion of its provider ISP’s address space hierarchical addressing allows efficient advertisement of routinginformation: ISPs-R-Us has a more specific route to Organization 1 Q: how does an ISP get block of addresses? A: ICANN: Internet Corporation for Assigned Names and Numbers http://www.icann.org/ allocates addresses manages DNS assigns domain names, resolves disputes NAT: network address translation motivation: local network uses just one IP address as far as outside world is concerned: range of addresses not needed from ISP: just one IP address for all devices can change addresses of devices in local network without notifying outside world can change ISP without changing addresses of devices in local network devices inside local net not explicitly addressable, visible by outside world (a security plus) implementation: NAT router outgoing datagrams: replace(source IP address, port #) of every outgoing datagram to (NAT IP address, new port #) remote clients/servers will respond using (NAT IP address, new port #) as destination addr remember (in NAT translation table) every (source IP address, port #) to (NAT IP address, new port #) translation pair incoming datagrams: replace (NAT IP address, new port #) in dest fields of every incoming datagram with corresponding (source IP address, port #) stored in NAT table 16-bit port-number field: 60,000 simultaneous connections with a single LAN-side address! NAT is controversial: routers should only process up to layer 3 address shortage should be solved by IPv6 violates end-to-end argument NAT possibility must be taken into account by app designers, e.g., P2P applications NAT traversal: what if client wants to connect to server behind NAT? IPv6initial motivation: 32-bit address space soon to be completely allocated. additional motivation: header format helps speed processing/forwarding header changes to facilitate QoS IPv6 datagram format: fixed-length 40 byte header no fragmentation allowed priority: identify priority among datagrams in flow flow Label: identify datagrams in same “flow.” (concept of“flow” not well defined). next header: identify upper layer protocol for data Other changes from IPv4 checksum: removed entirely to reduce processing time at each hop options: allowed, but outside of header, indicated by “Next Header” field ICMPv6: new version of ICMP additional message types, e.g. “Packet Too Big” multicast group management functions Transition from IPv4 to IPv6 not all routers can be upgraded simultaneously no “flag days” how will network operate with mixed IPv4 and IPv6 routers? tunneling: IPv6 datagram carried as payload in IPv4 datagram among IPv4 routers IPv6 adoption Google: 8% of clients access services via IPv6 NIST: 1/3 of all US government domains are IPv6 capable Long (long!) time for deployment, use 20 years and counting! think of application-level changes in last 20 years: WWW, Facebook, streaming media, Skype, … Generalized Forwarding and SDNEach router contains a flow table that is computed and distributed by a logically centralized routing controller OpenFlow data plane abstraction flow: defined by header fields generalized forwarding: simple packet-handling rules Pattern: match values in packet header fields Actions: for matched packet: drop, forward, modify, matched packet or send matched packet to controller Priority: disambiguate overlapping patterns Counters: #bytes and #packets Flow table in a router (computed and distributed by controller) define router’s match+action rules src=1.2.., dest=3.4.5.* -&gt; drop src = ..., dest=3.4.. -&gt; forward(2) src=10.1.2.3, dest=... -&gt; send to controller Flow Table Entries OpenFlow abstraction match+action: unifies different kinds of devices Router match: longest destination IP prefix action: forward out a link Switch match: destination MAC address action: forward or flood Firewall match: IP addresses and TCP/UDP port numbers action: permit or deny NAT match: IP address and port action: rewrite address and port Example: datagrams from hosts h5 and h6 should be sent to h3 or h4, via s1 and from there to s2 Control planeRouting protocolsRouting protocol goal: determine “good” paths (equivalently, routes), from sending hosts to receiving host, through network of routers path: sequence of routers packets will traverse in going from given initial source host to given final destination host “good”: least “cost”, “fastest”, “least congested” routing: a “top-10” networking challenge! Graph abstraction of the network graph: G = (N,E) N = set of routers = { u, v, w, x, y, z } E = set of links ={ (u,v), (u,x), (v,x), (v,w), (x,w), (x,y), (w,y), (w,z), (y,z) } aside: graph abstraction is useful in other network contexts, e.g.,P2P, where N is set of peers and E is set of TCP connections costs c(x,x’) = cost of link (x,x’); e.g., c(w,z) = 5 cost could always be 1, or inversely related to bandwidth, or inversely related to congestion key question: what is the least-cost path between u and z ? routing algorithm: algorithm that finds that least cost path Routing algorithm classification Q: global or decentralized information? global: all routers have complete topology, link cost info “link state” algorithms decentralized: router knows physically-connected neighbors, link costs to neighbors iterative process of computation, exchange of info with neighbors “distance vector” algorithms Q: static or dynamic? static: routes change slowly over time dynamic: routes change more quickly periodic update in response to link cost changes link stateA link-state routing algorithm Dijkstra’s algorithm net topology, link costs known to all nodes accomplished via “link state broadcast” all nodes have same info computes least cost paths from one node (‘source”) to all other nodes gives forwarding table for that node iterative: after k iterations, know least cost path to k dest.’s notation: c(x,y): link cost from node x to y; = ∞ if not direct neighbors D(v): current value of cost of path from source to dest. v p(v): predecessor node along path from source to v N’: set of nodes whose least cost path definitively known 1234567891011121314151 Initialization: 2 N&apos; = &#123;u&#125; 3 for all nodes v 4 if v adjacent to u 5 then D(v) = c(u,v) 6 else D(v) = ∞ 7 8 Loop 9 find w not in N&apos; such that D(w) is a minimum 10 add w to N&apos; 11 update D(v) for all v adjacent to w and not in N&apos; : 12 D(v) = min( D(v), D(w) + c(w,v) ) 13 /* new cost to v is either old cost to v or known 14 shortest path cost to w plus cost from w to v */ 15 until all nodes in N&apos; Dijkstra’s algorithm example notes: construct shortest path tree by tracing predecessor nodes ties can exist (can be broken arbitrarily) Dijkstra’s algorithm discussion algorithm complexity: n nodes each iteration: need to check all nodes, w, not in N n(n+1)/2 comparisons: O(n2) more efficient implementations possible: O(nlogn) oscillations possible: e.g., support link cost equals amount of carried traffic: Distance vector algorithmBellman-Ford equation (dynamic programming) min taken over all neighbors v of x c(x,v): cost to neighbor v dv(y): cost from neighbor v to destination y 1234let dx(y) := cost of least-cost path from x to ythen dx(y) = min &#123;c(x,v) + dv(y)&#125; Bellman-Ford example node achieving minimum is next hop in shortest path, used in forwarding table Dx(y) = estimate of least cost from x to y x maintains distance vector Dx = [Dx(y): y є N ] node x: knows cost to each neighbor v: c(x,v) maintains its neighbors’ distance vectors. For each neighbor v, x maintains Dv = [Dv(y): y є N ] key idea: from time-to-time, each node sends its own distance vector estimate to neighbors when x receives new DV estimate from neighbor, it updates its own DV using B-F equation: D_x(y) ← min_v{c(x,v) + D_v(y)} for each node y \\in N under minor, natural conditions, the estimate Dx(y) converge to the actual least cost dx(y) iterative, asynchronous: each local iteration caused by: local link cost change DV update message from neighbor distributed: each node notifies neighbors only when its DV changes neighbors then notify their neighbors if necessary Distance vector: link cost changes link cost changes: node detects local link cost change updates routing info, recalculates distance vector if DV changes, notify neighbors “good news travels fast” 12345t0 : y detects link-cost change, updates its DV, informs its neighbors.t1 : z receives update from y, updates its table, computes new least cost to x , sends its neighbors its DV.t2 : y receives z’s update, updates its distance table. y’s least costs do not change, so y does not send a message to z. bad news travels slow - “count to infinity” problem! 44 iterations before algorithm stabilizes: see text poisoned reverse: If Z routes through Y to get to X : Z tells Y its (Z’s) distance to X is infinite (so Y won’t route to X via Z) will this completely solve count to infinity problem? Comparison of LS and DV algorithmsmessage complexity LS: with n nodes, E links, O(nE) msgs sent DV: exchange between neighbors only convergence time varies speed of convergence LS: O(n^2) algorithm requires O(nE) msgs may have oscillations DV: convergence time varies may be routing loops count-to-infinity problem robustness: what happens if router malfunctions? LS: node can advertise incorrect link cost each node computes only its own table DV: DV node can advertise incorrect path cost each node’s table used by others error propagate thru network intra-AS routing in the Internet: OSPFMaking routing scalable our routing study thus far - idealized all routers identical network “flat” … not true in practice scale: with billions of destinations: can’t store all destinations in routing tables! routing table exchange would swamp links! administrative autonomy internet = network of networks each network admin may want to control routing in its own network Internet approach to scalable routing aggregate routers into regions known as “autonomous systems” (AS) (a.k.a. “domains”) intra-AS routing routing among hosts, routers in same AS (“network”) all routers in AS must run same intra-domain protocol routers in different AS can run different intra-domain routing protocol gateway router: at “edge” of its own AS, has link(s) to router(s) in other AS’es inter-AS routing routing among AS’es gateways perform inter-domain routing (as well as intra-domain routing) Interconnected ASes forwarding table configured by both intra- and inter-AS routing algorithm intra-AS routing determine entries for destinations within AS inter-AS &amp; intra-AS determine entries for external destinations Inter-AS tasks： suppose router in AS1 receives datagram destined outside of AS1: router should forward packet to gateway router, but which one? AS1 must: learn which dests are reachable through AS2, which through AS3 propagate this reachability info to all routers in AS1 job of inter-AS routing! Intra-AS Routing: also known as interior gateway protocols (IGP) most common intra-AS routing protocols: RIP: Routing Information Protocol OSPF: Open Shortest Path First (IS-IS protocol essentially same as OSPF) IGRP: Interior Gateway Routing Protocol (Cisco proprietary for decades, until 2016) OSPF (Open Shortest Path First) “open”: publicly available uses link-state algorithm link state packet dissemination topology map at each node route computation using Dijkstra’s algorithm router floods OSPF link-state advertisements to all other routers in entire AS carried in OSPF messages directly over IP (rather than TCP or UDP) link state: for each attached link IS-IS routing protocol: nearly identical to OSPF OSPF “advanced” features: security: all OSPF messages authenticated (to prevent malicious intrusion) multiple same-cost paths allowed (only one path in RIP) for each link, multiple cost metrics for different TOS (e.g., satellite link cost set low for best effort ToS; high for real-time ToS) integrated uni- and multi-cast support: Multicast OSPF (MOSPF) uses same topology data base as OSPF hierarchical OSPF in large domains. Hierarchical OSPF: two-level hierarchy: local area, backbone. link-state advertisements only in area each nodes has detailed area topology; only know direction (shortest path) to nets in other areas. area border routers: “summarize” distances to nets in own area, advertise to other Area Border routers. backbone routers: run OSPF routing limited to backbone. boundary routers: connect to other AS’es. routing among the ISPs: BGPInternet inter-AS routing: BGP BGP (Border Gateway Protocol): the de facto inter-domain routing protocol “glue that holds the Internet together” BGP provides each AS a means to: eBGP: obtain subnet reachability information from neighboring ASes iBGP: propagate reachability information to all AS-internal routers. determine “good” routes to other networks based on reachability information and policy allows subnet to advertise its existence to rest of Internet: “I am here” eBGP, iBGP connections BGP basics BGP session: two BGP routers (“peers”) exchange BGP messages over semi-permanent TCP connection: advertising paths to different destination network prefixes (BGP is a “path vector” protocol) when AS3 gateway router 3a advertises path AS3,X to AS2 gateway router 2c: AS3 promises to AS2 it will forward datagrams towards X Path attributes and BGP routes advertised prefix includes BGP attributes prefix + attributes = “route” two important attributes: AS-PATH: list of ASes through which prefix advertisement has passed NEXT-HOP: indicates specific internal-AS router to next-hop AS Policy-based routing: gateway receiving route advertisement uses import policy to accept/decline path (e.g., never route through AS Y). AS policy also determines whether to advertise path to other neighboring ASes BGP path advertisement AS2 router 2c receives path advertisement AS3,X (via eBGP) from AS3 router 3a Based on AS2 policy, AS2 router 2c accepts path AS3,X, propagates (via iBGP) to all AS2 routers Based on AS2 policy, AS2 router 2a advertises (via eBGP) path AS2, AS3, X to AS1 router 1c gateway router may learn about multiple paths to destination: AS1 gateway router 1c learns path AS2,AS3,X from 2a AS1 gateway router 1c learns path AS3,X from 3a Based on policy, AS1 gateway router 1c chooses path AS3,X, and advertises path within AS1 via iBGP BGP messages BGP messages exchanged between peers over TCP connection BGP messages: OPEN: opens TCP connection to remote BGP peer and authenticates sending BGP peer UPDATE: advertises new path (or withdraws old) KEEPALIVE: keeps connection alive in absence of UPDATES; also ACKs OPEN request NOTIFICATION: reports errors in previous msg; also used to close connection BGP route selection router may learn about more than one route to destination AS, selects route based on: local preference value attribute: policy decision shortest AS-PATH closest NEXT-HOP router: hot potato routing additional criteria Hot Potato Routing 2d learns (via iBGP) it can route to X via 2a or 2c hot potato routing: choose local gateway that has least intra-domain cost (e.g., 2d chooses 2a, even though more AS hops to X): don’t worry about inter-domain cost! BGP: achieving policy via advertisements A advertises path A w to B and to C B chooses not to advertise BAw to C: B gets no “revenue” for routing CBAw, since none of C, A, w are B’s customers C does not learn about CBAw path C will route CAw (not using B) to get to w A,B,C are provider networks X,W,Y are customer (of provider networks) X is dual-homed: attached to two networks policy to enforce: X does not want to route from B to C via X .. so X will not advertise to B a route to C Why different Intra-, Inter-AS routing ? policy: inter-AS: admin wants control over how its traffic routed, who routes through its net. intra-AS: single admin, so no policy decisions needed scale: hierarchical routing saves table size, reduced update traffic performance: intra-AS: can focus on performance inter-AS: policy may dominate over performance The SDN control planeSoftware defined networking (SDN) Internet network layer: historically has been implemented via distributed, per-router approach monolithic router contains switching hardware, runs proprietary implementation of Internet standard protocols (IP, RIP, IS-IS, OSPF, BGP) in proprietary router OS (e.g., Cisco IOS) different “middleboxes” for different network layer functions: firewalls, load balancers, NAT boxes, .. ~2005: renewed interest in rethinking network control plane Why a logically centralized control plane? easier network management: avoid router misconfigurations, greater flexibility of traffic flows table-based forwarding (recall OpenFlow API) allows “programming” routers centralized “programming” easier: compute tables centrally and distribute distributed “programming: more difficult: compute tables as result of distributed algorithm (protocol) implemented in each and every router open (non-proprietary) implementation of control plane Traffic engineering: difficult traditional routing Q: what if network operator wants u-to-z traffic to flow along uvwz, x-to-z traffic to flow xwyz? A: need to define link weights so traffic routing algorithm computes routes accordingly (or need a new routing algorithm)! Link weights are only control “knobs”: wrong! Q: what if network operator wants to split u-to-z traffic along uvwz and uxyz (load balancing)? A: can’t do it (or need a new routing algorithm) Q: what if w wants to route blue and red traffic differently? A: can’t do it (with destination based forwarding, and LS, DV routing) SDN perspective Data plane switches fast, simple, commodity switches implementing generalized data-plane forwarding in hardware switch flow table computed, installed by controller API for table-based switch control (e.g., OpenFlow) defines what is controllable and what is not protocol for communicating with controller (e.g., OpenFlow) SDN controller (network OS): maintain network state information interacts with network control applications “above” via northbound API interacts with network switches “below” via southbound API implemented as distributed system for performance, scalability, fault-tolerance, robustness network-control apps: “brains” of control: implement control functions using lower-level services, API provided by SND controller unbundled: can be provided by 3rd party: distinct from routing vendor, or SDN controller Components of SDN controller OpenFlow protocol operates between controller, switch TCP used to exchange messages optional encryption three classes of OpenFlow messages: controller-to-switch asynchronous (switch to controller) symmetric (misc) controller-to-switch messages: Key controller-to-switch messages features: controller queries switch features, switch replies configure: controller queries/sets switch configuration parameters modify-state: add, delete, modify flow entries in the OpenFlow tables packet-out: controller can send this packet out of specific switch port packet-in: transfer packet (and its control) to controller. See packet-out message from controller flow-removed: flow table entry deleted at switch port status: inform controller of a change on a port. Fortunately, network operators don’t “program” switches by creating/sending OpenFlow messages directly. Instead use higher-level abstraction at controller control/data plane interaction example S1, experiencing link failure using OpenFlow port status message to notify controller SDN controller receives OpenFlow message, updates link status info Dijkstra’s routing algorithm application has previously registered to be called when ever link status changes. It is called. Dijkstra’s routing algorithm access network graph info, link state info in controller, computes new routes link state routing app interacts with flow-table-computation component in SDN controller, which computes new flow tables needed Controller uses OpenFlow to install new tables in switches that need updating OpenDaylight (ODL) controller ODL Lithium controller network apps may be contained within, or be external to SDN controller Service Abstraction Layer: interconnects internal, external applications and services ONOS controller control apps separate from controller intent framework: high-level specification of service: what rather than how considerable emphasis on distributed core: service reliability, replication performance scaling SDN: selected challenges hardening the control plane: dependable, reliable, performance-scalable, secure distributed system robustness to failures: leverage strong theory of reliable distributed system for control plane dependability, security: “baked in” from day one? networks, protocols meeting mission-specific requirements e.g., real-time, ultra-reliable, ultra-secure Internet-scaling ICMP: The Internet Control Message Protocol used by hosts &amp; routers to communicate network-level information error reporting: unreachable host, network, port, protocol echo request/reply (used by ping) network-layer “above” IP: ICMP msgs carried in IP datagrams ICMP message: type, code plus first 8 bytes of IP datagram causing error Traceroute and ICMP source sends series of UDP segments to destination first set has TTL =1 second set has TTL=2, etc. unlikely port number when datagram in nth set arrives to nth router: router discards datagram and sends source ICMP message (type 11, code 0)(TTL expired) ICMP message include name of router &amp; IP address when ICMP message arrives, source records RTTs stopping criteria: UDP segment eventually arrives at destination host destination returns ICMP “port unreachable” message (type 3, code 3) source stops Network management and SNMPWhat is network management? autonomous systems (aka “network”): 1000s of interacting hardware/software components other complex systems requiring monitoring, control: jet airplane nuclear power plant others? “Network management includes the deployment, integrationand coordination of the hardware, software, and humanelements to monitor, test, poll, configure, analyze, evaluate,and control the network and element resources to meet thereal-time, operational performance, and Quality of Servicerequirements at a reasonable cost.” Infrastructure for network management managed devices contain managed objects whose data is gathered into a Management Information Base (MIB) SNMP protocol: simple network management protocol Two ways to convey MIB info, commands: SNMP protocol: message types SNMP protocol: message formats SNMP_message_format.png","categories":[],"tags":[{"name":"computer network","slug":"computer-network","permalink":"https://chenfeng.github.io/tags/computer-network/"}]},{"title":"同步与互斥","slug":"parellel_and_distributed_computing/distributed_compute4","date":"2017-05-22T16:00:00.000Z","updated":"2017-05-26T09:28:18.000Z","comments":true,"path":"2017/05/23/parellel_and_distributed_computing/distributed_compute4/","link":"","permalink":"https://chenfeng.github.io/2017/05/23/parellel_and_distributed_computing/distributed_compute4/","excerpt":"(并行与分布式计算十二) 分布式系统中的资源管理管理方式 全集中管理方式：所有资源都由一个节点管理； 集中分布管理方式：一个资源由一个节点管理； 全分布管理方式：一个资源由多个节点共同管理。","text":"(并行与分布式计算十二) 分布式系统中的资源管理管理方式 全集中管理方式：所有资源都由一个节点管理； 集中分布管理方式：一个资源由一个节点管理； 全分布管理方式：一个资源由多个节点共同管理。 控制空间 说明资源管理分散程度的参数： 参加资源的多重管理的节点数； 被多个节点管理的资源数。 按参加多重管理的节点数排序 ： 控制方式 多个节点参加对同一资源进行控制的方式： 顺序方式：按某种顺序，先由一个节点控制一段时间，之后再由另一个节点控制一段时间。 分工方式：由不同的节点并发或顺序地控制同一资源执行不同的活动。 民主方式：所有节点共同协商一致对同一资源执行每个管理活动。 多重管理形式的分散性的参数 一致性是指由所有节点共同完成的对同一个资源管理的活动数目 均等性是各节点对同一资源进行某一控制活动时被分配的管理权限和责任的平等程度 参加每个活动的节点数目 单个资源的控制空间 五维控制空间 可以将单个资源控制空间和集体资源控制空间合并成一个五维空间, 方法是加上资源个数、控制程度 资源个数 控制程度 由所有节点共同完成的对同一个资源管理的活动数目(一致性) 各节点对同一资源进行某一控制活动时被分配的管理权限和责任的平等程度(均等性) 参加每个活动的节点数目 资源分配原则计算机与网络系统的四种体系结构 主机/终端 Host / Terminal 工作站/文件服务器 Workstation / File Server 客户机/服务器 Client / Server 对等计算 Peer-to-Peer 全集中管理方式 资源申请者总是向惟一的节点提出 节点按一定顺序处理每个申请 如果资源已经被分配则申请者等待 只要不发生死锁和占用资源者无限期占用资源的情况，任何申请者必定能在有限时间内获得资源 分布管理方式 集中分布方式 申请者先向一个节点提出申请，如果暂时不能获得资源就转向另一个节点申请 可能发生“饿死”现象 也有可能发生死锁 全分布方式 申请者向任一节点提出申请，节点共同协商分配资源 同步机构同步点: 同步点是为了达到进程间同步而设立的执行控制点 特征：到达这些控制点时，一个进程在另一个进程执行完某一活动前不能继续执行 目的：让分解并分布到各个节点的任务能够在节点的协同合作下正确地解决任务间的数据依赖问题；否则的话，没有控制的超前或落后会导致数据的不一致和计算的错误 两类共享资源 一类是各进程可以同时访问的，如中央处理机(允许多个进程交叠使用一个处理机)、只读文件和不允许修改的存放子程序和数据的主存区域等 另一类是不允许多个进程同时访问的，每次只允许一个进程使用，如大多数外部设备(如打印机)、可写的文件以及主存中可修改的区域等。同步机构在互斥控制中的作用是对活动的执行进行排序 一致状态 一个计算系统应该在所有时间内满足一定的外部规定或约束 如果一个计算系统确实在所有时间内满足了一定的外部规定或约束，这时我们称系统状态是一致的 同步机构的目的就是给进程提供某种手段，使系统保持一致状态。 三种分布式计算方式 完全复制的计算：任何操作所激发的每个活动必须由所有的消费者共同处理，要求所有的活动均应完成 完全分割的计算：一个操作所激发的不同活动由不同的消费者分别独自处理 分割和部分复制的计算：一个操作所激发的活动中，某些是由不同的消费者独自处理的，某些操作是由一些消费者共同处理。它兼有前面两种计算形式的特点 同步机构在不同计算方式中的目的 完全复制的计算：同步机构的目的是保证消费者处理活动的次序必须相同 完全分割的计算：同步机构的目的是保证所有相互干扰的活动成为有序的，使得该操作保持原子性(要么完成操作，要么干脆不发生) 分割和部分复制的计算：同步机构的目的兼有保证次序和保证操作的原子性。对于不同的计算方式，同步机构的目的也是不完全相同的。 评价同步机构的标准 响应时间和吞吐量。各种机构应尽量利用系统的并行性质，以提高吞吐量和缩短响应时间。 恢复能力。同步机构应能使系统从故障中恢复过来。 开销。指使用同步机构的代价，包括额外增加的报文长度、数量和对它们的处理时间，以及用于存放同步信息所需的额外存储空间。 公平性。操作发生冲突时，同步机构应能避免生产者饿死，各生产者具有平等的权利。 可扩充性。系统扩充新的处理机时同步机构应不影响其正常运行。 连接方式。使用某些同步机构要求生产者在逻辑上全部互连，这样所产生的开销可能很大；有些同步机构只要求一个生产者知道其邻居的情况，开销也较少。 初始化。使用同步机构要求系统应容易进行初始化，知道进程何时可以进行生产和消费活动。 排序方法。当生产者对一序列操作进行某种指定排序时，必须交换报文，各种同步机构实现效率可能大不相同。 同步实体物理时钟、事件计数器、逻辑时钟、循环令牌和顺序器、进程、其它 集中式和分布式同步机构 在集中式同步机构中，每个生产者每次发动一个操作时均要访问该同步实体。集中式同步实体有一个为所有必须相互同步的进程都知道的名字，任何时候这些进程的任何一个均可访问这一同步实体。执行每个功能如进程调度、数据访问控制等均要经过集中的同步实体进行控制 。 分布式同步机构不存在一个集中的同步实体，执行各种功能时是分散控制的。 集中式同步机构和分布式同步机构的优缺点 集中式同步机构最大的缺点是不可靠，一旦出故障就可能造成全局不工作；另外在性能方面也大大下降，因为集中会产生一个瓶颈。但实现简单。 分布式同步机构在可靠性和性能方面优于集中式同步机构，也有很多种，主要有多重物理时钟、多重逻辑时钟、循环令牌等。但实现复杂。 同步机构：物理时钟 物理时钟需要从UTC(Universal Tim Coordinator)获得当前时间。UTC提供当前国际标准时间，有两个著名站点WWV和GEOS。 物理时钟的同步过程： A通过网络向B发送请求； B读取本地时钟值； B的时钟值通过网络传递给A； 按照网络所需的传输延迟对B的时钟值进行校正； 比较A的时钟值和B的时钟值。 物理时钟的同步方式：集中式、分布式。 集中式物理时钟 集中式物理时钟的实现方式：基于广播的方式、请求驱动的方式。 在基于广播的集中式物理时钟的实现方案中，集中的时钟服务员节点定期地向系统中的各个成员广播当前的时间。 在请求驱动的集中式物理时钟的实现方案中，顾客节点向时间服务员节点发送请求，并根据时间服务员节点发回的时间来校正自己的物理时钟。 基于广播的方式1： 原理：顾客只是简单地将本地时间同所接收到的时间进行对比，当然这种对比考虑到了通常的网络传输延迟，然后校正自己的本地时钟。 时间校正方法： 如果顾客的时钟值大于时钟服务员节点的时钟值，顾客将自己的时钟调慢，使之逐渐接近准确的时间。时钟值不能往回调，因为映像到此时钟的事件已经产生。 如果顾客的时钟值落后于时钟服务员节点的时钟值，则顾客将时钟值向前拨，同时将时钟适当地调快。 基于广播的方式1时间校正方法: 基于广播的方式2（Berkeley算法）： 顾客收到广播时间之后向集中的时间服务员节点发送它本地的当前时间值； 每个顾客到时间服务员节点有不同的平均延迟，这些延迟时间预先存放在时间节点处。时间服务员节点根据这些延迟对不同顾客传送来的当地时间进行校正； 任何校正过的时间如果同时间服务员节点上的时间差值超过了对应节点到时间节点的延迟时间常量，那么这个时间将不被列入考虑之列。因为这个时间可能是由于系统故障导致的，被认为是不准确的。 剩余被校正的时间值连同时间服务员节点上的时间值一起进行平均，这个平均值作为当前时间。 时间服务员节点为每个顾客计算误差，然后将每个误差发送给对应的顾客。 每个顾客校正自己的时钟。同前一个处理方式一样，时钟是不能往回拨的，但是可以按误差值将自己的时钟慢下来。 基于广播的方式2（Berkeley算法）： 请求驱动方式： 顾客向时间节点发送请求，要求获得当前时间； 时间节点返回当前时间值； 顾客计算本地的时间值和节点返回的时间值之间的差值，这个差值用于时钟值的校正；它的实现不仅考虑了网络延迟，还包含了报文的响应和服务时间； 如果校正值大于预先规定好的门限值，则被认为是不准确的，这可能是由于网络故障引起的，不准确的值被丢弃； 如果节点返回的时间值被认为是准确的，则对本地时钟进行校正，同样地，本地时钟不能往回拨，只能使本地时钟慢下来。 请求驱动方式： 分布式物理时钟 每个节点计算机以预先定义好的时间间隔定期地广播它的当前时间。 由于时钟存在漂移，假定广播报文并不是很准确地在同一时刻发出。 一旦一个节点广播了它的当前时间，就立即启动一个定时器，在定时期内接收其它节点的报文，每个报文标明了当地的当前时间，然后分别按对应的网络延迟对其它节点的时间值进行校正。 分布式物理时钟时间校正方式： 计算所有节点的平均值，把这个值作为当前时间。这种方法可能会产生不准确的结果，因为某些报文由于重发超出了通常的网络延迟。 设定一个容错门限延迟，这个门限为单次发送的最大网络延迟，任何超过这个门限延迟的值被认为是错误的并被丢弃。其他未被丢弃的值进行平均，平均值作为当前时间。 丢弃m个最大的时间值和m个最小的时间值，这些值被认为是不准确的。剩下的进行平均，平均值作为当前时间。 同步机构：逻辑时钟逻辑时钟可以给分布计算系统中的事件一个唯一的排序。逻辑时钟的本质是基于Lamport定义的因果优先关系: 如果a和b均是同一进程中的两个事件，并且a在b之前出现，则a→b； 若a代表“一个进程发送一个报文（消息）”这个事件，b代表“另一个进程接收这个报文”这个事件，则a→b； 如果a→b，且b→c，则a→c。 两个不同的事件a和b，如果a→b，或b→a，则事件a和b是因果关联的。如果a→b和b→a均不成立，则称事件a和b是并发的。 因果优先关系的时空图：水平方向代表空间，垂直方向代表时间，圆点代表事件，竖线代表进程，进程之间带箭头的线代表报文（消息） 设Ci代表进程i的逻辑时钟，该逻辑时钟就是一个函数，它给进程i中的事件a分配一个正整数值$C_i(a)$。 时钟条件： 对任何事件a和b，如果a→b，则C(a)&lt;C(b)。但相反的结论不能成立。 若a和b是同一进程$P_i$中的两个时间，并且a→b，则$C_i(a) &lt; C_i(b)$； 若a代表“一个Pi进程发送一个报文”这个事件，b代表“另一个进程$P_j$接收这个报文”这个事件，$C_i(a)&lt;C_j(b)$。 每个进程Pi有一个逻辑时钟$LC_i$，$LC_i$被初始化为init(init≥0)并且它是一个非减的整数序列。进程$P_i$发送的每个报文m都被标上$LC_i$的当前值和进程的标号i，从而形成一个三元组$(m,LC_i,i)$。任何一个逻辑时钟$LC_i$基于以下两条规则更新它的逻辑时钟值： 当发生一个事件(一个外部发送或内部事件)之前，我们更新$LC_i： LC_i:=LC_i+d (d&gt;0)$ 当收到一个带时间戳的报文$(m,LC_j,j)$时，我们更新$LC_i： LC_i:=max(LC_i,LC_j)+d (d&gt;0)$ 标量逻辑时钟 向量逻辑时钟 因果优先关系：a→b &lt;-&gt; $LC_i &lt; LC_j$ 并发关系： a‖b &lt;-&gt; $LC_i‖LC_j$ 同步机构：全局状态定义：分布式系统的全局状态是其各组成部件的本地状态的集合，包括各个处理器状态和所有通信信道状态 分类： 处理器状态：寄存器状态、堆栈状态、本地内存状态等，依赖于分布式应用的本地语义 通信信道状态：由信道中传输的消息集合给出 见分布式计算的概念和模型 全局状态的获取（快照算法）： 假如启动算法的进程为P，那么它首先记录自己的局部状态，然后它沿着它的输出通道发送一个标志(marker)，指示接收者应该参与记录一个全局状态的工作。 当接收者Q通过它的输入通道C收到一个标志，它将依据不同条件执行以下不同操作： 如果Q还没有记录自己的局部状态，它首先记录自己的局部状态，并记录通道C的状态为空报文序列，然后也沿着它自己的输出通道发送一个标志。 如果Q已经记录了自己的局部状态，通过通道C收到的标志用来指示Q应该记录通道的状态。通道的状态是Q记录它的局部状态以来到收到这个标志前所收到的报文系列。 如果一个进程已经沿它的每个输入通道接收到一个标志，并对每个标志进行了处理，就称它已经完成了它的那部分算法。 一个进程的局部状态，连同它的所有输入通道的状态将被发送到这个快照的发起进程。 P1启动了快照算法，它同时执行三个动作： (a)记录局部状态； (b)发送一个标志到C12和C13； (c)设置一个计数器对来自输入通道C21和C31的报文进行计数 一旦进程P2从通道C12接收到标志，它也执行三个动作： (a)记录其局部状态并记录通道C12的状态为空； (b)发送一个标志到通道C21和C23； (c)设置一个计数器对来自输入通道C32的报文进行计数。 类似地，进程P3也执行三个动作。 我们假定从进程P1来的标志比从进程P3来的标志早到达进程P2。 一旦从进程P3来的标志到达进程P2，P2就记录通道C32的状态为自设置计数器以来沿着这个通道接收到的报文的序列。于是进程P2完成了自己的那部分算法，因为它已经从每个输入通道接收到一个标志并已经记录了自己的局部状态。 类似地，进程P3在接收到从P1和P2发来的标志后，属于它的那部分算法终止。进程P1在接收到从P2和P3发来的标志后，属于它的那部分算法终止。 互斥算法衡量互斥算法性能的参数： 完成一次互斥操作所需的报文数目； 同步延迟，即从一个进程离开临界区之后到下一个进程进入临界区之前的时间间隔； 响应时间，即从一个进程发出请求到该进程离开该临界区之间的时间间隔。 互斥算法：集中式方法 Lamport时间戳互斥算法 Lamport时间戳互斥算法由以下5条规则组成 ： 一个进程Pi如果为了申请资源，它向其它各个进程发送具有时间戳Tm:Pi的申请资源的报文，并把此报文也放到自己的申请队列中； 一个进程Pj如果收到具有时间戳Tm:Pi的申请资源的报文，它把此报文放到自己的申请队列中，并将向Pi发送一个带有时间戳的承认报文。如果Pj正在临界区或正在发送自己的申请报文，则此承认报文要等到Pj从临界区中退出之后或Pj发送完自己的申请报文之后再发送，否则立即发送； 一个进程Pi如果想释放资源，它先从自己的申请队列中删除对应的Tm:Pi申请报文，并向所有其他进程发送具有时间戳的Pi释放资源的报文； 一个进程Pj如果收到Pi释放资源的报文，它从自己的申请队列中删除Tm:Pi申请报文； 当满足下述两个条件时，申请资源的进程Pi获得资源： Pi的申请队列中有Tm:Pi申请报文，并且根据时间戳它排在所有其它进程发来的申请报文前面； Pi收到所有其它进程的承认报文，其上面的时间戳值大于Tm。 Ricart-Agrawala互斥算法 一个进程申请资源时向所有其他进程发出申请报文； 其它进程收到申请报文后若不在临界区并且自己未申请进入临界区，或者自己虽然发出了申请报文，但自己的报文排在收到的申请报文之后，则回答表示同意； 申请资源的进程仅在收到所有进程的回答报文后才进入临界区使用资源； 一个进程使用完资源后，它向所有未给回答的其它申请发送回答报文。 Maekawa互斥算法 请求子集：在Maekawa互斥算法中，一个进程P在发出申请报文后，不用得到所有其他进程的回答，而只须得到一个进程子集S中的所有进程的回答即可进入临界区。称S是P的请求子集。假设Ri和Rj分别是进程Pi和Pj的请求子集，要求$R_i \\bigcap R_j \\not= NULL$。 当进程Pi请求进入临界区时，它只向Ri中的进程发送请求报文。 当进程Pj收到一个请求报文时，如果它自上一次临界区释放后还没有发出过回答报文给任何进程，且自己的请求队列中无任何请求，它就给该请求报文一个回答。否则，请求报文被放入请求队列中。 进程Pi只有收到Ri中的所有进程的回答后，才能进入临界区。 在释放临界区时，进程Pi只给Ri中的所有进程发送释放报文。 考虑一个七个进程的例子，每个进程的请求子集如下：1234567R1：&#123;P1，P3，P4&#125;；R2：&#123;P2，P4，P5&#125;； R3：&#123;P3，P5，P6&#125;； R4：&#123;P4，P6，P7&#125;；R5：&#123;P5，P7，P1&#125;；R6：&#123;P6，P1，P2&#125;；R7：&#123;P7，P2，P3&#125;。 Maekawa算法的两个极端情况： (1) 退化为集中式互斥算法。$P_c(c \\in {1, 2, …, n})$作为协调者，对所有进程Pi，有：Ri：{$P_c$}，1≤i≤n (2) 完全分布式的互斥算法。对所有进程Pi，有：Ri：{P1，P2，…，Pn}，1≤i≤n 简单令牌环互斥算法 在有n个进程的系统中，将这n个进程组成一个首尾相连的逻辑环。每个进程在环中有一个指定的位置，位置可以按网络地址进行排列，当然也可以采用任何其他可行的方式排列，但每个进程必须知道在环中哪个进程是它后面的进程。 一个进程拥有令牌时就可以进入临界区，令牌可在所有的进程间传递。 如果得到令牌的进程不打算进入临界区，它只是简单地将令牌传送给它后面的进程。 问题： 如果令牌丢失，需要重新产生一个令牌，但检测令牌是否丢失是比较困难的。 另外一个问题是进程的崩溃，但进程的崩溃比较容易检测。 这个算法在高负载的情况下工作得很好。然而，它在轻负载的情况下工作得很差，出现很多不必要的报文传递。 Ricart-Agrawala令牌环互斥算法 初始时，令牌被赋予给任何一个进程。 请求进入临界区的进程Pj不知道哪个进程拥有令牌，所以它向所有其它进程发送一个带时间戳的请求报文，请求得到令牌。每个进程有一个请求队列记录有所有进程的请求，令牌中记录有每个进程最后一个持有令牌的时间。 如果当前拥有令牌的进程Pi不再需要令牌，它就按照i+1，i+2，…，n，1，2，…，i-1的顺序寻找第一个符合条件的进程Pj，并将令牌传递给进程Pj。 说明：虽然该算法不是按照每个请求的时间顺序来满足的，但是，由于令牌是按一个方向绕环传递的，所以不会有饿死现象发生。 基于时间戳的令牌互斥算法 每个进程保持一张进程状态表，记录它所知的进程状态，进程状态包括该进程是否为请求进程，以及得到该状态的时间。令牌是一个特殊的报文，该报文中包含了发送该令牌的进程的进程状态表。 初始化时，每个进程的状态表中各个进程均为非请求状态，时钟值为0，并任意指定一个进程为令牌的持有者。 请求时，一个进程请求进入临界区时，如果它持有令牌，它不发送任何请求报文，将自己的进程状态表中相应于自己一栏的状态改为请求态，并记录该状态的时钟值，直接进入临界区。如果它不持有令牌，则它向所有其它进程发送带有时间戳的请求报文。发出请求报文后，将自己的进程状态表中相应于自己一栏的状态改为请求态，并记录该状态的时钟值。 收到请求时，当进程A收到进程B的请求报文时，A将B的请求报文中的时间戳同A的进程状态表中B的时间值进行比较。若B的请求报文中的时间戳大于A的进程状态表中B的时间值，则A修改自己的进程状态表。将A的进程状态表中对应于B的一栏改为请求状态，并记录此状态的时间。 退出临界区时，进程A退出临界区后，将自己的进程状态表中关于自己的一栏改为非请求状态，时钟值加1，并将该时钟值作为该状态的时间。然后检查其进程状态表中是否记录有某个进程处于请求状态，若有，则从处于请求状态的进程中选取一个请求最早的进程B(具有最小的时间戳)，将令牌传送给它，并在令牌中附上A的进程状态表。 收到令牌时，收到令牌的进程把随令牌传来的进程状态表和自己的进程状态表进行比较。若随令牌传来的进程状态表中某进程的时间戳大于自己的进程状态表中相应进程的时间戳，则将自己的进程状态表中相应进程的状态和时间戳该成随令牌传来的进程状态表中相应的状态和时间戳。 说明：同Ricart-Agrawala令牌环互斥算法相比，具有更强的公平性，因为它是基于请求的先后顺序来满足的，而Ricart-Agrawala令牌环互斥算法是基于进程的逻辑环结构来满足的。 Bully选举算法 从进程集中选出一个进程执行特别的任务。大部分选举算法是基于全局优先级的，就是说给每个进程预先分配一个优先级，选举算法选择一个具有最高优先级的进程作为协调者。 P发送选举报文到所有优先级比它高的进程。 如果在一定时间内收不到任何响应报文，P赢得选举成为协调者。它向所有比它的优先级低的进程发送通知报文，宣布自己是协调者。 如果收到一个优先级比它高的进程的回答，P的选举工作结束。同时启动一个计时器，等待接收谁是协调者的通知报文，如果在规定时间内得不到通知报文，则它重新启动选举算法。 任何时候，一个进程可能从比它的优先级低的进程那儿接收到一个选举报文，它就给发送者回答一个响应报文，同时启动如上所述的相同的选举算法，如果选举算法已经启动，就不必重新启动。 环选举算法 在环选举算法中，所有进程以任意的顺序排列在一个单向环上，每个进程知道环上的排列情况，任何进程在环上有一个后继进程。 任何一个进程发现协调者失效时，它创建一个选举报文，将自己的进程号加入该报文中作为一个候选协调者，并把该选举报文传递到它的后继进程。 收到该选举报文的后继进程，也将自己的进程号加入到该选举报文中作为一个候选协调者。如果发送者发现其后继者失效，它会将选举报文传送给后继者在环中的下一个进程，或沿环的方向可以寻找到的下一个运行的进程。 如果一个进程接收到自己所创建的选举报文，它将该报文的类型由选举报文改为协调者报文。 这个协调者报文再绕环一周，这个报文用于通知每个进程协调者是谁，组成新环的成员有那些。如果进程号大的进程具有高的优先级，那么具有最大进程号的进程就是协调者；","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"面向网络拓扑的通信优化","slug":"parellel_and_distributed_computing/distributed_compute3","date":"2017-05-15T16:00:00.000Z","updated":"2017-05-19T08:02:03.091Z","comments":true,"path":"2017/05/16/parellel_and_distributed_computing/distributed_compute3/","link":"","permalink":"https://chenfeng.github.io/2017/05/16/parellel_and_distributed_computing/distributed_compute3/","excerpt":"(并行与分布式计算十一) 最短路径问题研究范围: 有权图 有权图 通常对边与端附于一定权值，表示某种性质 权值：在不同实际问题中表示不同的物理意义, 例：距离、代价、费用、流量、容量、转接容量、电流、电位…… 最短路径问题 以有权图为基础，求解最短路径 目的：通信路由选择","text":"(并行与分布式计算十一) 最短路径问题研究范围: 有权图 有权图 通常对边与端附于一定权值，表示某种性质 权值：在不同实际问题中表示不同的物理意义, 例：距离、代价、费用、流量、容量、转接容量、电流、电位…… 最短路径问题 以有权图为基础，求解最短路径 目的：通信路由选择 最小生成树(MST, Minimum Spanning Tree) 给定连通图G=(V, E), w(e)是定义在E上的非负函数, $T=(V, E_r)$为G的一个生成树 定义树T的权为 $w(T) = \\sum_{e \\in E_r} w(e)$ MST问题：求生成树 $T^{}$，使得 $w(T^{})$ 最小。 应用 求连接n个城市之间的、通讯线路最短或造价最低的n-1条线路 多播和广播问题的通信优化 求最小生成树算法 Prim算法 : 反圈法(从点开始) Kruskal算法 : 避圈法(从边开始) 管梅谷破圈法 : (从圈开始) Prim算法(P算法) 将图的端点集合V分成A和V-A两部分 从图中任选一个端点$v_i$，令$A={v_i}$ 从A和V-A的连线中找出最短(权最小)边$e_{ij}=(v_i, v_j)$，令$A=A \\bigcup {v_j}$，并从V-A中去掉$v_j$ 重复上述过程，直至所有端点都在A中 Kruskal算法(K算法) Prim算法注意顶点，kruskal算法更关心边。 思想： 将所有边排序，然后由小到大选边，只要保持所选边不成圈，选了n-1条边后就可以证明形成一个最小生成树。 赋权的连通图G=(V,E)中$m=|E|,n=|V|$, S1:对E中各边的权排序，设$w_1 \\leq w_2 \\leq … \\leq w_m, w_i=w(e_i)$ S2:初始化：$w \\leftarrow 0,T \\leftarrow \\phi, k \\leftarrow 1,t \\leftarrow 0$ S3:若t=n-1则转S6，否则转S4 S4:若$T \\bigcup {e_k}$有圈则$k \\leftarrow k+1$转S4，否则转S5 S5: $T \\leftarrow T \\bigcup {e_k}, w \\leftarrow w+w_k, t \\leftarrow t+1, k \\leftarrow k+1$,转S3 S6:输出T及w，结束。 T为最小树，w为T的权。 网络流量问题 网的工作：把一定的业务流从源送出 网的控制：流量控制、路由控制、计费控制 流量：泛指传输速率 控制目标：流量最大(网运行的重要指标之一)、分配合理、提高效率、充分利用资源 特点：不任意性，受限于网络的拓扑结构，边和端的容量，流量分配和路由规划关系密切 优化问题：最大流，最小代价 有向图，单商品流问题(网络中只需要安排的只有一种商品或业务) 有向图G = {V, E}, $c{ij}$为边容量，$f{ij}$为边流量，${f{ij}}$为一组流，F为源宿之间${f{ij}}$的总流量 流满足两个条件： 非负、有界(对任意边): $0 \\leq f{i,j} \\leq c{i,j}$ 连续(对于任意端) \\sum_{(i,j)\\in E} f_{ij} = \\sum_{(j, i)\\in E} f_{ji} =\\begin{cases} F&\\text{$v_i$ 为源端}\\\\ -F&\\text{$v_i$ 为宿端}\\\\ 0& \\text{其他} \\end{cases}可行流的条件 具有m条(有向)边、n个端的图共有2m+n-1个限制条件，包括 m个非负性条件 m个有限性条件 n-1个连续性条件(连续性条件中有一个不是独立的) 满足此二限制条件的流称为可行流；可行流不止一个(流量为0也是一个可行流) v(f) = F 为源宿间流的总流量 需要解决的基本问题分为两类： 最大流问题：在确定流的源和宿的情况下求一个可行流是v(f) = F为最大 网络拓扑已定，$c_{ij}$已知，给定源$v_s$与宿$v_t$，在二限制条件下求$v_s \\to v_t$的最大流量$F_max$ 最小费用流问题：如果边$e{i,j}$的单位流费用为$d{i,j}$，流f的费用为$C = \\sum{(i,j)\\in E}d{i,j}f_{i,j}$，在确定流的源和宿的情况下求一个可行流f使C最小 网络拓扑已定，$c{ij}$已知，单位流量通过边$(v_i, v_j)$所需的代价$\\alpha{ij}$(代价系数)已知，给定流量F，寻求总代价中最小的可行流${f{ij}}$，其中总费用定义为：$\\phi = \\sum \\alpha{ij}*f_{ij}$ 割量 设X是V的真子集，且$v_s \\in X$, $v_t \\in \\overline X$。$(X, \\overline X)$表示两者界上的边，显然是使$v_s$,$v_t$分离的割集，定义方向$v_s \\to v_t$。 其边分二类： 前向边：与割方向一致的边 反向边：与割方向相反的边 割量：前向边容量和 $c(X, \\overline X) = \\sum{v_i \\in X, v_j \\in \\overline X} c{ij}$ 对可行流${f_{ij}}$ $f(X, \\overline X)$表示前向边的流量$\\sum f_{ij}$ $f(\\overline X, X)$表示反向边的流量$\\sum f_{ji}$ 总流量 = 正向 - 反向 性质 $F = f(X, \\overline X) - f(\\overline X, X)$ example: $F \\leq c(X, \\overline X)$ $ F = f(X, \\overline X) - f(\\overline X, X) \\leq f(X, \\overline X) \\leq c(X, \\overline X) $ 可增流路 可增流路径： 前向边均不饱和($f{ij} &lt; c{ij}$) 反向边均有非0流量($f_{ij} \\not= 0$) 在可增流路上增流不影响连续性条件也不影响其它边上的流量，同时可以使从源端到宿端的流量增大 在可增流路上所有正向边的流量均可增加不致于破坏流量的有限性，所有反向边上均可减流(相当于正向增流)不致于破坏非负性。整体的增流量应为这些正向边上能增流(或反向边上能减流)的最小值，即可增量为 \\delta = min[min_{e_{ij} \\in P}(c_{ij} - f_{ij}), min_{e_ji} \\in P(f_{ji})] 在可增流路上各边均增加$\\delta$(对于反向边即为减流$\\delta$)，不会破坏流量的非负性、有限性，并不影响连续性条件，从而得到一个新的可行流，并使源宿端间的流量增加 最大流问题 求解最大流问题 在找到一个可行流的基础上，找$v_s$到$v_t$的可增流路 在此路上增流直至无可增流路时停止 此为最大流的M算法 M算法所得结果必为最佳解 由于选择已标而未查端的次序是任意的，各种次序可能得不同的可行流，因此分配结果不是唯一的，但最大流量的值一定是一样的 在M算法中若令所有边容量$c_{ij} = 1$，则最大流量即源宿间完全不共边之有向径数目，也是使源宿分离而应去除的最少边数：图的结合度 M算法的推广 最小费用流(最佳流)问题 负权环算法","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"经济增长","slug":"economics/economic_growth","date":"2017-05-14T16:00:00.000Z","updated":"2017-06-29T08:58:08.347Z","comments":true,"path":"2017/05/15/economics/economic_growth/","link":"","permalink":"https://chenfeng.github.io/2017/05/15/economics/economic_growth/","excerpt":"economic growth theoryExogenous Growth Theory The Solow Growth Model (1956) The Augmented Solow Model (Mankiw, Romer and Weil, 1992) Endogenous Growth Theory The AK Model The ‘Basic’ AK Model An AK Model of Learning-by-Doing (Arrow 1962; Romer 1986) An AK Model with Human Capital (Lucas 1988) R&amp;D Models (Romer 1990)","text":"economic growth theoryExogenous Growth Theory The Solow Growth Model (1956) The Augmented Solow Model (Mankiw, Romer and Weil, 1992) Endogenous Growth Theory The AK Model The ‘Basic’ AK Model An AK Model of Learning-by-Doing (Arrow 1962; Romer 1986) An AK Model with Human Capital (Lucas 1988) R&amp;D Models (Romer 1990) Solow Growth Model(长期经济增长索洛模型)The supply and Demand for goodsThe supply for goods(供给侧) 总生产函数 $Y = AF(L, K, R)$ R: 自然资源, A: 经济中的技术水平; 先不考虑技术变革, 自然资源不变 Assume production function $Y = F(K, L)$, and has constant return to scale $\\lambda Y = F(\\lambda K, \\lambda L)$ Y: 产量, K: 物质资本量, L: 劳动量 set $\\lambda = 1/L$ so $Y/L = F(K/L, 1)$ production per worker(人均资本存量) $y = Y/L$, $k = K/L$, then y = f(k) Diminishing Returns to Capital(资本收益递减)：随着投入量的增加，每一单位额外投入得到的收益减少(资本边际产出下降) The demand for Goods(需求侧) (这儿有个隐式的假设，供给和需求达到均衡，即供给=需求，故Y=Z) The demand for Goods and the consumption Function $y = c + i$ y: 可支配收入(税后), c: 用于消费部分, i: 储蓄部分被用于投资的部分 储蓄率取决于银行的回报，银行的回报取决于银行投资率和利润率，假设高投资率 use S denote saving rate, so $c = (1 - s)y$(可支配收入储蓄部分以外的全部用于消费) Keep in mind that various goverment policies can potentially influence a nation’s saving rate, so one of our goal is to find what saving rate is desirable/ For now, however, we just take the saving rate as given. then $y = (1-s)y + i$, $i = sy$ Growth in the Capital stock(资本存量) and the Steady State(稳态)i = sf(k) 供给等于需求，故人均产出等于消费部分加上投资部分 Solow Growth Model索洛模型的目标是找出国民最优储蓄率 assume depreciation rate(资本折旧率) is $\\delta$, so the change in capital stock is equal to investment minus depreciation $\\Delta k = i - \\delta k$ let supply = demand, $$\\Delta k = sf(k) - \\delta k$ 提高s(储蓄率)可以获得暂时的经济增长，直到达到新稳态点 How saving Affects Growth: The Solow model shows that:If the saving rate is low, the economy will have a small capital stock and a low level of output. If the saving rate is high, the economy will have a large capital stock and a high level of output, but it will NOT maintain a high rate of growth forever. 一个国家只靠资本积累无法获得持续经济增长(存在资本折旧率) The Golden Rule Level of Capital 目标是福利水平最优，即不能只考虑GDP最大；尽可能使用于当前消费的部分收入最大化 Comparing Steady States$y = c + i$, $c = y - i$$c^{} = f(k^{}) - \\delta k^{*}$then $MPK = \\delta$: $S_{gold}$, 黄金储蓄率 当前福利水平尽可能最高的点在边际产出和折旧率相等点；将投资回报率调控到投资回报曲线与折旧曲线相交点 Population Growth The Steady State with Population Growth$\\Delta k = i - (\\delta + n)k$, where n is population growth rate. let supply = demand, $\\Delta k = sf(k) - (\\delta + n)k$ 人口增长，资本存量不变，相当于人均资本摊薄，等价于资本折旧率提高 The Effects of Population Growth$y^{} = f(k^{})$then $MPK = \\delta + n$: $S_{gold}$ Technological Progress The efficiency of labour and the S-S(steady state) with Technological Progress $Y = F(K, L * E)$ Let $k = K/(L E)$ (capital per effective worker), $y = Y/(L E) = f(k)$ (output per effective worker), so $\\Delta k = sf(k) - (\\delta + n + g)k$ 技术进步相当于有效劳动力增加，而资本不变，不变资本被摊薄；技术进步导致资本不够用 The Effects of Technological Progress$c^{} = f(k^{}) - (\\delta + n + g) k^{*}$then $MPK - \\delta = n + g$: $S_{gold}$ output per worker $y/L = y * E$ 增加人均产出只能靠技术进步 Policies and GrowthWhat’s the Optimal Rate of Saving? Changing the Saving-Rate Allocating the Economy’s Investment Fertility Programmes Encouraging Technological Progress Cross-Country Implications of the Solow ModelConditional Convergence assume all countries have access to the global stock of technology Long-run, all will grow at g. Short-run, growth-rates will depend inversely on the distance between the capital stock and steady-state level, which is determined by the savings-rate, depreciation-rate, and so on In terms of cross-country comparisons, there is no tendency to convergence. Countries which save more are predicted to have permanently faster growth, and income levels will therefore diverge over time Long-run: The model predicts that long-run growth in standards of living (y) is equal to the rate of technological progress, which is exogenously given. It follows that government is unable to influence growth permanently Short-Run: In the short-run, however, (where effective capital per head, k is not in its steady-state), growth is affected by a number of variables. Transitional growth (and the steady-state level of output per head) is increasing in the rate of saving, decreasing in the rate of population growth and rate of depreciation. Government has greater scope to affect growth in the short-run, by, for example, influencing fertility-rates and encouraging more household saving","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]},{"title":"传输层(Transport Layer)","slug":"computer_network/computer_network_3","date":"2017-05-09T16:00:00.000Z","updated":"2017-05-19T16:03:54.643Z","comments":true,"path":"2017/05/10/computer_network/computer_network_3/","link":"","permalink":"https://chenfeng.github.io/2017/05/10/computer_network/computer_network_3/","excerpt":"Transport services(运输层服务)Transport services and proto provide logical communication(逻辑通信) between app processes running on different hosts transport protocols run in end systems send side: breaks app messages into segments, passes to network layer rcv side: reassembles segments(报文段) into messages, passes to app layer more than one transport protocol available to apps Internet: TCP and UDP","text":"Transport services(运输层服务)Transport services and proto provide logical communication(逻辑通信) between app processes running on different hosts transport protocols run in end systems send side: breaks app messages into segments, passes to network layer rcv side: reassembles segments(报文段) into messages, passes to app layer more than one transport protocol available to apps Internet: TCP and UDP Transport vs. network layer(运输层和网络层的关系) network layer: logical communication between hosts transport layer: logical communication between processes relies on, enhances, network layer services e.g.:12 kids in Ann’s house sending letters to 12 kids in Bill’s house hosts = houses processes = kids app messages = letters in envelopes transport protocol = Ann and Bill who demux to in-house siblings network-layer protocol = postal service Internet transport-layer protocols(因特网传运输层) reliable, in-order delivery (TCP) congestion control flow control connection setup unreliable, unordered delivery: UDP no-frills extension of “best-effort” IP(尽力而为) services not available: delay guarantees bandwidth guarantees multiplexing and demultiplexing(多路复用与多路分解)multiplexing at sender: handle data from multiple sockets, add transport header (later used for demultiplexing) demultiplexing at receiver: use header info to deliver received segments to correct socket How demultiplexing workshost receives IP datagrams each datagram has source IP address, destination IP address each datagram carries one transport-layer segment each segment has source, destination port number host uses IP addresses &amp; port numbers to direct segment to appropriate socket Connectionless demultiplexing(无连接的多路分解) created socket has host-local port #: 1DatagramSocket mySocket1 = new DatagramSocket(12534); when creating datagram to send into UDP socket, must specify destination IP address destination port # when host receives UDP segment: checks destination port # in segment directs UDP segment to socket with that port # IP datagrams with same dest. port #, but different source IP addresses and/or source port numbers will be directed to same socket at dest Connection-oriented demux(面向连接的多路分解)TCP socket identified by 4-tuple: source IP address source port number dest IP address dest port number demux: receiver uses all four values to direct segment to appropriate socket server host may support many simultaneous TCP sockets: each socket identified by its own 4-tuple web servers have different sockets for each connecting client non-persistent HTTP will have different socket for each request connectionless transport: UDP(无连接运输: UDP)UDP: User Datagram Protocol [RFC 768] 关于何时、发送什么数据的应用层控制更为精细 无需连接建立 无连接状态 分组首部开销小 “no frills,” “bare bones” Internet transport protocol “best effort” service, UDP segments may be: lost delivered out-of-order to app connectionless: no handshaking between UDP sender, receiver each UDP segment handled independently of others UDP use: streaming multimedia apps (loss tolerant, rate sensitive) DNS SNMP reliable transfer over UDP: add reliability at application layer application-specific error recovery UDP: segment header(UDP报文段首部) length: in bytes of UDP segment, including header why is there a UDP no connection establishment (which can add delay) simple: no connection state at sender, receiver small header size no congestion control: UDP can blast away as fast as desired UDP checksum(UDP检验和) 端到端原则(end-end principle) Goal: detect “errors” (e.g., flipped bits) in transmitted segment sender: treat segment contents, including header fields, as sequence of 16-bit integers checksum: addition (one’s complement sum) of segment contents sender puts checksum value into UDP checksum field receiver: compute checksum of received segment check if computed checksum equals checksum field value: NO - error detected YES - no error detected. But maybe errors nonetheless? More later …. e.g.: add two 16-bit integers Note: when adding numbers, a carryout from the most significant bit needs to be added to the result UDP Pseudo-Header(UDP伪首部) Protocol – 17 (UDP) e.g. Checksum calculation of a simple UDP user datagram All 0s : Pending to 16bits principles of reliable data transfer(可靠数据传输原理) important in application, transport, link layers: top-10 list of important networking topics characteristics of unreliable channel will determine complexity of reliable data transfer protocol (rdt) rdt: reliable data transfer rdt_send(): called from above, (e.g., by app.). Passed data to deliver to receiver upper layer udt_send(): called by rdt, to transfer packet over unreliable channel to receiver rdt_rcv(): called when packet arrives on rcv-side of channel deliver_data(): called by rdt to deliver data to upper rdt1.0: reliable transfer over a reliable channel(经完全可靠信道的可靠数据传输) incrementally develop sender, receiver sides of reliable data transfer protocol (rdt) consider only unidirectional data transfer but control info will flow on both directions! use finite state machines (FSM) to specify sender, receiver underlying channel perfectly reliable no bit errors no loss of packets separate FSMs for sender, receiver: sender sends data into underlying channel receiver reads data from underlying channel rdt2.0: channel with bit errors(经具有比特差错信道的可靠数据传输) underlying channel may flip bits in packet checksum to detect bit errors the question: how to recover from errors: acknowledgements(ACKs, 肯定确认): receiver explicitly tells sender that pkt received OK negative acknowledgements(NAKs, 否定确认): receiver explicitly tells sender that pkt had errors sender retransmits(重传) pkt on receipt of NAK 自动重传请求协议(Automatic Repeat reQuest, ARQ) new mechanisms in rdt2.0 (beyond rdt1.0): error detection(差错检测) receiver feedback(接收方反馈): control msgs (ACK,NAK) rcvr-&gt;sender 停等(stop-and-wait)协议 rdt2.0 has a fatal flaw what happens if ACK/NAK corrupted sender doesn’t know what happened at receiver can’t just retransmit: possible duplicate 冗余分组(duplicate packet) handling duplicates: sender retransmits current pkt if ACK/NAK corrupted sender adds sequence number to each pkt receiver discards (doesn’t deliver up) duplicate pkt sender sends one packet, then waits for receiver response rdt2.1: sender, handles garbled(含糊不清的) ACK/NAKs sender: seq # added to pkt two seq. #’s (0,1) will suffice. must check if received ACK/NAK corrupted twice as many states state must “remember” whether “expected” pkt should have seq # of 0 or 1 receiver: must check if received packet is duplicate state indicates whether 0 or 1 is expected pkt seq # note: receiver can not know if its last ACK/NAK received OK at sender rdt2.2: a NAK-free protocol same functionality as rdt2.1, using ACKs only instead of NAK, receiver sends ACK for last pkt received OK receiver must explicitly include seq # of pkt being ACKed duplicate ACK at sender results in same action as NAK: retransmit current pkt rdt3.0: channels with errors and loss(经具有比特差错的丢包信道的可靠数据传输)new assumption: underlying channel can also lose packets (data, ACKs) checksum, seq. #, ACKs, retransmissions will be of help … but not enough approach: sender waits “reasonable” amount of time for ACK retransmits if no ACK received in this time if pkt (or ACK) just delayed (not lost): retransmission will be duplicate, but seq. #’s already handles this receiver must specify seq # of pkt being ACKed requires countdown timer rdt3.0 in action Performance of rdt3.0 rdt3.0: stop-and-wait operation(停等) rdt3.0 is correct, but performance stinks e.g.: 1 Gbps link, 15 ms prop. delay, 8000 bit packet: $D_{trans} = \\frac{L}{R} = \\frac{8000bits}{10^9bits/sec} = 8microsecs$ RTT = 30ms used ratio $ U_{sender} = \\frac{L/R}{RTT + L/R} = \\frac{0.008}{30.008} = 0.00027 $ 33kB/sec thruput over 1 Gbps link network protocol limits use of physical resources Pipelined protocols(流水线可靠数据传输协议) pipelining: sender allows multiple, “in-flight”, yet-to-be-acknowledged pkts range of sequence numbers must be increased buffering at sender and/or receiver two generic forms of pipelined protocols: go-Back-N, selective repeat 3-packet pipelining increases utilization(利用率) by a factor of 3 $ U_{sender} = \\frac{3L/R}{RTT + L/R} = \\frac{0.024}{30.008} = 0.00081 $ Go-back-N(GBN, 回退N步): sender can have up to N unacked packets in pipeline receiver only sends cumulative ack doesn’t ack packet if there’s a gap sender has timer for oldest unacked packet when timer expires, retransmit all unacked packets Selective Repeat(SR, 选择重传): sender can have up to N unack’ed packets in pipeline receiver sends individual ack for each packet sender maintains timer for each unacked packet when timer expires, retransmit only that unacked packet Go-Back-NSender k-bit seq # in pkt header “window” of up to N, consecutive unack’ed pkts allowed ACK(n): ACKs all pkts up to, including seq # n - “cumulative ACK” may receive duplicate ACKs (see receiver) timer for oldest in-flight pkt timeout(n): retransmit packet n and all higher seq # pkts in window 窗口长度N 滑动窗口协议(sliding-window protocol) sender extended FSM receiver extended FSM ACK-only: always send ACK for correctly-received pkt with highest in-order seq # may generate duplicate ACKs need only remember expectedseqnum out-of-order pkt: discard (don’t buffer): no receiver buffering re-ACK pkt with highest in-order seq # GBN in action 累积确认(cumulative acknowledgment) Selective repeat receiver individually acknowledges all correctly received pkts buffers pkts, as needed, for eventual in-order delivery to upper layer sender only resends pkts for which ACK not received sender timer for each unACKed pkt sender window N consecutive seq #’s limits seq #s of sent, unACKed pkts sender, receiver windows: sender data from above: if next available seq # in window, send pkt timeout(n): resend pkt n, restart timer ACK(n) in [sendbase,sendbase+N]: mark pkt n as received if n smallest unACKed pkt, advance window base to next unACKed seq # receiver pkt n in [rcvbase, rcvbase+N-1] send ACK(n) out-of-order: buffer in-order: deliver (also deliver buffered, in-order pkts), advance window to next not-yet-received pkt pkt n in [rcvbase-N,rcvbase-1] ACK(n) otherwise: ignore Selective repeat in action Selective repeat: dilemma example: seq #’s: 0, 1, 2, 3 window size=3 receiver sees no difference in two scenarios, duplicate data accepted as new in (b) Q: what relationship between seq # size and window size to avoid problem in (b)? SR协议中窗口长度必须小于或等于序号空间大小的一半 connection-oriented transport: TCP(面向连接的传输: TCP) point-to-point: one sender, one receiver reliable, in-order byte steam: no “message boundaries” pipelined: TCP congestion and flow control set window size full duplex data: bi-directional data flow in same connection MSS: maximum segment size connection-oriented: handshaking (exchange of control msgs) inits sender, receiver state before data exchange flow controlled: sender will not overwhelm receiver 流(stream): 没有报文边界的概念 最大报文段长度(MSS, Maximum Segment Size) 最大链路层帧长度(MTU, Maximum Transmission Unit, 最大传输单元) TCP segment structure(TCP报文段结构) sequence numbers(序号字段): byte stream “number” of first byte in segment’s data acknowledgements(确认号字段): seq # of next byte expected from other side cumulative ACK Q: how receiver handles out-of-order segments A: TCP spec doesn’t say, - up to implementor 接收窗口字段(receive window): 用于流量控制，指示接收方愿意接受的字节数量 Q: how to set TCP timeout value? longer than RTT but RTT varies too short: premature timeout, unnecessary retransmissions too long: slow reaction to segment loss Q: how to estimate RTT(估计往返时间)? SampleRTT: measured time from segment transmission until ACK receipt ignore retransmissions SampleRTT will vary, want estimated RTT “smoother” average several recent measurements, not just current SampleRTT $ EstimatedRTT = (1- \\alpha)EstimatedRTT + \\alphaSampleRTT $ * exponential weighted moving average(EWMA, 指数加权移动平均) influence of past sample decreases exponentially fast typical value: $\\alpha = 0.125$ timeout interval: EstimatedRTT plus “safety margin” large variation in EstimatedRTT -&gt; larger safety margin estimate SampleRTT deviation from EstimatedRTT: DevRTT = (1-\\beta)*DevRTT +\\beta* |SampleRTT-EstimatedRTT| (typically, \\beta = 0.25) TimeoutInterval = EstimatedRTT(estimated RTT) + 4*DevRTT(“safety margin”) TCP reliable data transfer(可靠数据传输) TCP creates rdt service on top of IP’s unreliable service pipelined segments cumulative acks single retransmission timer retransmissions triggered by: timeout events duplicate acks let’s initially consider simplified TCP sender: ignore duplicate acks ignore flow control, congestion control TCP sender events: data received from app: create segment with seq # seq # is byte-stream number of first data byte in segment start timer if not already running think of timer as for oldest unacked segment expiration interval: TimeOutInterval timeout: retransmit segment that caused timeout restart timer ack received: if ack acknowledges previously unacked segments update what is known to be ACKed start timer if there are still unacked segments TCP sender (simplified) retransmission scenarios: TCP ACK generation [RFC 1122, RFC 2581] event at receiver TCP receiver action arrival of in-order segment with expected seq #. All data up to expected seq # already ACKed delayed ACK. Wait up to 500ms for next segment. If no next segment, send ACK arrival of in-order segment with expected seq #. One other segment has ACK pending immediately send single cumulative ACK, ACKing both in-order segments arrival of out-of-order segment higher-than-expect seq #. Gap detected immediately send duplicate ACK, indicating seq. # of next expected byte arrival of segment that partially or completely fills gap immediate send ACK, provided that segment starts at lower end of gap TCP fast retransmit(快速重传) time-out period often relatively long: long delay before resending lost packet detect lost segments via duplicate ACKs. sender often sends many segments back-to-back if segment is lost, there will likely be many duplicate ACKs. if sender receives 3 dupl ACKs for same data(“triple duplicate ACKs”), resend unacked segment with smallest seq # likely that unacked segment lost, so don’t wait for timeout TCP flow control(TCP流量控制) receiver controls sender, so sender won’t overflow receiver’s buffer by transmitting too much, too fast receiver “advertises” free buffer space by including rwnd value in TCP header of receiver-to-sender segments RcvBuffer size set via socket options (typical default is 4096 bytes) many operating systems autoadjust RcvBuffer sender limits amount of unacked (“in-flight”) data to receiver’s rwnd value guarantees receive buffer will not overflow Connection Management(TCP连接管理) before exchanging data, sender/receiver “handshake”: agree to establish connection (each knowing the other willing to establish connection) agree on connection parameters Q: will 2-way handshake always work in network? variable delays retransmitted messages (e.g. req_conn(x)) due to message loss message reordering can’t “see” other side 2-way handshake failure scenarios: TCP 3-way handshake(三次握手) TCP 3-way handshake: FSM TCP: closing a connection(四次挥手) client, server each close their side of connection send TCP segment with FIN bit = 1 respond to received FIN with ACK on receiving FIN, ACK can be combined with own FIN simultaneous FIN exchanges can be handled Principles of congestion control(拥塞控制原理) congestion: informally: “too many sources sending too much data too fast for network to handle” different from flow control! manifestations: lost packets (buffer overflow at routers) long delays (queueing in router buffers) a top-10 problem Causes/costs of congestion: scenario two senders, two receivers one router, infinite buffers output link capacity: R no retransmission one router, finite buffers sender retransmission of timed-out packet application-layer input = application-layer output: $\\lambda{in} = \\lambda{out}$ transport-layer input includes retransmissions: $\\lambda{in}^{‘} \\geq \\lambda{in}$ idealization: perfect knowledge sender sends only when router buffers available Idealization: known loss packets can be lost, dropped at router due to full buffers sender only resends if packet known to be lost Realistic: duplicates packets can be lost, dropped at router due to full buffers sender times out prematurely, sending two copies, both of which are delivered “costs” of congestion: more work (retrans) for given “goodput” unneeded retransmissions: link carries multiple copies of pkt decreasing goodput four senders multihop paths timeout/retransmit Q: what happens as $\\lambda{in}$ and $\\lambda{in}^{’}$ increase ? A: as red $\\lambda_{in}^{’}$ increases, all arriving blue pkts at upper queue are dropped, blue throughput $\\to$ 0 another “cost” of congestion: when packet dropped, any upstream transmission capacity used for that packet was wasted(上游路由器用于转发该分组而使用的传输容量最终被浪费掉了) TCP congestion control: additive increase multiplicative decrease(AIMD, 加性增，乘性减) approach: sender increases transmission rate (window size), probing for usable bandwidth, until loss occurs additive increase: increase cwnd by 1 MSS every RTT until loss detected multiplicative decrease: cut cwnd in half after loss sender limits transmission: $ LastByteSend - LastByteAcked \\leq cwnd $ cwnd(拥塞窗口长度) is dynamic, function of perceived network congestion TCP sending rate: roughly: send cwnd bytes, wait RTT for ACKS, then send more bytes $ rate \\approx \\frac{cwnd}{RTT} bytes/sec $ TCP Slow Start(慢启动) when connection begins, increase rate exponentially until first loss event: initially cwnd = 1 MSS double cwnd every RTT done by incrementing cwnd for every ACK received summary: initial rate is slow but ramps up exponentially fast detecting, reacting to loss loss indicated by timeout: cwnd set to 1 MSS; window then grows exponentially (as in slow start) to threshold, then grows linearly(进入拥塞避免状态) loss indicated by 3 duplicate ACKs: TCP RENO(进入快速恢复状态) dup ACKs indicate network capable of delivering some segments cwnd is cut in half window then grows linearly TCP Tahoe always sets cwnd to 1 (timeout or 3 duplicate acks)(进入慢启动状态) switching from slow start to CA(Congestion Avoid) Q: when should the exponential increase switch to linear? A: when cwnd gets to 1/2 of its value before timeout. Implementation: variable ssthresh on loss event, ssthresh is set to 1/2 of cwnd just before loss event TCP throughput(TCP吞吐量) avg. TCP thruput as function of window size, RTT? ignore slow start, assume always data to send W: window size (measured in bytes) where loss occurs avg. window size (# in-flight bytes) is 3/4 W avg. thruput is 3/4W per RTT $ avg TCP throughput = \\frac{3}{4} \\frac{W}{RTT} bytes/sec $ TCP Futures: TCP over “long, fat pipes”(经高带宽路径的TCP) example: 1500 byte segments, 100ms RTT, want 10 Gbps throughput requires W = 83,333 in-flight segments throughput in terms of segment loss probability, L [Mathis 1997]: $ TCP thoughput = \\frac{1.22*MSS}{RTT\\sqrt{L}} $ to achieve 10 Gbps throughput, need a loss rate of L = 2·10-10 – a very small loss rate new versions of TCP for high-speed TCP Fairness(TCP公平性) fairness goal: if K TCP sessions share same bottleneck link of bandwidth R, each should have average rate of R/K Why is TCP fair two competing sessions: additive increase gives slope of 1, as throughout increases multiplicative decrease decreases throughput proportionally Fairness and UDP multimedia apps often do not use TCP do not want rate throttled by congestion control instead use UDP: send audio/video at constant rate, tolerate packet loss Fairness, parallel TCP connections application can open multiple parallel connections between two hosts web browsers do this e.g., link of rate R with 9 existing connections: new app asks for 1 TCP, gets rate R/10 new app asks for 11 TCPs, gets R/2 Explicit Congestion Notification (ECN) network-assisted congestion control: two bits in IP header (ToS field) marked by network router to indicate congestion congestion indication carried to receiving host receiver (seeing congestion indication in IP datagram), sets ECE bit on receiver-to-sender ACK segment to notify sender of congestion","categories":[],"tags":[{"name":"computer network","slug":"computer-network","permalink":"https://chenfeng.github.io/tags/computer-network/"}]},{"title":"分布式路由算法","slug":"parellel_and_distributed_computing/distributed_compute2","date":"2017-05-08T16:00:00.000Z","updated":"2017-05-19T08:01:49.457Z","comments":true,"path":"2017/05/09/parellel_and_distributed_computing/distributed_compute2/","link":"","permalink":"https://chenfeng.github.io/2017/05/09/parellel_and_distributed_computing/distributed_compute2/","excerpt":"(并行与分布式计算十) 分布式路由算法导论进程间通信类型 有效的进程间通信对分布式系统的性能很重要 根据目标个数的不同，进程间通信的类型有： 一对一（单播） 一对多（组播） 一对所有（广播） 通信延迟及其原因在基于消息传递的分布式系统中，消息一般在到达目标节点之前可能要通过一个或多个中间节点，故存在通信延迟。","text":"(并行与分布式计算十) 分布式路由算法导论进程间通信类型 有效的进程间通信对分布式系统的性能很重要 根据目标个数的不同，进程间通信的类型有： 一对一（单播） 一对多（组播） 一对所有（广播） 通信延迟及其原因在基于消息传递的分布式系统中，消息一般在到达目标节点之前可能要通过一个或多个中间节点，故存在通信延迟。 分布式系统中的通信延迟依赖于如下四个因素： 网络拓扑： 通常用图表示 定义处理单元（PE）之间是如何连接的 路由 决定如何选择路径以便将消息传递到目的地。 流量控制 流量控制决定在消息沿路径传递时如何分配网络资源，包括： 信道 缓冲区 交换 这是一个实际的机制，它决定消息如何从一个输人信道转到一个输出信道。 路由算法类型路由算法类型包括： 特殊 vs. 一般 最短 vs. 非最短 确定型 vs. 适应型 容错型 vs. 非容错型 冗余型 vs. 非冗余型 死锁避免型 vs. 非死锁避免型 一般型路由和特殊型路由 一般型路由算法 适合于所有类型的网络 但是对于某种特定网络不是很有效 特殊型路由算法 只对特定的网络类型有效，如超立方、网格等 这些算法由于利用了特定网络的拓扑属性，所以效率往往较高。 最短路由算法和非最短路由算法 最短路径算法 对给定的源-目标对给出一个代价最小的路径 路径的代价: 所有跳步（连接）代价的线性和。 缺点：可能会导致网络某一部分的拥塞 非最短路由算法 可以将消息路由到一个更长的路径从而避免拥塞。 在某些情况下，随机路由可能是有效的。 确定型路由和适应型路由 确定型路径算法 路由路径只在网络的拓扑发生改变时才发生变化， 而且它不使用任何有关网络状态的消息。 适应型路由算法 路径根据网络流量而改变 容错型路由和非容错型路由 容错型路由算法 即使出现错误，被路由消息也能保证送到。 非容错型路由算法 假定路由不会出错 路由算法不必动态调整自己的活动。 冗余型路由和非冗余路由 冗余型路由算法 用几个边分离（或节点分离）的路径向同一个目标发送多个拷贝。 只要这些路径中的一个是好的，那么就会至少有一个消息拷贝到达目标。 必须保证有且只有一个拷贝被接收 非冗余型路由算法 对每个目标只需转发消息的一个拷贝。 死锁避免型路由 死锁避免型路由算法 通过仔细设计的路由算法，保证不发生死锁。 非死锁避免型路由算法 没有特别的设施来预防或避免死锁。 可能发生死锁，也可能不发生死锁。 路由函数 路由函数 定义一个消息如何从源节点路由到目标节点。 每个PE在收到一个消息以后，都将决定： 1）把这条消息传送到本地存储器，还是 2）转发到一个邻接的PE 有许多不同的路由函数的定义，例如依赖于目标的、依赖于输入的、依赖于源的、依赖于路径的等等 这里介绍的仅使用依赖于目标的路由函数 一般类型网络的最短路径路由算法许多分组交换网，如法国的Transpac或美国的ARPAnet都使用最短路径路由 介绍三个一般类型网络的最短路径路由算法： Dijkstra集中式算法 Ford分布式算法 ARPAnet路由算法 分布式系统图示 一般地，一个分布式系统可以用图来表示： 节点代表PE（处理单元） 边代表通信链接 每个链接的数字代表链接代价 Dijkstra集中式算法 第一种类型的算法以集中式的风格进行路由 Dijkstra集中式算法可以发现一个源节点到所有其他节点的最短路径。 Dijkstra集中式算法需求： 需要了解给定网络的全局拓扑消息，即： 网络中所有其他节点的列表 节点之间的所有链接 每个链接的代价 算法描述 设D(v)是从源s到节点v的距离(沿给定路径的链接的代价的和), l(v,w)是节点v和w之间的代价 1.设N={s}；对不在N中的每一个节点v，令D(v)=l(s,v)。对那些没有连接到s的节点赋值为 $\\infty$ 2.找到不在N中的一个节点w，使D(w)最小并将w加入N；然后对所有不在N中的其它节点计算并更新D(v)： D(v) := min[D(v), D(w)+l(w,v)] 重复步骤2，直到所有节点都在N中 算法举例 上述算法作用于如图所示的网络：以P5为源节点 1.集合N只包含源节点P5即N = { P5 }。 对不在N中的节点P1,P2,P3,P4计算： D(1)=D(2)= $\\infty$ (由于P1和P2不与P5直接相连) D(3)=l(P5, P3) = 20 D(4)=l(P5, P4)=2 2.取D(1),D(2),D(3),D(4)中具最小值的对应节点P4加入到集合N中, N = {P5, P4} 对不在N中的其它节点P3,P2,P1更新 D(1)=min{D(1), D(4)+l(4,1)} = min{$\\infty$, 2+$\\infty$}=$\\infty$, D(2)=min{D(2), D(4)+l(4,2)} =min{$\\infty$, 2+1}=3 D(3)=min{D(3), D(4)+l(4,3)} =min{20, 2+2}=4 3.取D(1),D(2),D(3)中具最小值的对应节点P2加入到集合N中，N={P5,P4,P2} 对不在N中的其它节点P3,P1更新 D(1)=min{D(1), D(2)+l(2,1)} =min{$\\infty$,3+4}=7 D(3)=min{D(3), D(2)+l(2,3)} =min{4, 3+3}=4 4.取D(1),D(3)中具最小值的对应节点P3加入到集合N中, N = {P5,P4,P2,P3} 对不在N中的其它节点P1更新 D(1)=min{D(1), D(3)+l(3,1)} =min{7, 4+5}=7 5.取D(1)中具有最小值的对应节点P1加入到集合N中, N= { P5,P4,P2,P3,P1} 此时，节点都在N中，算法结束 Ford分布式算法 第二种类型的路由算法采用分布式的方法进行路由 分布式算法: 每个节点在交互式的基础上和其邻节点交换代价和路由信息，直到这些节点的路由表到达最短路径的要求为止 Ford分布式算法也包括两个部分： 一个初始步骤 一个最短距离计算的步骤(最短距离指一个给定节点和目标节点之间的距离) 当所有节点都带有 1）一个表示它们到目标节点距离的标记以及 2）沿着最短路径到达目标节点要经过的下一个节点的标记时 算法结束 算法描述 每个节点v，都有(n,D(v))的标记。 D(v)代表该节点到目标节点的最短距离的当前值； n是截至目前得到的最短路径的下一个节点。 初始步骤： 设d是目标节点, 令D(d)=0，将所有其它节点标记为(., $\\infty$) 最短距离计算步骤： 对所有节点的最短路径做标记： 对每个节点v≠d： 使用v的每个邻节点w的当前D(w) 计算D(w)+l(w, v)，使得D(v):=min{D(v),D(w)+l(w,v)} 更新v的标记：用使上述表达式取值最小的邻接节点代替n，并用新值代替D(v) 对每个节点重复上述操作，直到不再有改变 举例 上述算法作用于如图所示的网络：以P5为目标节点 初始：令D(5) = 0，将其他节点P1,P2,P3,P4都标记为(., $\\infty$) 1.对于P1，邻节点为P2,P3，由当前标记可知P2,P3距离P5都为$\\infty$，则P1不能通过任何节点到达P5，P1仍标记为(., $\\infty$) 同理，P2仍标记为(., $\\infty$) 对于P3，邻节点为P1,P2,P4,P5，其中D(1)= D(2)=D(4)=$\\infty$,D(5)=0 由于P3到P5的距离20+D(5)为20小于当前D(3)= $\\infty$, 表明P3经P5有最短路径可达P5, 故P3标记为(P5, 20) 同理，P４标记为(P5, 2) 2.对于P1，邻节点为P2,P3，由当前标记可知P5距离P2为$\\infty$，距离P3为20，则P1通过P3有最短路径到达P5，D(1)为P1到P3的距离与P3到P5的距离之和为5+20=25，故P1标记为(P3,25) 对于P2，邻节点为P1,P3,P4，计算P2到Pi (i = 1,3,4)的距离与当前D(i)之和，并取最小值，可见计算P2到P4的距离与当前D(4)之和最小为3，说明P2经P4有最短路径到达P5，故P2标记更新为(P4,3) 同理，更新P3和P4的标记为(P4,4)，(P5,2) 4.按同样方法更新P1,P2,P3,P4的标记为： (P2,7),(P4,3),(P4,4),(P5,2) 由于此后再重复以上算法试图更新每一个节点的标记都不会改变其标记，算法结束 上例中，所有节点的行为在经过几轮之后都被同步了 上述同步方法仅仅是为了便于演示, 同步方法是指所有节点在每一轮中都更新一次标记 Ford算法也适用于异步系统，其中每个节点以随机的速率更新其D(v)值 ARPAnet路由算法 ARPAnet的路由算法是一个可靠、实用的分布式路由算法，也是今天流行的Internet 路由算法的前身。 与Ford算法比较相似 不同的是 算法中的节点都维护一个一般化的路由表，以便记录通过不同邻接节点的最短路径。 这个路由表包含从这个节点到所有其它节点的最优路径的延迟。 每隔固定的时间间隔，路由表就被传送到它的所有邻接节点，直到最小延迟表在某一点达到稳定为止。 举例说明 用ARPAnet路由算法时，P1，P2，P3，P4的一般路由表，仍以P5为目标节点 每个表格都包含通过每个邻居到达P5的最短距离 假设在时刻0前已经达到了一个稳定点, 网络延迟表如图 假设0时刻，P4与P5之间链接失效，则它更新它的路由延迟表，并传输给P4的所有邻节点，从而使那些节点的路由延迟表发生变化，直到产生一个新的稳定点 上述过程一直持续到达到一个新的稳定点，P1，P2，P3，P4分别用了20，19，17，20个时间间隔，如下图所示 ARPAnet路由算法中, 每个节点对所有邻居都发送相同消息，对接收节点不做任何标识。这样，某些节点就会接收无用消息。 在链接节点失效时候，这些消息会导致我们不期望的循环。 例如, ，P4和P5链接失效时，P4的最短路径为4，但是这个4来自于P2，而P2到P5的最短路径原来就依赖于P4与P5的链接，由于P4使用P2的信息时，P2的信息尚未得到更新，导致出现不期望的循环：P4-&gt;P2-&gt;P4 不期望循环的消除 循环的消除是在路由消息中包含路径的所有节点，并把这些消息发给邻居节点。 然而，它的效率较底，因为它的额外开销太大。 Shin和Chou，提出了一个避免循环算法：只需在路由消息中存储路径中最近的l个节点，l与相应网络中循环的最大长度有关 特殊类型网络的单播路由算法 一般类型网络的路由算法适用于所有拓扑类型的网络。但是，每个节点需要维持路由延迟表，而且不适用于特殊类型的网络，原因是效率太低。 得益于特殊网络的拓扑特性，可以不使用路由延迟表而构造最短路径路由算法 介绍三种特殊网络的单播路由算法： 双向环单播路由算法 网格和圆环单播路由算法 超立方单播路由算法 双向环单播路由算法 在双向环上进行决定型单播路由非常简单： 消息沿着一个方向被转发：顺时针或者逆时针 由于消息可以沿两个方向发送，所以由源节点根据目标节点的位置决定发送方向： 如果目标离顺时针方向近，则用顺时针方向； 否则选择逆时针方向。 一个消息通过几个中间节点按照顺时针或逆时针方向传递，直到到达目标节点。 双向环上的单播路由算法可以使用两条路径：一条沿着顺时针，另一条沿着逆时针。 消息可以被复制，然后每个方向发一个拷贝；也可以分成两半，每半转发到一个方向。 算法一般化 双向环是k元1维立方，即只有一维度。 若维度大于1，例如网格和超立方，就用有序维度路由 每次将每个消息向一个维度路由 圆环：在一个维度中的各点以环的方式连接起来，带有周边连接 网格：一个维度中的各点以线性排列的形式连接起来，没有周边连接 环形路由方法可用于在一个维度中对消息进行路由。 沿着一个线性排列路由是很简单的。 当消息到达每个维度的对等者时，就使用下一个维度。 通过使经过的各个维度保持一个单调的顺序，就可以保证不会发生死锁。 但这种方法适应性差。 网格和圆环单播路由算法 网格和圆环是k元2维立方。 圆环有周边邻接， 网格没有周边连接。 类似地，3维网格和圆环是k元3维立方。 介绍以下路由算法 2维网格的XY路由 最短且完全适应路由 折线路由 最大最短路径路由 2维网格的XY路由 在2维网格中，有序维度路由叫XY路由。 每个节点的地址为(x,y)。 消息首先沿着X维度转发，然后沿着Y维度路由。 特别地，若源和目标分别为(sx,sy)和(dx,dy)，则路由消息将在X维度上走|dx – sx| 步，然后在Y维度上走|dy– sy|步 最短且完全适应路由 在最短且完全适应路由中，每个中间节点，包括源节点，都要充分利用所有可行的最短路径。 在2维网格中， 只要dx–sx≠0且dy–sy≠0，每个节点在选择邻居时总有两个选择。 一个好的适应性路由算法应该能选择任意－个邻居并能尽可能地保持dx –sx≠0且dy–sy≠0的情况。 显然,XY路由是最不灵活的一个。 适应性路由图示(只要dx–sx≠0且dy–sy≠0，每个节点在选择邻居时总有两个选择：X方向或者Y方向) 如果每个链接（信道）拥塞的概率是一样的，那么在最短路由的限制下，哪一个是最好的路由方法呢 这里的最好是指在这种路由方法下，消息到达目标的延迟最小。 折线路由 Badr和Podar提出了一个2维网格的折线路由方法 首先建立一个包含源和目标的矩形． 源s=(sx,sy)和目标d=(dx,dy)分别位于矩形的两个对角 从端点d=(dx,dy)引出一条线L，这条线将平分经过点d的矩形的两边所组成的角。消息将沿着直线L路由，但仍在矩形内部。即所有的中间节点都是依照它们到L的距离来选择的——在所有合格的节点中，总是选择距离L最近的一个。 在2维圆环中，折线路由可能不是最优的，因为一个中间节点可能有多于两个的合格邻居。 特别，对一个n为偶数的n*n的圆环，存在一个具有四个合格邻居的节点。而且，有2(n-2)个节点，它们和源的距离为n／2个行或列，因此，在最短路径上就有多个方向。 对于最优解，Wu在k元M维立方的最短路径路由算法的基础上提出了一个最大最短路径(MP)路由算法：路由消息总是被转发到与目标节点存在最大个数的最短路径的那个邻居节点。 基于最大最短路径的路由算法是一个对2维网格和M维立方都是最优的路由算法。 然而，关于最大最短路径对2维圆环是不是最优的仍然是一个未决的问题。 若源和目标都有四个邻居，那么很容易在它们之间建立四个边(或点)分离的路径，如图。 一般地，设k(k&lt;=4)是源和目标节点所具有的最小的邻居的数目，那么，在源和目标之间就存在k个边〔点〕分离的路径。 超立方单播路由算法 对超立方的单播路由可采用一种相对简单的方法，不必在每个节点中存储路由延迟表。 一个n维超立方（n-cube）可定义为： Q0，是一个只有一个节点的退化图 $Qn＝K_2 x Q{n-1}$, 这里：$K_2$是具有两个节点的完全图；x是两个图的笛卡尔乘积。 Qn中的一个节点的地址可以表示为$ u = un u{n-1}…u_1(u_i＝0/1, 1&lt;=i&lt;=n) $ 海明距离 两个节点$u=u_n u{n-1}…u_1$和$w=w_n w{n-1}…w_1$间最短路径长度就是u和w间的海明距离，表示为H(u,w)。 H(u, w) = \\sum_{i=1}^{n}h(u_i, w_i), h(u_i,w_i)=\\begin{cases} 1&\\text{if $u_i \\not= w_i$},\\\\ 0&\\text{if $u_i = w_i$}. \\end{cases} u和w间的异或操作$u \\oplus w＝rn r{n-1}… r_1$定义为： 如果$u_i＝w_i$，则$r_i＝0$ 如果$u_i \\not= w_i$，则$r_i＝1,1&lt;=i&lt;=n$ 显然，H(u,w)等于$u \\oplus w$中1的个数 u(i)表示改变u的第i位(也叫维)．例如1101(3)=1001 超立方路由 在超立方路由中 当前节点u和目标节点w的相对地址为$w_i \\oplus u_i$，它和将要发送到下一个节点(这个节点也叫转发节点)的消息一起传送 在每个跳步，相对距离都会通过将$w_i \\oplus u_i$中的一个1替换而进行更新 在下面的算法中，节点u是当前节点(可以是源节点)，节点w是目标节点。 在上述算法中，i的选择是随机的，这意味着可能有不止一条最短路径。 实际上，最短边分离的个数等于源节点和目标节点的海明距离。 如果遵循一个预定的顺序，这种算法就是决定性的，叫做e立方路由。 例如，维的顺序遵循升序：首先是1维，然后2维，等等。n维在最后 一个3维立方路由的例子 例中：源节点u=000目标节点w＝110。从点000到点110有下列三个点分离路径： 路径1（红色）：000$\\to$100$\\to$110 路径2（蓝色）：000$\\to$010$\\to$110 路径3（绿色）：000$\\to$001$\\to$011$\\to$111$\\to$110 超立方多路径路由的性质 超立方多路径路由具有如下性质：若两个节点u和w在n维立方中的海明距离是k, 则在u和w之间就有n个点分离路径。在这n条路径中，有k个路径长度为k，其余n-k个路径长度为k+2 000和110之间的距离|000$\\oplus$110|＝2。因此，上述路径中有两条长度为2，一条长度为4 路径1（红色）：000$\\to$100$\\to$110 路径2（蓝色）：000$\\to$010$\\to$110 路径3（绿色）：000$\\to$001$\\to$011$\\to$111$\\to$110 类似地．000和100之间的三条点分离路径为： 路径1（红色）：000$\\to$100 路径2（绿色）：000$\\to$001$\\to$101$\\to$100 路径3（蓝色）：000$\\to$010$\\to$110$\\to$100 000和100之间的海明距离|000$\\oplus$100|=1 特殊类型网络的多播路由算法 多播（一到多）是指从一个源向任意多个目标节点传送同样的消息。 只有一个目标的单播和以网络中的所有节点为目标的广播都是多播的特例。 多播在数据并行编程操作中有一些应用，例如复制，障碍同步，对共享存储器失效以及分布式共享内存系统更新的支持等。 一般的多播路由算法 两个主要的多播路由参数是通信量和时间。 通信量是以将消息发送到所有的目标所需的通信链接的数目来衡量的。 时间就是消息传送的时间。 当两个多播路由算法有相同的时间步数时，应该选择具有较小的通信量步数的那一个。 通信量可以通过不同的目标共享链接来降低。 多播优化问题 通常，多播存在下列四个优化问题： 多播路径优化问题: 一个最优的多播路径是一个包括所有目标的最短路径。 多播回路优化问题: 最优多播回路是包含所有目标的最短长度的回路。 steiner树优化问题 一个包含所有目标节点的给定拓扑的一个子树 最小steiner树具有最小的总长度 注意：不一定每个通向目标的路径长度都是最短的。 多播树优化问题 一个包含所有目标的给定拓扑的子树，且树中每个通向目标的路径的长度对于给定的拓扑是最小的。 一个最优的多播树具有最小的通信量 不幸的是，对网格和超立方的多播优化问题都是NP完全问题。因此，一般使用启发式多播算法。 目前，已有人给出了在使用分割-通过路由技术(如虫孔路由)的网络中进行最优化多播通信的充分条件。 考虑两种算法：一个是基于路径的；另一个是基于树的。 基于路径的多播路由算法 基本思想： 首先建立一个哈密尔顿回路， 然后根据这个回路把多播集合转发出去。 如果有一个邻居位于目标前面，但距离目标更近，那么就可以抄近路。 1895年，爱尔兰数学家哈密尔顿首先提出“环球周游”问题。他用一个正十二面体的20个顶点代表世界上20个城市，要求旅游者能否找到沿着正十二面体的 棱，从某一个顶点（即城市）出发，经过每一个顶点（即每一座城市）恰好一次，然后回到出发顶点？这便是著名的哈密尔顿问题。它的解称为哈密尔顿回路。 主要步骤: 在给定的网格或超立方上建立哈密尔顿回路； 将哈密尔顿回路上的节点排序。 这个顺序起始于源节点，并包括所有目标节点。 这样哈密尔顿回路就被分割成了哈密尔顿路径； 对每个中间节点， 若它是一个目标节点， 保留消息的一个拷贝，删除该目标节点的地址。 将消息和目标列表传给一个邻居。这个邻居必须在当前节点之前（按顺序)，离下一个目标最近，且仍在这个目标之前(或就是这个目标)。 若使用双向链接，则只需一个哈密尔顿路径(而不是哈密尔顿回路)即可。 哈密尔顿路径为系统中的所有节点定义了一个顺序。 在整个顺序中，每个节点(x,y)都被赋予一个数字r： r(x, y)=\\begin{cases} yn+x&\\text{if y is even}\\\\ yn+n-x-1&\\text{if y is odd} \\end{cases} 例如，一个4X4的网格上每个节点具有的r值如图所示： n=4 若y是偶数，r值沿X方向递增, r(x,y)=yn+x 若y是奇数，r值沿X方向递减, r(x,y)=yn+n-x-1=yn+(n-1)-x 哈密尔顿路径定义: 两个节点在路径中相邻当且仅当|r(v)-r(u)|=1 例如：4X4网格中，使用粗线连接两个相邻节点 使用顺序定义，整个网格可以分成两个子网： 一个包括从低序节点到高序节点的链接； 另一个包括从高序节点到低序节点的链接。 在两个子网中，除了哈密尔顿路径上的链接以外，其它链接也包含在其中。 最短路径路由函数 目标依据它们与源的相对位置也分为两个子集。 一个子集将沿着高信道网络传送， 另外一个将沿着低信道网络传送。 为了将消息沿着最短路径传送，定义如下路由函数。 假定使用高信道网络。 v和d（r(v)&lt;r(d)）分别是中间节点和目标节点。 若d是v的一个邻居，那么消息将直接转发到d； 否则，选择一个满足下式的v的邻居u：$r(u) = max{r(w): r(w) &lt; r(d),$ w is a neighbor of v$}$ 基于路径的多播路由算法举例 下图显示了一个在4X4网格中进行多播的例子 哈密尔顿路径连接了那些r值依次递增的节点 假定节点6(地址为(1,1))为源节点，目标节点为0、2、10、13和14 显然，转发消息到节点0和2时，应该使用低信道网络。依据路由函数，可以得到如下路径：6$\\to$5$\\to$2$\\to$1$\\to$0 同样，转发消息到节点10，13和14时应使用高信道网络: 6$\\to$9$\\to$10$\\to$13$\\to$14 红色：低信道网络路径和具有最小r值的邻居深紫色：高信道网络路径和具有最大r值的邻居 基于树的多播路由算法 Lan的贪婪多播算法可以应用于超立方。在这个算法中，每个节点(包括源节点)在收到包含目标节点地址列表的消息后，就把自己的地址和目标节点的地址相比较。 若发现匹配，消息的一个拷贝将被送往本地的处理器 若多播集合非空，当前节点将决定把目标列表中的地址转发到哪些邻居。 根据维度顺序进行转发 维度顺序由目标节点的相对二进制地址来决定 n位地址的每一位都有一个计数器。 计数器的内容代表相应维度的信息。 具有最大计数值的那一维将被选中。 所有在这一位为1的目标将被转发到这一维上的那个邻居 在剩余的目标中，将利用下一个被选中的维度重复上述步骤。 当剩余的多播集合为空时，这一过程就结束。 基于树的多播路由算法：4维立方中的多播例子 考虑一个4维立方体(目标用蓝色节点代表) 节点0010打算向组播集{0000，0001，1001，1100，1110}中的每个节点发送消息 所有目标节点的实际地址和源节点0010的实际地址做异或操作，得到多播集合的相对地址{0010，0011，1011，1110，1100}。 每一列的1的数目组成了一个称为列总和的向量(3, 2, 4, 2) 沿着第2维的邻居拥有最受欢迎的维度。即节点0000成为下一个转发节点，发往节点0000的消息包含子集(0000，0001，1001，1100)。 只有节点1110被剩下了，这个节点可以通过第3维的邻居转发，也可以通过第4维的邻居转发。 上述过程将在每个转发节点重复操作。 每个多播树的分支都将继续到剩余的多播集合变空为止","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"分布式计算的概念和模型","slug":"parellel_and_distributed_computing/distributed_compute1","date":"2017-05-01T16:00:00.000Z","updated":"2017-05-19T08:01:29.130Z","comments":true,"path":"2017/05/02/parellel_and_distributed_computing/distributed_compute1/","link":"","permalink":"https://chenfeng.github.io/2017/05/02/parellel_and_distributed_computing/distributed_compute1/","excerpt":"(并行与分布式计算九) 分布式系统的实例和定义一般性的分布式系统 实例 生物中的实例：鱼的群体、鸟的群体、微生物生态系统 计算机系统的实例：Google FS、 Big Table、Hadoop、Hbase 定义：由一组相互独立的实体构成的集合，这些实体相互协作可解决任何单独的实体不能解决的问题","text":"(并行与分布式计算九) 分布式系统的实例和定义一般性的分布式系统 实例 生物中的实例：鱼的群体、鸟的群体、微生物生态系统 计算机系统的实例：Google FS、 Big Table、Hadoop、Hbase 定义：由一组相互独立的实体构成的集合，这些实体相互协作可解决任何单独的实体不能解决的问题 特征： 其中一个实体的失效不会影响整体对问题的求解 相互独立，有某种程度的自治性 宏观上具有一致行为 实体间的相互协作 分布式计算机系统可能呈现的特征 系统中某个计算机的崩溃不影响系统整体的功能 系统中每个计算机都是半自治的：没有共享内存和共同的物理时钟 系统中的计算机尽管相互独立，但在用户面前具有一致行为 弱耦合：通过通信网络进行通信和协作 允许地理分散 允许硬件和软件上的异构 典型分布式系统的体系结构硬件 软件架构 软件部件之间的关系 分布式软件也叫做中间件 分布式执行是贯穿整个分布式系统的多个进程的执行 分布式执行通过多进程的合作来达成共同的目标 分布式系统用分层的体系结构来分散系统设计的复杂性 分布式系统的中间件通常包含一些分布式计算的原语，包括： 消息传递 组通信 远程过程调用（RPC） 分布式计算的动机需求 满足实体所固有的地理分散性，例如银行转账 解决大规模共享数据资源的存储问题和访问瓶颈问题 解决数据权限和敏感性问题 提高系统的可靠性 可用性：资源就当在任何时间内都可以访问 完整性：面对多个处理器同时进行访问时，数据能符合应用所期望的语义 容错性：在系统故障时能恢复工作 提高系统的性能价格比 分布式计算的优势 可伸缩性 当需要满足更大的应用规模需求时，能够方便地增加系统中的计算机，通过广域网络扩展系统规模 在扩大系统规模时，不会直接在通信网络中造成瓶颈 模块化和可延展性 模块化使能方便地为异构处理器实例化功能模块，相同功能的模块可以有不同的具体实现 由于模块化使处理器能够被替换，分布式系统易于延展到多种硬件架构上 与并行计算的关系并行系统的分类 多处理器系统：多个处理器能够直接访问构成公用地址空间的共享内存，但通常没有公用的时钟 多计算机系统：多个处理器无法直接访问共享内存，或者使用的内存不构成公用地址空间，通常没有统一的时钟，但通过互连网络连接在一起 阵列处理器系统：物理上放置在一起，具有统一的物理时钟，但可能没有共享内存和数据传输的处理器阵列，例如数字信号处理和某些图像处理应用 UMA和NUMA多处理器系统UMA(uniform memory access), 一致性内存访问 多个处理器访问各自的内存 NUMA(non-uniform memory access), 非一致性内存访问: 多个处理器访问共享内存 多处理器系统两种流行的互联网络 Omega互联函数 为连接n个处理器到n个内存单元，只需用 $\\frac{n}{2}log_2 n$ 个2x2的交换单元 每一层编号i的交换单元连下一层编号j的交换单元，其中 j = \\begin{cases} 2i & 0 \\leq i \\leq n/2 - 1, \\\\ 2i + 1 - n & n/2 \\leq i \\leq n - 1. \\end{cases} Butterfly互联函数 所需要的交换单元个数与Omega互联函数的一样，为连接n个处理器到n个内存单元，只需用 $\\frac{n}{2}log_2 n$ 个2x2的交换单元 与Omega互联函数的区别：相邻两级之间互联模式不仅依赖于n, 而且依赖于级号s第s级第x个交换单元与第s+1层第y个交换单元相连，其中x和y满足关系： x_{s+1} xor y_{s+1} = 1 这里 $x(s+1)$ 和 $y(s+1)$ 分别是x和y的第（s+1）个MSB位(Most Significant Bit) 多计算机的圆环面和超立方体拓扑 超立方体与海明距离 超立方体中的两个计算机的距离由消息要经过的交换单元(路由)个数来定义 上述距离恰好是这两个计算机的编号的海明距离 两个非负整数的海明距离=它们的二进制表示有多少个位不相同 Flynn分类法与耦合度 耦合的松紧由软、硬模块的相互依存关系决定 SISD MISD 有共同时钟，所以是紧耦合 SIMD 有共同时钟，所以是紧耦合 MIMD 松耦合 并行系统和分布式系统的比较 分布式系统通常是松耦合多计算机系统 各个计算机间没有共享内存，也没有共同的时钟 物理上共同放置的多计算机系统在通信延迟上相对较小，这种系统同时是并行系统与分布式系统 物理上分开放置的系统通信延迟相对较大，这种系统是传统意义上的分布式系统，但与并行系统有所差别 共同术语 耦合 加速比：T(1) / T(n)，其中n是处理器个数 并行度：有效执行CPU指令所占的时间比例 有效执行的操作是除去等待通信的操作 并发度：本地操作与全局操作在数目上的比例 本地操作：非通信、非共享内存访问 全局通信：通信或共享内存访问 粒度：计算总量与通信总量的比例 分布式计算的两种范例 消息传递分布式系统 没有公共时钟，没有公共地址空间 靠消息传递来通信和相互协作 共享内存分布式系统 没有公共时钟，没有公共地址空间 一个进程的共享区域在另一个进程中用的是不同的地址 利用共享内存中的共享区域来通信和相互协作 范例的等价性 在共享内存的系统上仿真消息传递 发送：写共享区域，然后激发同步原语 接收：激发同步原语，然后读共享区域 在消息传递的系统上仿真共享内存 读共享区域：向共享区域拥有者发送查询请求的消息，然后接收对方的回复消息 写共享区域：向共享区域拥有者发送更新数据的请求消息 分布式计算的原语 分类一：同步和异步 如果一个操作原语与对方实现了握手（得到对方响应确认后再开始操作），则称其操作是同步的 如果一个操作原语没有与对方握手，则称其操作是异步的 分类二：阻塞和非阻塞 如果一个操作原语在处理完成之后才返回调用流程，则称其操作是阻塞的 如果一个操作原语在处理完成之前就返回调用流程，则称其操作是非阻塞的 非阻塞发送原语的例子1234Send(X, destination, handle_k) // handle_k is a return parameter......Wait(handle_1, handle_2, ..., handle_k, ..., handle_m) // Wait always blocks 一些原语库与标准 MPIPVMSocketSun RPCCORBADCOM 同步与异步执行同步执行的例子 异步执行的例子 分布式计算模型的动机和主要思想 动机：解决分布式计算中的不确定性所带来的控制困难 不确定性一：通信网络的延迟难以预测 不确定性二：不存在一个能随时访问的全局时钟 困难：当发生通信超时、处理器失效、链路层崩溃等情况时，通信消息可能会在传递过程中乱序、丢失、被篡改或重复传送 解决该困难的主要思想： 用有向图对分布式系统进行建模 节点表示处理器 有向边代表单向通信信道 通过该有向图来管理分布式计算中事件与事件之间的因果关系 分布式程序 一个分布式程序由一组n个异步进程 $p_1, p_1, ⋯, p_n$ 组成，它们之间通过通信网络进行消息传递 一般性的假设： 不同的进程运行在不同的处理器上 进程间没有可共享的全局存储，只能通过消息传送来进行联系 通信延迟是有限的但无法预测 这些进程不共享一个可随时访问的全局时钟 进程的运行和消息的传送都是异步的 分布式运行模型事件和状态 事件的定义：进程运行中的原子动作 事件的分类：内部事件、消息发送事件和消息接收事件 事件的符号：进程 $p_i$ 上的第x个事件记作 $e_i^x$ 事件对系统状态的影响： 内部事件改变所处的进程的状态 消息发送事件和消息接收事件改变事件中收发双方的状态 事件的顺序 单个进程中的事件顺序: 进程 $p_i$ 上的 $e_i^1, e_i^2, ⋯, e_i^x, e_i^{x+1}, ⋯$ 这些事件的集合记为 $hi$, 顺序记为 $→𝑖$ , 序列记为 $H_i=(h_i,→_i)$ 关系 $→_i$ 表示了 $p_i$ 的事件间的因果依赖 消息发送和接收双方之间的因果依赖： 记消息m的发送事件为send(m), 接收事件为rec(m), 则有 $send(m) →_{msg}rec(m)$ 时空图 因果优先关系 逻辑并发和物理并发 在一次分布式计算中 两个事件是逻辑并发的，当且仅当它们之间无因果影响 两个事件是物理并发的，当且仅当它们在同一物理时间发生 两个或更多个事件可能是逻辑并发的，即使它们不是物理并发的 前面时空图中的 $e_1^3, e_2^4, e_3^3$ 是逻辑并发的，但不是物理并发 通信网络模型 分类： 先进先出(FIFO): 信道由先进先出的消息队列来维持 非先进先出(非FIFO): 信道由能随机加入消息和取出消息的集合来维持 因果序(CO: causal ordering): 对任意两个消息 $m{ij}$ 和 $m{kj}$ , 由 $m{ij} → m{kj} ⟹ send(m{ij}) → send(m{kj}) ∧ rec(m{ij}) → rec(m{kj})$ CO ⊂ FIFO ⊂ 非FIFO 由上述因果序定义的因果依赖模型大大简化了分布式算法的设计，因为它提供了一个内存的同步机制 分布式系统的全局状态定义：分布式系统的全局状态是其各组成部件的本地状态的集合，包括各个处理器状态和所有通信信道状态 分类: 处理器状态：寄存器状态、堆栈状态、本地内存状态等，依赖于分布式应用的本地语义 通信信道状态：由信道中传输的消息集合给出 处理器状态 $LS_i^0$ 表示进程 $p_i$ 的初始状态 $LS_i^x$ 表示进程 $p_i$ 在发生了事件 $e_i^x$ 但还没有发生事件 $e_i^{x+1}$ 时的状态 关系 $send(m) \\leq {LS}_i^x$ 表示 $∃y:1≤y≤x::e_i^y=send(m)$ 关系 $rec(m) \\leq {LS}_i^x$ 表示 $∃y:1≤y≤x::e_i^y=rec(m)$ 关系 $send(m) \\not\\leq {LS}_i^x$ 表示 $∀y:1≤y≤x::e_i^y≠send(m)$ 关系 $rec(m) \\not\\leq {𝐿𝑆}_i^x$ 表示 $∀y:1≤y≤x::e_i^y≠rec(m)$ 信道状态 ${𝑆𝐶}{ij}^{x,y}$ 表示进程 $p_i$ 和进程 $p_j$ 之间的信道 $C{ij}$ 的状态 ${𝑆𝐶}{ij}^{x,y} = { m{ij}│send(m{ij})≤{LS}_i^x⋀rec(m{ij})≰ {𝐿𝑆}_j^y }$ ${𝑆𝐶}_{ij}^{x,y}$ 的元素是进程 $p_i$ 直到事件 $e_i^x$ 发送的并且进程 $p_j$ 直到事件 $e_j^y$ 未收到的消息，换句话说，就是直到事件 $e_i^x$ 和e_j^y$ 仍然在该信道中传输的消息 全局状态 分布式系统的全局状态是所有处理器本地状态以及信道状态的集合 全局状态GS可定义为 GS = \\{ \\bigcup_𝑖 {LS}_i^{x_i}, \\bigcup_{j,k}{SC}_{jk}^{x_j,y_k} \\} 全局状态的意义： 所有部件的状态无法在同一瞬间被记录，而上述全局状态去掉了这个要求 上述全局状态的依据：一个消息如果没有被发送，也就不可能会被接收 一致性和非一致性全局状态一个全局状态 GS = \\{ \\bigcup_𝑖 {LS}_i^{x_i}, \\bigcup_{j,k}{SC}_{jk}^{x_j,y_k} \\}是一个一致性全局状态，如果它满足如下条件: \\forall m_{ij}: send(m_{ij}) \\not\\leq {LS}_i^{x_i} ⇒ m_{ij} \\not\\in {SC}_{ij}^{x_i,y_j} \\bigwedge rec(m_{ij}) \\not\\leq {LS}_j^{y_j} 不满足上述条件的全局状态是非一致性的全局状态，如前面时空图的 ${ {LS}_1^1, {LS}_2^3, {LS}_3^3, {LS}_2^4 }$ 非中转和强一致 全局状态 $GS = { \\bigcup𝑖 {LS}_i^{x_i}, \\bigcup{j,k}{SC}{jk}^{x_j,y_k} }$ 是非中转的，如果对任意j和k，都有 ${SC}{jk}^{x_j,y_k}$ 为空集 一个全局状态是强一致的，如果它同时是非中转的和一致性的 分布式计算的运行分割分割线的概念和定义 概念： 画一条曲线C与每条进程线相交且仅相交一个点，把整个计算过程分割为两部分 左边部分记作PAST(C), 表示C处已发生的所有事件，右边部分记作FUTURE(C)，表示C处未发生的所有事件 上述曲线称为一条分割线，每条分割线对应一个全局状态，每个全局状态可以图形化为时空图上的一条分割线 定义： 如果 $ei^{max{PAST_i(C)}}$ 表示进程 $p_i$ 上的PAST(C)中最新的事件，那么由分割线C所表示的全局状态是 ${ \\bigcup_i{LS}_i^{max{PAST_i(C)}}, \\bigcup{j,k}{SC}_{jk}^{max{PAST_k(C)}} }$ 分割线与全局状态一致性的关系 一条分割线所对应的全局状态是一致的，如果所有跨越分割线的消息都是从分割线的PAST集发送，到其FUTURE集接收 一条分割线所对应的全局状态是不一致的，如果存在一条消息从分割线的FUTURE集发送，到其PAST集接收 图中𝐶_1的全局状态是非一致的，𝐶_2的全局状态是一致的 事件的过去和未来锥面 进程通信模型同步通信 优点：简单 缺点：效率低，并且容易造成死锁 异步通信 优点：高度的并行性 缺点：复杂的缓冲管理机制和困难的通信方式设计、验证和实现","categories":[],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"https://chenfeng.github.io/tags/分布式计算/"}]},{"title":"随机并行算法(Randomized Algorithm)","slug":"parellel_and_distributed_computing/paralell_compute9","date":"2017-04-24T16:00:00.000Z","updated":"2017-05-01T01:12:45.609Z","comments":true,"path":"2017/04/25/parellel_and_distributed_computing/paralell_compute9/","link":"","permalink":"https://chenfeng.github.io/2017/04/25/parellel_and_distributed_computing/paralell_compute9/","excerpt":"(并行与分布式计算八) 随机并行算法简介随机算法：使用了随机数生成器(random-number generator)的算法 随机算法的分析基于概率论(Probability Theory)基本事实 伯努利随机试验: $Pr{X \\geq m} = \\sum{j=m}^n (_j^n)p^jq^{n-j}$ 切尔诺夫界/不等式(Chernoff bounds): $P_r{ X \\leq (1 - \\epsilon)pn } \\leq e^{-\\epsilon^2np/2}$ $P_r{ X \\geq (1 + \\epsilon)pn } \\leq e^{-\\epsilon^2np/3}$","text":"(并行与分布式计算八) 随机并行算法简介随机算法：使用了随机数生成器(random-number generator)的算法 随机算法的分析基于概率论(Probability Theory)基本事实 伯努利随机试验: $Pr{X \\geq m} = \\sum{j=m}^n (_j^n)p^jq^{n-j}$ 切尔诺夫界/不等式(Chernoff bounds): $P_r{ X \\leq (1 - \\epsilon)pn } \\leq e^{-\\epsilon^2np/2}$ $P_r{ X \\geq (1 + \\epsilon)pn } \\leq e^{-\\epsilon^2np/3}$ PRAM模型需要加入一些特征 主要为每个处理器能够在一步时间内产生有限范围内的随机数 设正整数范围为[1, 2, …, M], 限制产生的随机数长度为O(logn)bits，其中n是输入的长度 这样的随机数能够在一个内存位置中出现，因此可用O(1)步完成 k个处理器产生k的独立的随机数 randomized PRAM high-likelihood bounds(高可能性边界): 一个随机并行算法需要的资源上界 $f(n)$: 对于任意的输入n，该算法使用的资源数量有 $1 - n^{-c}$的概率最多为 $\\alpha f(n)$, 其中 $\\alpha$ 和c是正的常数 $O(f(n))$ 两种类型的随机算法: Las Vegas(拉斯维加斯)算法 总是产生正确的解 性能用期望资源使用数或使用资源的上界的概率衡量 Monte Carlo(蒙特卡洛)算法 允许存在误差，但保持在足够小的概率 优点：简单、易实现、易并行、性能往往比较好 缺点：性能也随机，快慢不总是一样 在图中找分数阶的独立集(Fractional Independent Set)可平面图G = (V, E): 可映射到平面上且边不相交 aim: to identify a large independent set of G consisting excusively of low-degree vertices 图G的顶点集合为V，找出集合 $X \\subseteq V$ ，使得 X中每一顶点v的度小于等于某个常量d 集合X是独立的，即X中任意两个定点不相邻(没有边连接) 集合X满足 $|X| \\geq c|V|$(对某个正常数c) X即为图G的一个分数阶的独立集 给定图G=(V,E)，定义其分数阶的独立集X满足下面三个条件： 低度性：存在常数d，使X是顶点度数小于d的顶点组成的V子集 独立性：X中的任意两点都在G中不相邻 分数阶：存在正的常数c，使|X|不小于c|V| 引理9.1: 平面图G = (V, E), |V| &gt; 2, 则 $|E| \\leq 3|V| - 6$ 定理9.2: 任意平面图G = (V, E)都能在线性串行时间内建立一个分数阶独立集X 令 $V_d$ 为G的一个阶不大于d的顶点子集(d &gt;= 6) 令$Vh = V - V_d$ ，则 $\\sum{v \\in V_h}deg(v) \\geq (d + 1)|V_h|$ $(d + 1)|Vh| \\leq \\sum{v \\in V}deg(v) \\leq 6|V| - 12$ $|V_h| \\leq (6|V| - 12)/(d + 1)$ $|v_d| = |V| - |V_h| \\geq (d - 5)|V|/(d + 1)$ 构造分数阶独立集X： 从 $V_d$ 中选择任意的顶点v，除去所有v在 $V_d$ 中邻接的顶点 再选 $V_d$ 的另外一个顶点重复以上步骤 重复直到遍历 $V_d$ 中所有顶点 $|X| \\geq |V_d|/(d + 1) \\geq (d - 5)|V|/(d + 1)^2$，是|V|的函数 有向环(directed cycles)求有向环G = (V, E)上的分数阶独立集 Algorithm 9.112345678(Randomized Symmetry Breaking)Input: A directed cycle G = (V, E) whose arcs are specified by an array S of length n.Output: The set of vertices X = &#123;v \\in V | label(v) = 1&#125;, which forms a fractional independent set with high probability.begin for all v \\in V pardo 1. Assign label(v) = 1 or 0 randomly with equal probability. 2. if (label(v) = 1 and label(S(v)) = 1) then set label(v) := 0end T(n) = O(1), W = O(n) 复杂度分析 独立的伯努利随机试验：n/2（两点距离&gt;1即可） 顶点被选（最终label为1）的概率：1/4 在独立试验中的平均被选率：n/8 最终被选的包括独立试验的和非独立试验的 $ P_r{|X| \\leq \\alpha n} \\leq e^{-\\beta n} $ (由Chernoff bounds得) 其中$ 0 &lt; \\alpha &lt; 1/8 $, $ \\beta = (1 - 8\\alpha)^2/16 $ 可平面图(planar graphs)求任意可平面图G = (V, E)上的分数阶独立集 Algorithm 9.212345678910111213(Fractional Independent Set)Input: A planar graph G = (V, E) represented by its edge lists. The edges on the list of a vertex v are ordered counterclockwise as they appear around the vertex v in a planar embedding of G. Output: A labeled set of low-degree vertices forming a large independent set with high probability. begin 1. for each vertex v in V pardo if (deg(v) &lt;= 6) then set lowdeg(v) := 1 else set lowdeg(v) := 0 2. for each vertex v in V pardo if (lowdeg(v) = 1) then Randomly assign label(v) := 0 or 1 with equal probability 3. for each vertex v in V pardo if (label(v) = 1) then if (label(u) = 1 for some u on the list of v) then set label(v) := 0end T(n) = O(1), W = O(n) 复杂度分析 参数d取为6 独立的伯努利随机试验：$|V_d|/36$（两点距离&gt;2即可） 成功率：1/27 独立试验中的平均成功点数至少为： $|V_d|/36 * 1/27$ 最终被选的包括独立试验的和非独立试验的 $ P_r {|X| \\leq \\alpha n } \\leq e^{-\\beta n} $ $\\alpha$ 和 $\\beta$为常量 字符串匹配的随机并行算法基本策略类似于hashing hash函数将集合U映射到一个整数范围之内([1, 2, …, r]) u -&gt; h(u) 将长度为m的字符串映射为O(logm)比特的整数(fiingerprint)：两个不同的字符创映射到同一个整数的概率极其低(前提是hash函数选得好) 关键思想： 指纹(Fingerprints): 把字符串匹配问题转换为固定几个整数的比较问题 随机选质数，作为除数对指纹的整数求余，使余数的长度上界能固定 用比较余数来代替比较指纹整数 最终算法达到右面三个要求: property 9.1: 对任意字符串 $X \\in B$, $f_p(X)$ 由O(logm)比特组成，对每个$p \\in S$ property 9.2: 随机选择 $\\mathcal{F}$ 中的一个$f_p$，将两个不同的字符串X和Y映射到D中同一元素的概率非常小 property 9.3: 对每个$p \\in S$, $f_p(X)$很容易并行地计算，对所有B中的字符串 指纹函数 文本字符串T长度为n，模式字符串P长度为m，$m \\leq n$ 确定P在T中出现的所有位置 令集合B为T的所有长度为m的子字符串的集合，起始位置i($ 1 \\leq i \\leq n-m+1 $) 问题转化成确定B中元素是否和P相同 令 $\\mathcal{F} = { fp }{p \\in S}$为函数集合，其中 $f_p$ 将长度为m的字符串映射到值域D中 $\\mathcal{F}$ 必须满足以下三个特性： 1.对任意字符串 $X \\in B$, $f_p(X)$ 由O(logm)比特组成，对每个$p \\in S$ 2.随机选择 $\\mathcal{F}$ 中的一个$f_p$，将两个不同的字符串X和Y映射到D中同一元素的概率非常小 3.对每个$p \\in S$, $f_p(X)$很容易并行地计算，对所有B中的字符串 $f_p(X)$称为字符串X的指纹(fingerprint) 满足以上性质的指纹函数 由{0, 1}组成的字符串 将{0, 1}映射到 整数环Z上的2*2矩阵 (满足性质2但不满足1和3) f(0) = \\left[ \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\end{matrix} \\right]f(1) = \\left[ \\begin{matrix} 1 & 1 \\\\ 0 & 1 \\end{matrix} \\right] 对字符串XY，f(XY)=f(X)f(Y)(Z上的矩阵乘法) 指纹是一一对应的 通过比较行内元素的大小，可以知道最后是0还是1（0是左大右小，1是左小右大） 而矩阵f(0)和f(1)的逆是已知的，可以右乘最后一位的逆矩阵来从指纹中删除最后一位，从而可以依次知道倒数第1、2、3、…位 e.g. X = 1011 f(X) = f(1)f(0)f(1)f(1) f(X) = $\\left[\\begin{matrix}1 &amp; 1 \\0 &amp; 1\\end{matrix}\\right] \\left[ \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\end{matrix} \\right]\\left[\\begin{matrix}1 &amp; 1 \\0 &amp; 1\\end{matrix}\\right]$$\\left[\\begin{matrix}1 &amp; 1 \\0 &amp; 1\\end{matrix}\\right]$ = $\\left[\\begin{matrix}2 &amp; 5 \\1 &amp; 3\\end{matrix}\\right]$ 指纹的增长速度(不满足性质1) X长度为m，则f(X)的每个元是不大于 $F{m+1}$ 的整数，其中 $F{m+1}$ 是第(m + 1)个斐波那契数($ F1 = F_2 = 1, F{m + 1} = Fm + F{m - 1} $) f(X)的元会大至 $F_{m + 1} \\approx \\frac{\\phi^{m+1}}{\\sqrt{5}}$ $ \\phi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618… $ 解决指纹增长过快的问题 令p为[1, 2, …, M]内的素数，令 $Z_p$ 为模p的整数环 定义 $f_p(X) = f(X)$ module p e.g X = (1011)^4, 长度为16 f(X) = $\\left[\\begin{matrix}206 &amp; 575 \\115 &amp; 321\\end{matrix}\\right]$ 给定素数p = 7 f(X) = $\\left[\\begin{matrix}3 &amp; 1 \\3 &amp; 6\\end{matrix}\\right]$ 引理9.4: 对任意整数 $m \\geq 17$ , 有 $ \\frac{m}{\\ln m} \\leq \\pi(m) \\leq 1.2551\\frac{m}{\\ln m} $ 引理9.5: 给定正数 $u \\leq 2^m$, u的不等质因数的数量为 $\\pi(m)$, 当 $m \\geq 29$ 时 随机化匹配产生错误的概率 $f_p$为从函数集合 $\\mathcal{F} = {f_p}$ 中随机选取的函数，其中p是范围[1, 2, …, M]内的素数 任意两个长度为m的不同字符串产生错误匹配的概率不大于 $\\frac{\\pi(\\lfloor2.776m\\rfloor)}{\\pi(M)}$, $m \\geq 11$ 推论9.1: 选取的素数在$[1, 2, …, m^k]$范围内，则两个长度为m的字符串产生错误匹配的概率不大于 $\\frac{3.48k}{m^{k-1}}$, k &gt; 1 $\\pi(\\lceil2.776m\\rceil) \\leq 1.2551 \\frac{2.776m}{\\ln(2.776m)} \\approx \\frac{3.48m}{\\ln(2.776m)}$ $\\pi(m^k) \\geq \\frac{m^k}{\\ln m^k} = \\frac{m^k}{k\\ln m}$ 随机选取的指纹函数 $f_p \\in \\mathcal{F}$, p为[1, 2, …, M]中的素数，t对字符串产生错误匹配的概率上界为 $\\frac{\\pi(\\lceil2.776mt\\rceil)}{\\pi(M)}$, $mt \\geq 11$ 推论9.2: 任意一个正整数常量k，$M = mt^k$, t对长度为m字符串产生错误匹配的概率为 $O(\\frac{1}{t^{k-1}})$ Algorithm 9.4123456789101112(Monte Carlo String Matching)Input: Two arrays T(1:n) and P(1:m) representing the text and the pattern strings, respectively, and an integer M.Output: The array MATCH indicating all the positions where the pattern occurs in the text.begin 1. for 1 &lt;= i &lt;= n-m+1 pardo Set MATCH(i) := 0 2. choose a random prime in the range [1, 2, ..., M], and compute f_p(P) 3. for 1 &lt;= i &lt;= n-m+1 pardo Set L_l := f_p(T(i : i+m-1)) 4. for 1 &lt;= i &lt;= n-m+1 pardo if (L_l = f_p(P)) then Set MATCH(i) := 1end T(n) = O(logn), W(n) = O(n) 快速排序的随机并行算法Algorithm 9.5123456789101112(Randomized Quicksort)Input: An array A containing the n elements to be sorted.Output: The Array A in sorted order.begin 1. if n &lt;= 30 then sort A using any sorting algorithm and exit. 2. Select a random element S(A) of A. 3. for 1 &lt;= i &lt;= n pardo A(i) &lt; S(A): Set mark(i) := 1 A(i) &gt; S(A): Set mark(i) := 0 4. Compact the elements of A marked 1 at the beginning of A, followed by S(A), which is followed by the elements marked 0. Set k equal to the position of the element S(A). 5. Recursively sort the subarrays A(1:k-1) and A(k+1:n).end $T(n) = O(log^2 n)$; $W(n) = O(nlogn)$","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"应用层 Application Layer","slug":"computer_network/computer_network_2","date":"2017-04-18T16:00:00.000Z","updated":"2017-04-22T13:08:04.484Z","comments":true,"path":"2017/04/19/computer_network/computer_network_2/","link":"","permalink":"https://chenfeng.github.io/2017/04/19/computer_network/computer_network_2/","excerpt":"应用层协议原理 principles of network applications网络应用体系结构(application architecture): 客户-服务器体系结构(client-server architecture) server: always-on host permanent IP address data centers for scaling","text":"应用层协议原理 principles of network applications网络应用体系结构(application architecture): 客户-服务器体系结构(client-server architecture) server: always-on host permanent IP address data centers for scaling clients: communicate with server may be intermittently connected may have dynamic IP addresses do not communicate directly with each other P2P体系结构(P2P architecture): peer-to-peer no always-on server arbitrary end systems directly communicate peers request service from other peers, provide service in return to other peers: self scalability – new peers bring new service capacity, as well as new service demands 自扩展性(self-scalability) peers are intermittently connected and change IP addresses:complex management 进程(process)通信process: program running within a host within same host, two processes communicate using inter-process communication(defined by OS) processes in different hosts communicate by exchanging messages 客户和服务器进程:在一对进程之间的通信会话场景中，发起通信(即在该会话中开始时发起与其他进程的联系)的进程被标识为客户，在会话开始时等待联系的进程是服务器 client process: process that initiates communication server process: process that waits to be contacted aside: applications with P2P architectures have client processes &amp; server processes 进程与计算机网络之间的接口：应用程序编程接口(Application Programming Interface, API) 套接字(socket) process sends/receives messages to/from its socket socket analogous to door: sending process shoves message out door sending process relies on transport infrastructure on other side of door to deliver message to socket at receiving process 应用程序开发者对运输层的控制仅限于 选择运输层协议 设定运输层参数如最大缓存和最大报文段长度等 进程寻址： 主机地址：IP地址(IP address) 目的主机宏接受进程的标识符：端口号(port number) to receive messages, process must have identifier host device has unique 32-bit IP address Q: does IP address of host on which process runs suffice for identifying the process? A: no, many processes can be running on same host identifier includes both IP address and port numbers associated with process on host. example port numbers: HTTP server: 80 mail server: 25 应用程序可用运输服务 可靠数据传输(reliable data transfer) 容忍丢失的应用(loss-tolerant application) 吞吐量 带宽敏感的应用(bandwidth-sensitive application) 弹性应用(elastic application) 定时 安全性 data integrity some apps (e.g., file transfer, web transactions) require 100% reliable data transfer other apps (e.g., audio) can tolerate some loss throughput some apps (e.g., multimedia) require minimum amount of throughput to be “effective” other apps (“elastic apps”) make use of whatever throughput they get timing some apps (e.g., Internet telephony, interactive games) require low delay to be “effective” security encryption, data integrity 因特网提供的运输服务QoS: Quantity of Service TCP服务：面向连接服务和可靠数据传输 TCP service: reliable transport between sending and receiving process flow control: sender won’t overwhelm receiver congestion control: throttle sender when network overloaded does not provide: timing, minimum throughput guarantee, security connection-oriented: setup required between client and server processes UDP服务：不提供不必要服务的轻量级运输协议，无连接的 UDP service: unreliable data transfer between sending and receiving process does not provide: reliability, flow control, congestion control, timing, throughput guarantee, security, or connection setup, 安全套接字层(Secure Sockets Layer, SSL): TCP的加强版本，增加安全性服务 TCP &amp; UDP: no encryption cleartext passwds sent into socket traverse Internet in cleartext SSL: provides encrypted TCP connection data integrity end-point authentication SSL is at app layer apps use SSL libraries, that “talk” to TCP SSL socket API cleartext passwords sent into socket traverse Internet encrypted 应用层协议(application-layer protocol) 交换的报文类型 报文类型的语法 字段的语义 进程何时及如何发送报文，对报文响应的规则 types of messages exchanged, e.g., request, response message syntax: what fields in messages &amp; how fields are delineated message semantics meaning of information in fields exchange rules for when and how processes send &amp; respond to messages open protocols: defined in RFCs allows for interoperability e.g., HTTP, SMTP proprietary protocols: e.g., Skype Telnet TELNET Protocol Offers three basic services: Defines network virtual terminal (NVT) Basic terminal operations standard interface Allows client and server negotiate options Treats both ends symmetrically No force on client; it can be arbitrary program Network Virtual Terminal: Different OS’s, different keys : Ctrl-c &lt;—&gt; ESC different End of line : CR, LF, CR-LF TELNET defines standard 7 bit US ASCII their interpretation of control(e.g., CR-13,LF-10) End of line is CR-LF Some 8 bit octets for control functions RLOGIN(REMOTE LOGIN)rlogin – understands Unix environment better Passes some terminal parameters automatically Trusted machines do not require password The Rlogin process uses the TCP port 513 文件传输协议: FTPFTP使用两个TCP连接传输文件 控制连接(control connection) 两主机之间传递控制信息：用户标识、口令、改变远程目录和’put’/‘get’等 带外传送(out-of-band) 数据连接(data connection) FTP命令和回答：7比特ASCII格式在控制连接上传送，每个命令跟回车换行符(区分命令) 每个命令4个大写字母ASCII字符，部分具有可选参数 e.g. USER username、PASS password、LIST、RETR filename、STOR filename 等 回答是一个3位数字，后跟可选信息e.g. 230 User login, OK、331 Uername OK, Password require、125 Data connection already open; transfer starting、425 Can’t open data connection、452 Error writing file 等 TFTP(Trivial File Transfer Protocol)TFTP is intended for application with simple needs: Simple file transfer w/o authentication Software is much smaller than FTP Small size of software is importante.g., in ROM for booting diskless workstations Uses UDP instead of TCP Less reliable Using timeout and retransmission TFTP Reliability: Minimal error handling Most errors result in termination Web和HTTP web page consists of objects object can be HTML file, JPEG image, Java applet, audio file,… web page consists of base HTML-file which includes several referenced objects each object is addressable by a URL web的应用层协议：超文本传输协议(HyperText Transfer Protocol, HTTP) HTTP: hypertext transfer protocol — Web’s application layer protocol client/server model client: browser that requests, receives, (using HTTP protocol) and “displays” Web objects server: Web server sends (using HTTP protocol) objects in response to requests uses TCP: client initiates TCP connection (creates socket) to server, port 80 server accepts TCP connection from client HTTP messages (application-layer protocol messages) exchanged between browser (HTTP client) and Web server (HTTP server) TCP connection closed 无状态协议(stateless protocol) HTTP is “stateless”:server maintains no information about past client requests protocols that maintain “state” are complex! past history (state) must be maintained if server/client crashes, their views of “state” may be inconsistent, must be reconciled 非持续连接(non-persistent connection): 每一个请求/响应对是经一个单独的TCP连接发送，如HTTP1.0 non-persistent HTTP: at most one object sent over TCP connection, connection then closed downloading multiple objects required multiple connections suppose user enters URL: www.someSchool.edu/someDepartment/home.index (contains text, references to 10 jpeg images) 1a. HTTP client initiates TCP connection to HTTP server (process) at www.someSchool.edu on port 80 1b. HTTP server at host www.someSchool.edu waiting for TCP connection at port 80. “accepts” connection, notifying client HTTP client sends HTTP request message (containing URL) into TCP connection socket. Message indicates that client wants object someDepartment/home.index HTTP server receives request message, forms response message containing requested object, and sends message into its socket HTTP server closes TCP connection. HTTP client receives response message containing html file, displays html. Parsing html file, finds 10 referenced jpeg objects Steps 1-5 repeated for each of 10 jpeg objects 持续连接(persistent connection): 所有的请求及其响应经相同的TCP连接发送，如HTTP1.1 persistent HTTP: multiple objects can be sent over single TCP connection between client, server response time往返时间(Round-Trip Time, RTT): 一个短分组从客户到服务器然后在返回客户的时间 RTT (definition): time for a small packet to travel from client to server and back HTTP response time: one RTT to initiate TCP connection one RTT for HTTP request and first few bytes of HTTP response to return file transmission time non-persistent HTTP response time = 2RTT+ file transmission time non-persistent HTTP issues: requires 2 RTTs per object OS overhead for each TCP connection browsers often open parallel TCP connections to fetch referenced objects persistent HTTP: server leaves connection open after sending response subsequent HTTP messages between same client/server sent over open connection client sends requests as soon as it encounters a referenced object as little as one RTT for all the referenced objects HTTP报文格式two types of HTTP messages: request, response HTTP request message: ASCII (human-readable format) 请求报文 请求行(request line): 方法字段、URL字段、HTTP版本字段 首部行(header line)(多个) 实体体(entity body)(POST方法才使用实体体) POST method: web page often includes form input input is uploaded to server in entity body URL method: uses GET method input is uploaded in URL field of request line: www.somesite.com/animalsearch?monkeys&amp;banana HTTP/1.0: GET / POST / HEAD(asks server to leave requested object out of response) HTTP/1.1: GET, POST, HEAD PUT(uploads file in entity body to path specified in URL field) DELETE(deletes file specified in the URL field) 响应报文 初始状态行(status line): 协议版本字段、状态码、相应状态信息 首部行(多个) 实体体(entity body) status code appears in 1st line in server-to-client response message. some sample codes: 200 OK(request succeeded, requested object later in this msg) 301 Moved Permanently(requested object moved, new location specified later in this msg (Location:)) 400 Bad Request(request msg not understood by server) 404 Not Found(requested document not found on this server) 505 HTTP Version Not Supported Trying out HTTP (client side) for yourself: 用户和服务器的交互: cookiecookie技术有四个组件: 在HTTP响应报文中的一个cookie首部行 在HTTP请求报文中的一个cookie首部行 在用户端系统中保留有一个cookie文件，由浏览器进行管理 位于Web站点的一个后端数据库 many Web sites use cookiesfour components: 1) cookie header line of HTTP response message2) cookie header line in next HTTP request message3) cookie file kept on user’s host, managed by user’s browser4) back-end database at Web site example: Susan always access Internet from PC visits specific e-commerce site for first time when initial HTTP requests arrives at site, site creates: unique ID entry in backend database for ID what cookies can be used for: authorization shopping carts recommendations user session state (Web e-mail) how to keep “state”: protocol endpoints: maintain state at sender/receiver over multiple transactions cookies: http messages carry state cookies and privacy: cookies permit sites to learn a lot about you you may supply name and e-mail to sites Web缓存Web缓存器(web cache)/代理服务器(proxy server): 代表初始Web服务器满足HTTP请求的网络实体 Web缓存器可以大大减少对客户请求的响应时间，特别是当客户与初始服务器之间的瓶颈带宽远低于客户与Web缓存器之间的瓶颈带宽时。 Web缓存器能够大大减少一个机构的接入链路到因特网的通信量。 goal: satisfy client request without involving origin server user sets browser: Web accesses via cache browser sends all HTTP requests to cache object in cache: cache returns object else cache requests object from origin server, then returns object to client cache acts as both client and server server for original requesting client client to origin server typically cache is installed by ISP (university, company, residential ISP) why Web caching: reduce response time for client request reduce traffic on an institution’s access link Internet dense with caches: enables “poor” content providers to effectively deliver content (so too does P2P file sharing) example: assumptions: avg object size: 100K bits avg request rate from browsers to origin servers:15/sec avg data rate to browsers: 1.50 Mbps RTT from institutional router to any origin server: 2 sec access link rate: 1.54 Mbps consequences: LAN utilization: 0.15% access link utilization = 99% total delay = Internet delay + access delay + LAN delay = 2 sec + minutes + usecs example: fatter access link raise access link rate to 154 Mbps access link utilization will change to 0.99% total delay will be 2sec and msecs and usecs example: install local cache Calculating access link utilization, delay with cache: suppose cache hit rate is 0.4; 40% requests satisfied at cache, 60% requests satisfied at origin access link utilization: 60% of requests use access link data rate to browsers over access link = 0.6*1.50 Mbps = .9 Mbps; utilization = 0.9/1.54 = .58 total delay = 0.6 (delay from origin servers) + 0.4 (delay when satisfied at cache) = 0.6 (2.01) + 0.4 (~msecs) = ~ 1.2 secs less than with 154 Mbps link (and cheaper too!) 内容分发网络(Content Distribution Network, CDN): 地理上分散的Web缓存器 条件GET方法conditional GET方法: HTTP协议允许缓存器证实它的对象是最新的的一种机制 请求报文使用GET方法，并且请求报文中包含一个”If-Modified-Since:”首部行 Goal: don’t send object if cache has up-to-date cached version no object transmission delay lower link utilization cache: specify date of cached copy in HTTP request If-modified-since: server: response contains no object if cached copy is up-to-date: HTTP/1.0 304 Not Modified 因特网中的电子邮件(Electronic mail)3个主要组成部分: 用户代理(user agent)、邮件服务器(mail server)、简单邮件传输协议(Simple Mail Transfer Protocol, SMTP) 邮箱(mailbox) User Agent a.k.a. “mail reader” composing, editing, reading mail messages; e.g., Outlook, Thunderbird, iPhone mail client outgoing, incoming messages stored on server mail servers: mailbox contains incoming messages for user message queue of outgoing (to be sent) mail messages SMTP protocol between mail servers to send email messages client: sending mail server “server”: receiving mail server SMTP限制所有邮件报文的体部分职能采用7比特ASCII码表示 HTTP是一个拉协议(pull protocol): 某些人在Web服务器上装载信息，用户使用HTTP从该服务器拉取这些信息 SMTP是一个推协议(push protocol): 发送邮件服务器把文件推向接受邮件服务器 SMTP [RFC 2821]: uses TCP to reliably transfer email message from client to server, port 25 direct transfer: sending server to receiving server three phases of transfer handshaking (greeting) transfer of messages closure command/response interaction (like HTTP) commands: ASCII text response: status code and phrase messages must be in 7-bit ASCII SMTP uses persistent connections SMTP requires message (header &amp; body) to be in 7-bit ASCII SMTP server uses CRLF.CRLF to determine end of message comparison with HTTP: HTTP: pull vs SMTP: push both have ASCII command/response interaction, status codes HTTP: each object encapsulated in its own response message vs SMTP: multiple objects sent in multipart message 邮件报文格式(Mail message format)和MIMEFrom: 首部行、To: 首部行、Subject: 首部行 SMTP: protocol for exchanging email messages RFC 822: standard for text message format: header lines, e.g., To: From: Subject: different from SMTP MAIL FROM, RCPT TO: commands!Body: the “message” ASCII characters only 邮件访问协议不能使用SMTP取回报文，取报文是一个拉操作而SMTP协议是一个推协议 SMTP: delivery/storage to receiver’s server mail access protocol: retrieval from server POP: Post Office Protocol [RFC 1939]: authorization, download IMAP: Internet Mail Access Protocol [RFC 1730]: more features, including manipulation of stored messages on server HTTP: gmail, Hotmail, Yahoo! Mail, etc. 第三版邮局协议(Post Office Protocol-Version 3, POP3) 三个阶段: 特许(authorization): 用户代理以明文形式发送用户名和口令以鉴别用户 事务处理: 用户代理取回报文，对报文做删除标记，取消报文删除标记，获取邮件的统计信息 更新: 客户发出quit命令退出POP3会话；邮件服务器删除被标记为删除的报文 邮件服务器回答: +OK正常 -ERR错误 authorization phaseclient commands: user: declare username pass: passwordserver responses +OK -ERRtransaction phase, client: list: list message numbers retr: retrieve message by number dele: delete quit more about POP3: POP3 “download-and-keep”: copies of messages on different clients POP3 is stateless across sessions 因特网邮件访问协议(Internet Mail Access Protocol, IMAP) keeps all messages in one place: at server allows user to organize messages in folders keeps user state across sessions: names of folders and mappings between message IDs and folder name DNS: 因特网的目录服务主机使用IP地址(IP address)进行标识 域名系统(Domain Name System, DNS)将主机名解析为IP地址 Internet hosts, routers: IP address (32 bit) - used for addressing datagrams “name”, e.g., www.yahoo.com - used by humans Q: how to map between IP address and name, and vice versa ? Domain Name System: distributed database implemented in hierarchy of many name servers application-layer protocol: hosts, name servers communicate to resolve names (address/name translation) note: core Internet function, implemented as application-layer protocol complexity at network’s “edge DNS是一个由分层的DNS服务器(DNS Server)实现的分布式数据库 DNS是一个使得主机能够查询分布式数据库应用层协议，运行在UDP之上，使用53号端口 主机别名(host aliasing): 通常规范主机名(canonical hostname)较为复杂 邮件服务器别名(mail server aliasing) 负载分配(load distribution): 冗余的服务器(e.g. Web服务器) DNS services: hostname to IP address translation host aliasing(canonical, alias names) mail server aliasing load distribution(replicated Web servers: many IP addresses correspond to one name) 单一DNS服务器(集中式设计)的问题(why not centralize DNS?): 单点故障(a single point of failure): DNS服务器崩溃会导致整个互联网瘫痪 通信容量(traffic volume): DNS查询体量极其大 远距离集中式数据库(distant centralized database) 维护(maintenance) 分布式设计方案(分布式层次数据库)根DNS服务器(13个)顶级域DNS服务器(一般域名 国家顶级域名 反向域名)权威DNS服务器 top-level domain (TLD) servers: responsible for com, org, net, edu, aero, jobs, museums, and all top-level country domains, e.g.: uk, fr, ca, jp Network Solutions maintains servers for .com TLD Educause for .edu TLD Top-Level Domain(TLD): Generic domains:.COM – commercial organizations.EDU – educational institutions.GOV – federal government institutions.MIL – United States military.NET – major network support centers.ORG – other organizations.INT – international organizations New Top Level Domains:| TLD | Spd/Unspd | Purpose || ———— | :———: | :——: || .aero | spd | Air-transport industry || .biz | Unspd | Businesses || .coop | spd | Cooperatives || .info | Unspd | Unrestricted use || .museum | spd | Museums || .name | Unspd | For registration by individuals || .pro | Unspd | Accountants, lawyers, physicians, and other professionals | Country Domains: Inverse domain: authoritative DNS servers: organization’s own DNS server(s), providing authoritative hostname to IP mappings for organization’s named hosts can be maintained by organization or service provider Zones and domains: Zone A primary server loads all information from the disk file; the secondary server loads all information from the primary server. When the primary downloads information from the secondary, it is called zone transfer. Authoritative Server Configuration(example): 本地DNS服务器(local DNS server): 严格上不属于DNS层次结构，但很重要 does not strictly belong to hierarchy each ISP (residential ISP, company, university) has one(also called “default name server”) when host makes DNS query, query is sent to its local DNS server has local cache of recent name-to-address translation pairs (but may be out of date!) acts as proxy, forwards query into hierarchy Name Resolution: Resolvers use UDP (single name) or TCP (whole group of names) Knowing the address of the root server is sufficient Resolvers use recursive query. Servers use iterative query. e.g.: client wants IP for www.amazon.com; 1st approximation: client queries root server to find com DNS server client queries .com DNS server to get amazon.com DNS server client queries amazon.com DNS server to get IP address for www.amazon.com contacted by local name server that can not resolve name root name server: contacts authoritative name server if name mapping not known gets mapping returns mapping to local name server 迭代查询(iterative query): 查询结果返回给请求者 contacted server replies with name of server to contact “I don’t know this name, but ask this server” host at cis.poly.edu wants IP address for gaia.cs.umass.edu: 递归查询(recusive query): 转发查询请求 puts burden of name resolution on contacted name server heavy load at upper levels of hierarchy? DNS Optimization: Spatial Locality: Local computers referenced more often than remoteTemporal Locality: Same set of domains referenced repeatedly -&gt; CachingCaching: each entry has a time to live (TTL)Replication: Multiple servers. Multiple roots. Ask the geographically closest server. DNS缓存(DNS caching): 改善时延性能并减少在因特网上到处传输的DNS报文数量 once (any) name server learns mapping, it caches mapping cache entries timeout (disappear) after some time (TTL) TLD servers typically cached in local name servers, thus root name servers not often visited cached entries may be out-of-date (best effort name-to-address translation!) if name host changes IP address, may not be known Internet-wide until all TTLs expire update/notify mechanisms proposed IETF standard, RFC 2136 DNS: distributed database storing resource records (RR, 提供主机名到IP地址的映射) RR format: (name, type, value, ttl) type=A name is hostname value is IP address type=NS name is domain (e.g., foo.com) value is hostname of authoritative name server for this domain type=CNAME name is alias name for some “canonical” (the real) name www.ibm.com is really servereast.backup2.ibm.com value is canonical name type=MX value is name of mailserver associated with name Resource Record Types:| Type | Meaning || —— | :———-: || A | Host Address || CNAME | Canonical Name (alias) || HINFO | CPU and O/S || MINFO | Mailbox Info || MX | Mail Exchanger || NS | Authoritative name server for a domain || PTR | Pointer to a domain name (link) || RP | Responsible person || SOA | Start of zone authority (Which part of naming hierarchy implemented) || TXT | Arbitrary Text | Inserting records into DNS: example: new startup “Network Utopia” register name networkutopia.com at DNS registrar (e.g., Network Solutions) provide names, IP addresses of authoritative name server (primary and secondary) register inserts two RRs into .com TLD server: (networkutopia.com, NS, dns1.networkutopia.com) (dns1.networkutopia.com, A, 212.212.212.1) create authoritative server type A record for www.networkuptopia.com; type MX record for networkutopia.com DNS报文: DNS查询和回答报文(query and reply both with same message format) message header: dentification: 16 bit # for query, reply to query uses same # flags: query or reply recursion desired recursion available reply is authoritative Domain names stored as series of labels 1 octet length (n) (top two bits of length are 00) n octet label Zero length marks end of name Attacking DNSDDoS attacks bombard root servers with traffic not successful to date traffic filtering local DNS servers cache IPs of TLD servers, allowing root server bypass bombard TLD servers potentially more dangerous redirect attacks man-in-middle Intercept queries DNS poisoning Send bogus relies to DNS server, which caches exploit DNS for DDoS send queries with spoofed source address: target IP requires amplification P2P应用Objectives of P2P: Share the resources (storage and bandwidth) of individual clients to improve scalability/ robustness Bypass DNS to find clients with resources! examples: instant messaging, skype Pure P2P architecture no always-on server arbitrary end systems directly communicate peers are intermittently connected and change IP addresses 40-70% of total traffic in many networks P2P Examples: File Sharing: BitTorrent, LimeWire Streaming: PPLive, PPStream, Zatto, … Research systems Collaborative computing: SETI@Home project Human genome mapping Intel NetBatch: 10,000 computers in 25 worldwide sites for simulations File distribution: client-server vs P2P:how much time to distribute file (size F) from one server to N peers peer upload/download capacity is limited resource client-server: server transmission: must sequentially send (upload) N file copies: time to send one copy: $F/u_s$ time to send N copies: $NF/u_s$ client: each client must download file copy $d_{min}$ = min client download rate min client download time: $F/d_{min}$ time to distribute F to N clients using client-server approach(increases linearly in N):$D{c-s}$ &gt; max{$NF/u_s, F/d{min}$} P2P: server transmission: must upload at least one copy time to send one copy: $F/u_s$ client: each client must download file copy min client download time: $F/d_{min}$ time to distribute F to N clients using P2P approach(increases linearly in N, but so does this, as each peer brings service capacity):$D{P2P}$ &gt; max{$F/u_s, F/d{min}, NF/(u_s + \\sum u_i)$} Napster(Centralized Database)Program for sharing music over the Internet Application-level, client-server protocol over TCP A centralized index system that maps files (songs) to machines that are alive and with files Steps: Connect to Napster server Upload your list of files (push) to server Give server keywords to search the full list Select “best” of hosts with answers Napster Architecture Napster Publish Napster Search Summary of features: a hybrid design control: client-server (aka special DNS) for files data: peer to peer Advantages: simplicity, easy to implement sophisticated search engines on top of the index system Disadvantages: application specific (compared with DNS) lack of robustness, scalability: central search server single point of bottleneck/failure easy to sue ! BitTorrent A P2P file sharing protocol Created by Bram Cohen in 2004 A peer can download pieces concurrently from multiple locations A global central index server is replaced by one tracker per file (called a swarm), reduces centralization; but needs other means to locate trackers The bandwidth scalability management technique is more interesting torrent(洪流): 参与一个特定文件分发的所有对等方(peer)的集合 追踪器(tracer) Metadata File Structure: Meta info contains information necessary to contact the tracker and describes the files in the torrent announce URL of tracker file name file length piece length (typically 256KB) SHA-1 hashes of pieces for verification also creation date, comment, creator, … Tracker Protocol: Communicates with clients via HTTP/HTTPS Client GET request info_hash: uniquely identifies the file peer_id: chosen by and uniquely identifies the client client IP and port numwant: how many peers to return (defaults to 50) stats: e.g., bytes uploaded, downloaded Tracker GET response interval: how often to contact the tracker list of peers, containing peer id, IP and port stats Robustness: A swarming protocol Peers exchange info about other peers in the system Peers exchange piece availability and request blocks from peers 块(chunk) Peer Protocol: Over TCP Unchoke: indicate if A allows B to download Interest/request: indicate which block to send from B to A incentive Periodically (typically every 10 seconds) calculate data-receiving rates from all peers Upload to (unchoke) the fastest constant number (4) of unchoking slots partition upload bw equally among unchoked commonly referred to as “tit-for-tat” strategy(一报还一报) Optimistic Unchoking Periodically select a peer at random and upload to it typically every 3 unchoking rounds (30 seconds) Multi-purpose mechanism allow bootstrapping of new clients continuously look for the fastest peers (exploitation vs exploration) Block Availability Request (local) rarest first(最稀缺优先) achieves the fastest replication of rare pieces obtain something of value Revisions When downloading starts (first 4 pieces): choose at random and request them from the peers get pieces as quickly as possible obtain something to offer to others Endgame mode defense against the “last-block problem”: cannot finish because missing a few last pieces send requests for missing sub-pieces to all peers in our peer list send cancel messages upon receipt of a sub-piece Summary Very widely used mainline: written in Python Azureus and μTorrent: the most popular Other popular clients: ABC, BitComet, BitLord, BitTornado, Opera browser Many explorations, e.g., BitThief BitTyrant Better understanding is needed Gnutella文件共享网络 Decentralized Flooding: Gnutella On startup, client contacts other servents (server + client) in network to form interconnection/peering relationships servent interconnection used to forward control (queries, hits, etc) How to find a resource record: decentralized flooding send requests to neighbors neighbors recursively forward the requests Each node forwards the query to its neighbors other than the one who forwards it the query Each node should keep track of forwarded queries to avoid loop: nodes keep state (which will time out—-soft state) carry the state in the query, i.e. carry a list of visited nodes Basic message header: Unique ID, TTL, Hops Message types: Ping : probes network for other servents Pong : response to ping, contains IP addr, # of files, etc. Query : search criteria + speed requirement of servent QueryHit : successful response to Query, contains addr + port to transfer from, speed of servent, etc. Ping, Queries are flooded QueryHit, Pong: reverse path of previous message Advantages: totally decentralized, highly robust Disadvantages: not scalable; the entire network can be swamped with flood requests: especially hard on slow clients; at some point broadcast traffic on Gnutella exceeded 56 kbps to alleviate this problem, each request has a TTL to limit the scopeeach query has an initial TTL, and each node forwarding it reduces it by one; if TTL reaches 0, the query is dropped (consequence?) Flooding: FastTrack (aka Kazaa) Modifies the Gnutella protocol into two-level hierarchy Supernodes Nodes that have better connection to Internet Act as temporary indexing servers for other nodes Help improve the stability of the networkStandard nodes Connect to supernodes and report list of filesSearch Broadcast (Gnutella-style) search across supernodesDisadvantagesKept a centralized registration -&gt; prone to law suits 分布式散列表(Distributed Hash Table, DHT)DHT Overview Abstraction: a distributed “hash-table” (DHT) data structure put(key, value) and get(key) -&gt; value DHT imposes no structure/meaning on keys one can build complex data structures using DHT Implementation: nodes in system form an interconnection network: ring, zone, tree, hypercube, butterfly network, … DHT Applications File sharing and backup [CFS, Ivy, OceanStore, PAST, Pastiche …] Web cache and replica [Squirrel, Croquet Media Player] Censor-resistant stores [Eternity] DB query and indexing [PIER, Place Lab, VPN Index] Event notification [Scribe] Naming systems [ChordDNS, Twine, INS, HIP] Communication primitives [I3, …] Host mobility [DTN Tetherless Architecture] Key Issues in Understanding a DHT Design: How does the design map keys to internal representation (typically a metric space)? Which space is a node responsible? How are the nodes linked? e.g. … Content Addressable Network(CAN)Abstraction map a key to a “point” in a multi-dimensional Cartesian space a node “owns” a zone in the overall space route from one “point” to another CAN Example: Two Dimensional Space Space divided among nodes Each node covers either a square or a rectangular area of ratios 1:2 or 2:1 CAN Insert Example:node I::insert(K,V) (1) a = hx(K) b = hy(K) (2) route(K,V) -&gt; (a,b) Routing: A node maintains state only for its immediate neighboring nodes Forward to neighbor which is closest to the target point a type of greedy, local routing scheme (3) (K,V) is stored at (a,b) CAN Retrieve Example:node J::retrieve(K) (1) a = hx(K) b = hy(K) (2) route “retrieve(K)” to (a,b) CAN Insert: Join CAN Evaluations Guarantee to find an item if in the network Load balancing hashing achieves some load balancing overloaded node replicates popular entries at neighbors Scalability for a uniform (regularly) partitioned space with n nodes and d dimensions storage: per node, number of neighbors is 2d a fixed d can scale the network without increasing per-node state routing average routing path is $(dn^{1/d})/3$ hops (due to Manhattan distance routing, expected hops in each dimension is dimension length * 1/3) Chord: search by routing/consistent hashing Space is a ring Consistent hashing: m bit identifier space for both keys and nodes key identifier = SHA-1(key), where SHA-1() is a popular hash function: Key=“Matrix3” -&gt; ID=60 node identifier = SHA-1(IP address) IP=“198.10.10.1” -&gt; ID=123 Chord: Storage using a Ring A key is stored at its successor: node with next higher or equal ID how to Search(One Extreme) Every node knows of every other node Routing tables are large O(N) Lookups are fast O(1) how to Search(the Other Extreme) Every node knows its successor in the ring Routing tables are small O(1) Lookups are slow O(N) Chord Solution: “finger tables” Node K knows the node that is maintaining K + 2i, increase distance exponentially Joining the Ring use a contact node to obtain info transfer keys from successor node to new node updating fingers of existing nodes DHT: Chord Node Join Assume an identifier space [0..8] Node n1 joins Node n2 joins Node n6 joins Node n0 joined DHT: Chord Insert Items Nodes: n1, n2, n0, n6 Items: f7, f1 Upon receiving a query for item id, a node: checks whether stores the item locally if not, forwards the query to the largest node in its successor table that does not exceed id Chord/CAN Summary Each node “owns” some portion of the key-space in CAN, it is a multi-dimensional “zone” in Chord, it is the key-id-space between two nodes in 1-D ring Files and nodes are assigned random locations in key-space provides some load balancing probabilistically equal division of keys to nodes Routing/search is local (distributed) and greedy node X does not know of a path to a key Z but if it appears that node Y is the closest to Z among all of the nodes known to X so route to Y video streaming and content distribution networks (CDNs)(流式视频和内容分发网络)Multimedia: video video: sequence of images displayed at constant rate e.g., 24 images/sec digital image: array of pixels each pixel represented by bits coding: use redundancy within and between images to decrease # bits used to encode image spatial (within image) spatial coding example: instead of sending N values of same color, send only two values: color value and number of repeated values (N) temporal (from one image to next) temporal coding example: instead of sending complete frame at i+1, send only differences from frame i CBR: (constant bit rate): video encoding rate fixed VBR: (variable bit rate): video encoding rate changes as amount of spatial, temporal coding changes examples: MPEG 1 (CD-ROM) 1.5 Mbps MPEG2 (DVD) 3-6 Mbps MPEG4 (often used in Internet, &lt; 1 Mbps) Streaming stored video(流式存储视频) simple scenario: video server(stored video) -&gt; Internet -&gt; client challenge: heterogeneity different users have different capabilities (e.g., wired versus mobile; bandwidth rich versus bandwidth poor) Streaming multimedia: DASH(Dynamic Adaptive Streaming over HTTP) server: divides video file into multiple chunks each chunk stored, encoded at different rates manifest file(文件清单): provides URLs for different chunks client: periodically measures server-to-client bandwidth consulting manifest, requests one chunk at a time chooses maximum coding rate sustainable given current bandwidth can choose different coding rates at different points in time (depending on available bandwidth at time) “intelligence” at client: client determines when to request chunk (so that buffer starvation, or overflow does not occur) what encoding rate to request (higher quality when more bandwidth available) where to request chunk (can request from URL server that is “close” to client or has high available bandwidth) Content distribution networks(CDN, 内容分发网络)video traffic: major consumer of Internet bandwidth challenge: how to stream content (selected from millions of videos) to hundreds of thousands of simultaneous users? option 1: single, large “mega-server” single point of failure point of network congestion long path to distant clients multiple copies of video sent over outgoing link quite simply: this solution doesn’t scale option 2: store/serve multiple copies of videos at multiple geographically distributed sites (CDN) enter deep: push CDN servers deep into many access networks close to users used by Akamai, 1700 locations bring home: smaller number (10’s) of larger clusters in POPs near (but not within) access networks used by Limelight CDN: stores copies of content at CDN nodes e.g. Netflix stores copies of MadMen subscriber requests content from CDN directed to nearby copy, retrieves content may choose different copy if network path congested OTT(over the top) challenges: coping with a congested Internet from which CDN node to retrieve content? viewer behavior in presence of congestion? what content to place in which CDN node? Caching explicit(明确的) transparent (hijacking connections)Replication server farms(服务器群) geographically dispersed(分散)(CDN) Traditional: Performance move content closer to the clients avoid server bottlenecksNew: DDoS Protection dissipate attack over massive resources multiplicatively raise level of resources needed to attack Denial of Service Attacks (DoS) Distributed DoS (DDoS) Redirection Overlay TechniquesDNS one name maps onto many addresses works for both servers and reverse proxiesHTTP requires an extra round tripRouter one address, select a server (reverse proxy) content-based routing (near client)URL Rewriting embedded links RidirectionHashing Schemes: Modulo Easy to compute Evenly distributed Good for fixed number of servers Many mapping changes after a single server change Consistent Hashing (CHash) Hash server, then URL Closest match Only local mapping changes after adding or removing servers Used by State-of-the-art CDNs Highest Random Weight (HRW) Hash(url, svrAddr) Deterministic order of access set of servers Different order for different URLs Load evenly distributed after server changes Redirection Strategies Random (Rand) Requests randomly sent to cooperating servers Baseline case, no pathological behavior Replicated Consistent Hashing (R-CHash) Each URL hashed to a fixed # of server replicas For each request, randomly select one replica Replicated Highest Random Weight (R-HRW) Similar to R-CHash, but use HRW hashing Less likely two URLs have same set of replicas Coarse(粗略) Dynamic Replication (CDR) Using HRW hashing to generate ordered server list Walk through server list to find a lightly loaded one of replicas for each URL dynamically adjusted Coarse grained server load information Fine Dynamic Replication (FDR) Bookkeeping min # of replicas of URL (popularity) Let more popular URL use more replicas Keep less popular URL from extra replication ReplicationWhy Replicate? Performance keep copy close to remote users caching is a special case Survive Failures availability: provide service during temporary failure fault tolerance: provide service despite catastrophic failure Fault Models Crashed failed device doesn’t do anything (i.e., fails silently) Fail-Stop failed device tells you that it has failed Byzantine(拜占庭将军问题,Byzantine Generals Problem) failed device can do anything adversary playing a game against an evil opponent opponent knows what you’re doing and tries to fool you usually some limit on opponent’s actions (e.g. at most k failures) 拜占庭将军问题 (Byzantine Generals Problem)，是由莱斯利兰伯特提出的点对点通信中的基本问题。 在分布式计算上，不同的计算机透过讯息交换，尝试达成共识；但有时候，系统上协调计算机 (Coordinator / Commander) 或成员计算机 (Member / Lieutanent) 可能因系统错误并交换错的讯息，导致影响最终的系统一致性。拜占庭将军问题就根据错误计算机的数量，寻找可能的解决办法 (但无法找到一个绝对的答案，只可以用来验证一个机制的有效程度)。 Synchrony Assumptions concerning boundedness of component execution or network transmissions Synchronous always performs function in a finite &amp; known time bound Asynchronous no such bound Famous Result: A group of processes cannot agree on a value in an asynchronous system given a single crash failure Network Partitions Can’t tell the difference between a crashed process and a process that’s inaccessible due to a network failure. Network Partition: network failure that cuts processes into two or more groups full communication within each group no communication between groups danger: each group thinks everyone else is dead Mirroring Goal: service up to K failures Approach: keep K+1 copies of everything Clients do operations on “primary” copy Primary makes sure other copies do operations too Advantage: simple Disadvantages: do every operation K times use K times more storage than necessary Mirroring Details Optimization: contact one replica to read What if a replica fails? get up-to-date data from primary after recovering What if primary fails? elect a new primary Election Problem When algorithm terminates, all non-failed processes agree on which replica is the primary Algorithm works despite arbitrary failures and recoveries during the election If there are no more failures and recoveries, the algorithm must eventually terminate Bully Algorithm Use fixed “pecking order” among processes e.g., use network addresses Idea: choose the “biggest” non-failed machine as primary Correctness proof is difficult Bully Algorithm Details Process starts an election whenever it recovers or whenever primary has failed how to know primary has failed?(一段时间无响应) To start an election, send election messages to all machines bigger than yourself if somebody responds with an ACK, give up if nobody ACKs, declare yourself the primary On receiving election message, reply with ACK and start an election yourself (unless in progress) Quorums Quorum(法人): a set of server machines Define what constitutes a “read quorum” and a “write quorum” To write acquire locks on all members of some write quorum do writes on all locked servers release locks To read: similar, but use read quorum Correctness requirements any two write quorums must share a member any read quorum and any write quorum must share a member (read quorums need not overlap(覆盖)) Locking ensures that at most one write happening at a time never have a write and a read happening at the same time Defining Quorums Many alternatives Example write quorum must contain all replicas read quorum may contain any one replica Consequence writes are slow, reads are fast can write only if all replicas are available can read if any one replica is available Example: Majority Quorum write quorum: any set with more than half the replicas read quorum: any set with more than half the replicas Consequences modest(适度) performance for read and write can proceed(进行) as long as more than half the replicas are available Quorums &amp; Version Numbers Write operation writes only a subset of the servers some servers are out-of-date Remedy(纠正方法) put version number stamp on each item in each replica when acquiring locks, get current version number from each replica quorum overlap rules ensure that one member of your quorum has the latest version When reading, get the data from the latest version number in your quorum When writing, set version number of all replicas you wrote equal to 1 + (max version number in your quorum beforehand) Guarantees correctness even if no recovery action is taken when replica recovers from a crash Quorums and Partitions One group has a write quorum (and thus usually a read quorum); that group can do anything other groups are frozen No group has a write quorum, but some groups have a read quorum some groups can read no groups can write No group contains any quorum everyone is frozen socket programming with UDP and TCPWhat is “socket” A socket is a virtual connection between two applications Using a socket, two processes can communicate with each other The socket is the major communication tool for Internet applications A socket is bi-directional (full-duplex) transmission A socket can be created dynamically Socket as a virtual connection between two processes Socket as a client/server model Port: a logical connecting point at the transport-layer protocol. Socket programmingTwo socket types for two transport services: UDP: unreliable datagram TCP: reliable, byte stream-oriented Application Example: client reads a line of characters (data) from its keyboard and sends data to server server receives the data and converts characters to uppercase server sends modified data to client client receives modified data and displays line on its screen Socket programming with TCP client must contact server server process must first be running server must have created socket (door) that welcomes client’s contact client contacts server by: Creating TCP socket, specifying IP address, port number of server process when client creates socket: client TCP establishes connection to server TCP when contacted by client, server TCP creates new socket for server process to communicate with that particular client allows server to talk with multiple clients source port numbers used to distinguish clients application viewpoint:TCP provides reliable, in-order, byte-stream transfer (“pipe”) between client and server Client/Server Process Organization Unix Socket Programming Technical Details Unix TCP server(1) create socket: socket_id = socket (AF_INET, SOCK_STREM, DEFAULT_PROTOCOL);(2) bind socket: bind (socket_id, server_addr, server_len);(3) listen to socket: listen (socket_id, number_of_connection);(4) accept a connection: accept (socket_id, &amp;client_addr, &amp;client_len);(5) read (receive) data: read (socket_id, buffer, buffer_len);(6) write (send) data: write (socket_id, buffer, buffer_len);(7) close socket: close(socket_id); Unix TCP client(1) create socket: same as server socket_id = socket (AF_INET, SOCK_STREM, DEFAULT_PROTOCOL);(2) connect socket: connect (socket_id, serverINETaddress, server_len);(3) write (send) data: write (socket_id, buffer, buffer_len);(4) read (receive) data: read (socket_id, buffer, buffer_len);(5) close socket: same as server close(socket_id); Step 1: socket(…) call It declares a socket to be used.Prepare data structure to manage socketOS is responsible for this Step 2: bind(…) call It connects a process to a specific portPort = A logical connecting point at a host for two communicating processes using socketPort Numbers:0~1023: System ReservedPort 21: FTPPort 23: telnetPort 80: HTTP1024 and above: available to users Step 3: listen(…) call listen() system call: prepare memory buffer for incoming connectionslisten (socket_id, number_of_connection) -&gt; We need to specify how many connection requests should be held in the buffer when SERVER is busy (can’t accept a request). Step 4 - Part 1: accept(…) call The server process accepts a request from a clientaccept() function is a blocking function Step 4 - Part 2: accept(…) call The accept(_) call returns another port number and establish another connection Step 5: read( ) and write( ) call The server and client communicate using the second socket Step 6: close ( ) call Close the second socket and leave the first socket for next client Step 7: Go back to accept(…) call The server process goes back to the accept call Winsock Programming Technical Details Initialize Winsock Step 1: Define your socketStep 2: Initialize your socketStep 3: Start using it 1234567891011void main (void)&#123; /* The following two lines needed for Window's socket */ // Winsock version 2.2 WORD wVersionRequested = MAKEWORD(2,2); /* Stuff for WSA functions */ WSADATA wsaData; /* Stuff for WSA functions */ /* This stuff initializes winsock*/ WSAStartup(wVersionRequested, &amp;wsaData); /* Create a socket */ My_SocketID = socket ( ….. ); socket ( ) function : Returns socket ID on success unsigned int socket_id = socket (AF_INET, SOCK_STREAM, 0); bind ( ) function : Return code (&lt; 0 if error) int status = bind (socket_id, (struct sockaddr_in *) my_addr, sizeof(my_addr)); The sockaddr_in structure to specify port # and IP address of this machine (server machine) The “sock_addr” structureStep 1: You instantiate the structureStep 2: Fill up the components 123456struct sockaddr_in my_addr; /* My (client) Internet address *//* Set My(client's) IP Address ---------------------------------------- */my_addr.sin_family = AF_INET; /* Address Family To Be Used */ my_addr.sin_port = htons (MY_PORT_NUM); /* Port number to use */ my_addr.sin_addr.s_addr = htonl (INADDR_ANY); /* My IP address */ listen ( ) function : Return code (&lt; 0 if error) int status = listen (socket_id, 3); The size of the connection request buffer(3) accept ( ) function : duplicated socket ID (&lt; 0 if error) unsingned int child_sock = accept (socket_id, (struct sockaddr_in *) client_addr, sizeof (client_addr); recv ( ) function : On success, the number of bytes received; Return code (&lt; 0 if error) int status = recv (child_sock, in_buffer, MAX_BUFFER_SIZE, 0); The input (receive) buffer as a character string Example: char in_buffer [MAX_BUFFER] send ( ) function : On success, the number of bytes actually sent; Return code (&lt; 0 if error) int status = send (child_sock, out_buffer, MAX_BUFFER_SIZE, 0); closesocket ( ) function : Return code (&lt; 0 if error) int status = closesocket (child_sock); Clear winsockAfter you call “closesocket” function but before your program is terminated 12/* This stuff cleans-up winsock */WSACleanup( ); How to specify your destination in socket? Each destination for a socket connection is determined by &lt; IP address + Port# &gt; sockaddr_in structure is used to define your destination The sockaddr_in structure is defined in C/C++ struct The sockaddr_in structure is defined in windows.h header file 1234567struct sockaddr_in &#123; u_char sin_len; /* Length of this structure */ u_char sin_family; /* Network protocol used*/ u_short sin_port; /* Port number */ struct in_addr sin_addr; /* Pointer to an IP address */ char sin_zero[8]; /* Extra information */&#125;; 123struct in_addr &#123; u_long s_addr; /* Actual IP address */&#125;; How can I set the IP address and the port number of my destination? STEP #1: Instantiate a sockaddr_in structure: STEP #2: Set your destination IP address: Case 1: by “32-bit IP address”: server_address.sin_addr.s_addr = inet_addr(“146.163.147.59”); Case 2: by a host name: server_address.sin_addr.s_addr = inet_aton(“cougar.siue.edu”); Case 3: by a system-defined parameter: server_address.sin_addr.s_addr = htonl(INADDR_ANY); STEP #3: Set your destination port number: server_address.sin_port = htons(80); Python Programming Technical Details Python TCPClient:12345678910from socket import * #include Python’s socket libraryserverName = ’servername’serverPort = 12000clientSocket = socket(AF_INET, SOCK_STREAM) create TCP socket for server, remote port 12000clientSocket.connect((serverName,serverPort))sentence = raw_input(‘Input lowercase sentence:’)clientSocket.send(sentence.encode()) # No need to attach server name, port modifiedSentence = clientSocket.recv(1024)print (‘From Server:’, modifiedSentence.decode())clientSocket.close() Python TCPServer:1234567891011121314151617 from socket import *serverPort = 12000serverSocket = socket(AF_INET,SOCK_STREAM) # create TCP welcoming socketserverSocket.bind((‘’,serverPort))serverSocket.listen(1) # server begins listening for incoming TCP requestsprint ‘The server is ready to receive’while True: # loop forever # server waits on accept() for incoming requests, new socket created on return connectionSocket, addr = serverSocket.accept() # read bytes from socket (but not address as in UDP) sentence = connectionSocket.recv(1024).decode() capitalizedSentence = sentence.upper() connectionSocket.send(capitalizedSentence.encode()) # close connection to this client (but not welcoming socket) connectionSocket.close() Socket programming with UDP UDP: no “connection” between client &amp; server no handshaking before sending data sender explicitly attaches IP destination address and port # to each packet receiver extracts sender IP address and port# from received packet UDP: transmitted data may be lost or received out-of-order Application viewpoint: UDP provides unreliable transfer of groups of bytes (“datagrams”) between client and server Client/server socket interaction: UDP Python UDPClient1234567891011121314from socket import *serverName = ‘hostname’serverPort = 12000# create UDP socket for serverclientSocket = socket(AF_INET, SOCK_DGRAM)# get user keyboard inputmessage = raw_input(’Input lowercase sentence:’)# Attach server name, port to message; send into socketclientSocket.sendto(message.encode(), (serverName, serverPort))# read reply characters from socket into stringmodifiedMessage, serverAddress = clientSocket.recvfrom(2048)# print out received string and close socketprint modifiedMessage.decode()clientSocket.close() 12345678910111213from socket import *serverPort = 12000# create UDP socketserverSocket = socket(AF_INET, SOCK_DGRAM)# bind socket to local port number 12000serverSocket.bind(('', serverPort))print (“The server is ready to receive”)while True: # loop forever # Read from UDP socket into message, getting client’s address (client IP and port) message, clientAddress = serverSocket.recvfrom(2048) modifiedMessage = message.decode().upper() # send upper case string back to this client serverSocket.sendto(modifiedMessage.encode(), clientAddress)","categories":[],"tags":[{"name":"computer network","slug":"computer-network","permalink":"https://chenfeng.github.io/tags/computer-network/"}]},{"title":"数值计算中的并行算法","slug":"parellel_and_distributed_computing/paralell_compute8","date":"2017-04-17T16:00:00.000Z","updated":"2017-04-23T12:55:06.959Z","comments":true,"path":"2017/04/18/parellel_and_distributed_computing/paralell_compute8/","link":"","permalink":"https://chenfeng.github.io/2017/04/18/parellel_and_distributed_computing/paralell_compute8/","excerpt":"(并行与分布式计算七) Arithmetic Computations 线性递推式(linear recurrences)m阶线性递推式(linear recurrece of order m):$yi$ 由 $ y{i-1}, y{i-2}, …, y{i-m} $ 的线性组合生成 多项式求值A = ($ a0, a_1, …, a_n $)是多项式$ p(x) = a_0x^n + a_1x^{n-1 + … + a{n-1}x} + a_n $的系数数组，给定点$x_0$计算$p(x_0)$ Horner’s algorithm(多项式求值的经典算法: 使用n次乘法和n次加法)p(x_0) = (...((a_0x_0 +a_1)x_0 + a_2)x_0 + ... + a_{n-1})x_0 + a_n","text":"(并行与分布式计算七) Arithmetic Computations 线性递推式(linear recurrences)m阶线性递推式(linear recurrece of order m):$yi$ 由 $ y{i-1}, y{i-2}, …, y{i-m} $ 的线性组合生成 多项式求值A = ($ a0, a_1, …, a_n $)是多项式$ p(x) = a_0x^n + a_1x^{n-1 + … + a{n-1}x} + a_n $的系数数组，给定点$x_0$计算$p(x_0)$ Horner’s algorithm(多项式求值的经典算法: 使用n次乘法和n次加法)p(x_0) = (...((a_0x_0 +a_1)x_0 + a_2)x_0 + ... + a_{n-1})x_0 + a_n $ y1 = a_0x_0 + a_1 $$ y_2 = y_1x_0 + a_2 $$ . $$ . $$ . $$ p(x_0) = y_n = y{n-1}x_0 + a_n $ 即如下一阶递推式:$ y_0 = a_0 $$ y_i = y_ix_0 + a_i, 1 \\leq i \\leq n $ 三对角线矩阵的LDU分解(LDU Factorization of a Tridiagonal Matrix) n*n 非奇异(nonsingular)三对角线矩阵AA = \\left[ \\begin{matrix} b_1 & c_1 & & & & \\\\ a_2 & b_2 & c_2 & & & \\\\ & a_3 & b_3 & c_3 & & \\\\ & . & . & . & & \\\\ & & . & . & . & \\\\ & & & a_{n-1} & b_{n-1} & c_{n-1}\\\\ & & & & a_n & b_n \\end{matrix} \\right] A的LDU分解: 单位下三角矩阵L, 对角矩阵D和单位上三角矩阵U; A = LDU 易证三个矩阵形式如下 L = \\left[ \\begin{matrix} 1 & & & & & \\\\ l_2 & 1 & & & & \\\\ & l_3 & 1 & & & \\\\ & & . & . & & \\\\ & & & . & . & \\\\ & & & & . & . \\\\ & & & & l_n & 1 \\end{matrix} \\right]U = \\left[ \\begin{matrix} 1 & u_1 & & & & \\\\ & 1 & u_2 & & & \\\\ & & 1 & u_3 & & \\\\ & & & . & . & \\\\ & & & & . & u_{n-1} \\\\ & & & & & 1 \\end{matrix} \\right]D = \\left[ \\begin{matrix} d_1 & & & & & \\\\ & d_2 & & & & \\\\ & & . & & & \\\\ & & & . & & \\\\ & & & & . & \\\\ & & & & & d_n \\end{matrix} \\right]其中$ d1 = b_1 $$ d_j = b_j - a_jc{j-1}/d{j-1}, 2 \\leq j \\leq n $$ l_j = a_j/d{j-1}, 2 \\leq j \\leq n $$ u_j = c_j/d_j, 1 \\leq j \\leq n - 1 $ $l_j$和$u_j$的值可以有$d_j$快速得到 使$dj = w_j/w{j-1}, w_0 = 1, w_1 = b_1$ $wj$可由下列二阶递推式计算:$w_0 = 1$$w_1 = b_1$$w_j = b_jw{j-1} - (ajc{j-1})w_{j-2}, 2 \\leq j \\leq n$ 三对角线矩阵A的LDU分解转化成求解二阶线性递推式 带状三角线性系统(Banded Triangular Linear Systems)n*n 下三角矩阵A, 其中所有非零元在主对角线或者其下的m-1对角线上(m &lt; n) e.g. (m = 3): A = \\left[ \\begin{matrix} a_{11} & 0 & 0 & 0 & ... & ... & 0 \\\\ a_{21} & a_{22} & 0 & 0 & ... & ... & 0 \\\\ a_{31} & a_{32} & a_{33} & 0 & . & . & . \\\\ 0 & a_{42} & a_{43} & a_{44} & & & \\\\ & & . & . & . & . & . \\\\ & & & . & . & . & 0\\\\ & & & & a_{n,n-2} & a_{n, n-1} & a_{nn} \\end{matrix} \\right] 线性系统$ Ax = b $的解可以表示为:$ x1 = \\frac{b_1}{a{11}} $$ xi = -(\\sum{j=i-m+1}^{i-1}\\frac{a{ij}}{a{i1}}xj) - \\frac{b_i}{a{i1}}, 2 \\leq i \\leq n $ 该解是一个m-1阶线性递推式 一阶线性递推式(first-order linear recurrences)$ y1 = b_1 $$ y_i = a_iy{i-1} + b_i, 2 \\leq i \\leq n $ 基本思想： 类似于前缀和的计算(若对所有i有$a_i = 1$，则为前缀和计算) 用平衡树方法 不妨设$n = 2^k$，i($2\\leq i \\leq n$)为偶数，则$yi = a_i(a{i-1}y{i-2} + b{i-1}) + bi$，即$y_i = a_ia{i-1}y{i-2} + a_ib{i-1} + b_i$ 这是对偶数下标i的一阶线性递推式(size: n/2) 使$ai^{‘} = a{2i}a{2i-1}$和$b_i^{‘} = a{2i}b{2i-1} + b{2i}$, $1 \\leq i \\leq \\frac{n}{2}$, 同时使$zi = y{2i}$, 则得到下列递推式:$ z1 = b_1^{‘} $$ z_i = a_i^{‘}z{i-1} + b_i^{‘}, 2 \\leq i \\leq n/2 $ Algorithm 8.11234567891011121314(First-Order linear Recurrence)Input: Two arrays B = (b_1, b_2, ..., b_n) and A = (a_1 = 0, a_2, ..., a_n) representing the first-order linear recurrence y_1 = b_1 and y_i = a_iy_&#123;i-1&#125; + b_i, (2 &lt;= i &lt;= n); n is assumed to be a power of 2.Output: The values of all the y_i terms.begin1. if n = 1 then &#123;set y_1 := b_1, exit&#125;2. for 1 &lt;= i &lt;= n/2 pardo Set a_i^&#123;&apos;&#125; := a_&#123;2i&#125;a_&#123;2i-1&#125; Set b_i^&#123;&apos;&#125; := a_&#123;2i&#125;b_&#123;2i-1&#125; + b_&#123;2i&#125;3. Recursively, solve the first-order linear recurrence defined by z_1 = b_1^&#123;&apos;&#125; and z_i = a_i^&#123;&apos;&#125;z_&#123;i-1&#125; + b_i^&#123;&apos;&#125;, where 2 &lt;= i &lt;= n/2.4. for 1 &lt;= i &lt;= n pardo i even : Set y_i := z_&#123;i/2&#125; i = 1 : Set y_1 := b_1 i odd &gt; 1 : Set y_i = a_iz_&#123;(i-1)/2&#125; + b_iend $ T(n) = T(n/2) + O(1) $ $ W(n) = W(n/2) + O(n) $ 并行复杂度: T(n) = O(logn), W(n) = O(n) 高维(一阶)线性递推式((first-order)higher-demensional linear recurrences) m维向量$bi(1 \\leq i \\leq n)$, mm矩阵$A_i(2 \\leq i \\leq n)$, 递推式如下:$ y_1 = b_1 $*$ y_i = A_iy{i-1} + b_i $**, $2 \\leq i \\leq n$ 将问题规约为通过计算$Ai^{‘} = A{2i}A{2i-1}$和$b_i^{‘} = A{2i}b{2i-1} + b{2i}, 1 \\leq i \\leq n/2$求解$y_2, y_4, …, y_n$ $y2i = A_i^{‘}y{2(i-1)} + b_i^{‘}$; 偶数下标y值得出后容易通过定义算得奇数下标y值 将Algorithm8.1中相应元素换为矩阵和向量即可 两个mm 矩阵乘积的可以在O(logm)的时间复杂度内用O(M(m))计算量复杂度求得，其中M(m)是计算mm矩阵乘积所需要的数学操作数量的时序约束(sequential bound)，目前可知的最好上界是$M(m) = O(m^2.376)$(over a ring) 并行复杂度: T(n) = O(lognlogm); W(n) = O(nM(m)) 三角线性方程组(Triangular Linear Systems) 高斯消元法(Gaussian elimination scheme)可以将任意的线性方程组化简为三角矩阵 再用标准前向替换法(standard forward substitution algorithm)可以求解 单位下三角矩阵及其线性方程线性方程组$Ax = b$, 其中$x$和$b是n维向量$, A是n*n 单位下三角矩阵: A = \\left[ \\begin{matrix} 1 & 0 & 0 & ... & 0 \\\\ a_{21} & 1 & 0 & ... & 0 \\\\ a_{31} & a_{32} & 1 & ... & 0 \\\\ . & . & . & . & . \\\\ a_{n1} & a_{n2} & ... & a_{n,n-1} & 1 \\end{matrix} \\right] 对任意矩阵，通过将每行元素除以$a{ii}(a{ii} \\not= 1, 1 \\leq i \\leq n)$可得到以上形式的矩阵 简单方法: $xi = b_i - \\sum{j=1}^{i-1}a_{ij}x_j$; 需要O(n^2)的计算量, 但无法求得并行算法 快速矩阵求逆并行算法用分治策略求出矩阵$A$的逆$A^{-1}$，则$x = A^{-1}b$能在$O(logn)$时间内用$O(n^2)$计算量求得 矩阵分块: 将矩阵$A$分成(n/2) * (n/2)的块(不妨设n是2的幂)A = \\left[ \\begin{matrix} A_1 & 0 \\\\ A_2 & A_3 \\end{matrix} \\right] $A_1$和$A_3$是非奇异下三角矩阵 非奇异矩阵: 行列式不为零(存在逆矩阵) A^{-1} = \\left[ \\begin{matrix} A_1^{-1} & 0 \\\\ -A_3^{-1}A_2A_1^{-1} & A_3^{-1} \\end{matrix} \\right] n*n 三角线性方程组可以在$O(log^2n)$时间复杂度，O(M(n))的计算量内求解 $T(n) = O(log^2n) = O(logn) * O(log^n)$: O(logn) (分治)迭代; O(logn) 维数&lt;=(n/2)的矩阵乘法 $W(n) = 2W(n/2) + 2M(n/2)$: 假设$M(n) \\geq 4M(n/2)$可得$W(n) \\leq M(n)$ 带状三角形线性方程组e.g.(n = 6, m = 3) A = \\left[ \\begin{matrix} a_{11} & 0 & 0 & 0 & 0 & 0 \\\\ a_{21} & a_{22} & 0 & 0 & 0 & 0 \\\\ a_{31} & a_{32} & a_{33} & 0 & 0 & 0 \\\\ 0 & a_{42} & a_{43} & a_{44} & 0 & 0 \\\\ 0 & 0 & a_{53} & a_{54} & a_{55} & 0 \\\\ 0 & 0 & 0 & a_{64} & a_{65} & a_{66} \\end{matrix} \\right] 不失一般性假设主对角线元等于1，$Ax = b$的解可以表示为$ x1 = b_1 $$ x_i = (-\\sum{j=i-m+1}^{i-1}a_{ij}x_j) + b_i, 2 \\leq i \\leq n $ 不妨设m能整除n，将A分成m*m 的块$A{i,j}, 1 \\leq i,j \\leq n/m$; $A{i,i}$是下三角矩阵，$A_{i,i-1}$是上三角矩阵e.g.: 设D为如下子矩阵: D = \\left[ \\begin{matrix} A_{1,1} & & & \\\\ & A_{2,2} & & \\\\ & & . & \\\\ & & & A_{\\frac{n}{m},\\frac{n}{m}} \\end{matrix} \\right] 使$A^{} = D^{-1}A$, 使$d = D^{-1}b$; $Ax = b$的解同$D_{-1}Ax = D^{-1}b$, 即$A^{}x = b$, $A^{*}$如下: A = \\left[ \\begin{matrix} I_m & & & & \\\\ A_{2,1}^{*} & I_m & & & \\\\ & A_{3,2}^{*} & I_m & & \\\\ & & . & . & \\\\ & & & A_{\\frac{n}{m},\\frac{n}{m}-1}^{*} & I_m \\end{matrix} \\right] $A{i,i-1}^{*} = A{i,i}^{-1}A{i,i-1}, 2 \\leq i \\leq n/m$; $A^{}$的计算需要对(n/m)-1个独立的mm矩阵求逆得到${A{i,i}^{-1}}{i=2}^{n/m}$，再通过(n/m)-1个独立的m*m矩阵相乘得到${A{i,i}^{-1}A{i,i-1}}{i=2}^{n/m}$ 运用对下三角矩阵求逆的并行算法，可以在$O(log^2m)$时间内用$O((n/m)M(m))$计算量求出$A{i,i}^{-1}, 1 \\leq i \\leq n/m$; (n/m)-1矩阵乘法与$d = D{-1}b$的计算显然在这个上界之内 将x和d分成m维子向量$x = (x1, x_2, …, x{n/m})$和$d = (d1, d_2, …, d{n/m})$, $Ax = d$的解可表示为$x1 = d_1$$x_i = -A{i,i-1}^{}x_{i-1} + d_i, 2 \\leq i \\leq n/m$ $x_i$的计算可以在O(log(n/m)logm)的时间复杂度内，用O((n/m)M(m))的计算量 $T(n) = O(lognlogm)$; W(n) = O((n/m)M(m)) 离散傅氏变换(Discrete fourier transform)定义在复数域上的离散傅氏变换DFT 定义复数$ \\omega = e^{i\\frac{2\\pi}{n}} = \\cos\\frac{2\\pi}{n} + i\\sin\\frac{2\\pi}{n} $，其中$i = \\sqrt{-1}$ $\\omega^{n} = e^{2\\pi i} = 1$; $1, \\omega, \\omega^2, …, \\omega^{n-1}$是复数域上(相异的)第n单位根(root of unity); $\\omega$被称为第n本原单位根(primitive root of unity) 使n*n矩阵$W_n(j,k) = \\omega^{jk}, 0 \\leq j,k \\leq n-1$, n维列向量$x$的DFT定义为列向量$y = W_nx$ $yj = \\sum{k=0}^{n-1}\\omega^{jk}x_k, 0 \\leq j \\leq n-1$ e.g. 快速傅氏变换用分治策略计算DFT $y = W_nx$(假设n是2的幂) 使j为偶数: $j = 2l, 0 \\leq l \\leq \\frac{n}{2} - 1$ $yj = y{2l} = \\sum{k=0}^{n-1}\\omega^{2lk}x_k$, 故有$ y{2l} = x0 + \\omega^{2l}x_1 + \\omega^{4l}x_2 + … + \\omega^{2l(\\frac{n}{2}-1)}x{\\frac{n}{2}-1} + x{\\frac{n}{2}} + \\omega^{2l}x{\\frac{n}{2}+1} + \\omega^{4l}x{\\frac{n}{2}+2} + … + \\omega^{2l(\\frac{n}{2}-1)}x{n-1} $ $ y{2l} = (x_0 + x{\\frac{n}{2}}) + \\omega^{2l}(x1 + x{\\frac{n}{2}+1}) + \\omega^{4l}(x2 + x{\\frac{n}{2}+2}) + … + \\omega^{2l(\\frac{n}{2}-1)}(x{\\frac{n}{2}-1} + x{n-1}) $ 显然$\\omega^2 = e^{i\\frac{2\\pi}{\\frac{n}{2}}}$, 故$\\omega^2$是第(n/2)本原单位根 $z^{(1)} = [y0, y_2, …, y{n-2}]^{T}$是向量$[x0 + x{\\frac{n}{2}}, x1 + x{\\frac{n}{2}+1}, …, x{\\frac{n}{2}-1} + x{n-1}]^{T}$的离散傅氏变换 如果j为奇数: $j = 2l + 1$, 类似地有$ y{2l+1} = (x_0 + \\omega^{\\frac{n}{2}})x{\\frac{n}{2}} + \\omega^{2l}(\\omega x1 + \\omega^{\\frac{n}{2}+1}x{\\frac{n}{2}+1}) + … + \\omega^{2l(\\frac{n}{2}-1)}(\\omega^{\\frac{n}{2}-1}x{\\frac{n}{2}-1} + \\omega^{n-1}x{n-1}) $ $\\omega^{\\frac{n}{2}} = e^{i\\pi} = -1$, 故$ y{2l+1} = (x_0 - x{\\frac{n}{2}}) + \\omega^{2l}\\omega (x1 - x{\\frac{n}{2}+1}) + \\omega^{4l}\\omega^2(x2 - x{\\frac{n}{2}+2}) + … + \\omega^{2l(\\frac{n}{2}-1)}\\omega^{\\frac{n}{2}-1}(x{\\frac{n}{2}-1} - x{n-1}) $ $z^{(2)} = [y1, y_3, …, y{n-1}]^{T}$是向量$[x0 - x{\\frac{n}{2}}, \\omega (x1 - x{\\frac{n}{2}+1}), …, \\omega^{\\frac{n}{2}-1}(x{\\frac{n}{2}-1} - x{n-1})]^{T}$的离散傅氏变换 algorithm 8.212345678910111213(Fast Fourier Transform)Input: An n-dimensional vector x whose entries are complex numbers, and \\omega = e^&#123;i\\frac&#123;2\\pi&#125;&#123;n&#125;&#125;, where n is assumed to be a power of 2.Output: The vector y that is the DFT of x.begin1. if n = 2 then &#123;Set y_1 := x_1 + x_2, y_2 := x_1 - x_2, exit&#125;2. for 0 &lt;= l &lt;= n/2-1 pardo Set u_l := x_l + x_&#123;n/2+l&#125; Set v_l := \\omega^l (x_l - x_&#123;n/2+l&#125;)3. Recurrsively, compute the DFT of the two vectors [u_0, u_1, ..., u_&#123;n/2-1&#125;] and [v_0, v_1, ..., v_&#123;n/2-1&#125;], and store the results in vetors z^(1) = [z_0^(1), z_1^(1), ..., z_&#123;n/2-1&#125;^(1)] and z^(2) = [z_0^(2), z_1^(2), ..., z_&#123;n/2-1&#125;^(2)], respectively.4. for 0 &lt;= j &lt;= n-1 pardo j even : Set y_j := z_&#123;j/2&#125;^(1) j odd : Set y_j := z_&#123;(j-1)/2&#125;^(2)end $ T(n) = T(n/2) + O(1) $ $ W(n) = 2W(n/2) + O(n) $ T(n) = O(logn); W(n) = O(nlogn) 离散傅里叶逆变换(inverse discrete Fourier transform, IDFT): 矩阵$W_n$的逆$W_n^{-1}(j,k) = \\frac{1}{n}\\omega^{-jk}, 0 \\leq j,k \\leq n-1$, 向量x的离散傅氏逆变换是向量$y = W_n^{-1}x$ 类似地，T = O(logn), W = O(n logn) 多项式乘法和卷积多项式$p(x) = \\sum{k=0}^{n-1}a_kx^k$可由系数列表唯一表示$(a_0, a_1, …, a{n-1})$; 给定点$x_i$, $y_i = p(x_j)$值唯一 多项式乘法 两个多项式$ p(x) = \\sum{k=0}^{n-1}a_kx^k $,$ q(x) = \\sum{k=0}^{m-1}bkx^k $,其积为$ r(x) = p(x)q(x) = \\sum{k=0}^{n+m-2}ckx^k $,使得$ c_k = \\sum{j=0}^{k}ajb{k-j} $ (下标越界的a、b值为0) Polynomial multiplication using the FFT algorithm 设l为2的幂且使得$n+m-2 &lt; l \\leq 2(n+m-2)$; $a = [a0, …, a{l-1}]^{T}, aj = 0$ for j &gt; n-1, $b = [b_0, …, b{l-1}]^{T}, b_k = 0$ for k &gt; m-1 计算系数列表${c_k}$的算法如下( 多项式乘法的并行算法): 用F快速傅里叶变换算法计算 $y = W_la$ 和 $z = W_lb$ , 得到p(x)和q(x)在点x = 1, $\\omega, \\omega^2, …, \\omega^{l-1}$的值，其中$\\omega$是第l本原单位根，$y_j = p(\\omega^j), z_j = q(\\omega^j), 0 \\leq j \\leq l-1$ 计算 $u_j = y_jz_j$ , for $0 \\leq j \\leq l-1$。显然 $u_j = p(\\omega^j)q(\\omega^j) = r(\\omega^j)$, 故能得到多项式$r(x)$在l个相异单位根的值 计算向量$u = [u0, u_1, …, u{l-1}]^{T}$的傅里叶逆变换。向量前n+m-1个元和乘积$r(x)$的系数相同。 T(n) = O(log(n+m)); W(n) = O((n+m)log(n+m)) 用快速傅里叶变换算法计算卷积(Convolution)向量$a$和$b$的卷积，可以表示为$ a\\bigotimes b $ $a = [a0, …, a{n-1}]^{T}$; $b = [b0, …, b{m-1}]^{T}$ $a \\bigotimes b$定义为向量$c = [c0, …, c{m+n-1}]^{T}$, 使得$ck = \\sum{j=0}^kajb{k-j}$, 其中$a_j = 0, j &gt; n-1$, $b_j = 0, j &gt; m-1$ 除$c{n+m-1}$(总是为0)外，两个向量$a$和$b$的卷积和多项式$p(x) = \\sum{j=0}^{n-1}ajx^j$和$q(x) = \\sum{j=0}^{m-1}b_jx^j$的乘积的系数相同 计算n维向量x和m维向量y的卷积的并行算法的复杂度: T = O(log(n+m)); W((n+m)log(n+m)) Toeplitz矩阵(托普利茨矩阵)Toeplitz矩阵: n*n矩阵T满足$T(k,l) = T(k-1,l-1)$, for $2 \\leq l,k \\leq n$ 矩阵T同一对角线上的所有元素相等; 因此这类矩阵又出现在第一行和第一列的2n-1个元素唯一确定T = \\left[ \\begin{matrix} t_{n-1} & t_{n-2} & ... & & t_2 & t_1 & t_0 \\\\ t_n & t_{n-1} & t_{n-2} & ... & & t_2 & t_1 \\\\ t_{n+1} & t_n & t_{n-1} & t_{n-2} & ... & & t_2 \\\\ . & & & . & . & . & . \\\\ . & & & & . & . & . \\\\ t_{2n-3} & t_{2n-4} & ... & & & t_{n-1} & t_{n-2} \\\\ t_{2n-2} & t_{2n-3} & ... & & t_{n+1} & t_n & t_{n-1} \\end{matrix} \\right] $t = [t0, t_1, …, t{2n-2}]^{T}$确定了托普利茨矩阵T Toeplitz矩阵乘以向量 向量$a = [a0, a_1, …, a{n-1}]^{T}$, $d = Ta$, 其中T是n*n托普利茨矩阵 $t = [t0, t_1, …, t{2n-2}]^{T}$ 计算d的一般算法需要O(logn)的时间和O(n^2)的计算量 易证$dl = \\sum{j=0}^{n-1}ajt{n+l-j-1}, 0 \\leq l \\leq n-1$ 考察向量 $a$ 和 $t$ 的卷积c, $ck = \\sum{j=0}^kajt{k-j}$, 将k=n+l-1代入得$c{n+l-1} = \\sum{j=0}^{n+l-1}ajt{n+l-j-1} = \\sum{j=0}^{n-1}a_jt{n+l-j-1}$($j &gt; n-1 时 a_j = 0$) $dl = c{n+l-1}, 0 \\leq l \\leq n-1$ 乘积Ta可通过计算$a \\bigotimes t$, 令$dl = c{n+l-1}(0 \\leq l \\leq n-1)$得到 Toeplitz矩阵乘以向量的并行算法:$c = a \\bigotimes t$得到的c向量的元素$(c{n-1}, c_n, …, c{2n-2})$ T(n) = O(logn); W(n) = O(nlogn) 求下三角Toeplitz矩阵的逆矩阵-下三角托普利茨矩阵T分成n/2 * n/2的块: T = \\left[ \\begin{matrix} T_1 & 0 \\\\ T_2 & T_1 \\end{matrix} \\right] 不妨设n是2的幂 矩阵T的逆$T^{-1}$如下: T^{-1} = \\left[ \\begin{matrix} T_1^{-1} & 0 \\\\ -T_1^{-1}T_2T_1^{-1} & T_1^{-1} \\end{matrix} \\right] $T^{-1}$也是一个下三角托普利茨矩阵，由第一列元素唯一确定; 计算$T^{-1}$的算法: 递归地计算$T_1^{-1}$的第一列 计算$-T_1^{-1}T_2T_1^{-1}$的第一列 计算$-T_1^{-1}T_2T_1^{-1}$的第一列等价于计算$-T_1^{-1}T_2T_1^{-1}e$, 其中$e = [1, 0, …, 0]^{T}$ T(n) = T(n/2) + O(logn) W(n) = W(n/2) + O(nlogn) Toeplitz矩阵求逆算法的并行复杂度: $T(n) = O(log^2n)$; $W(n) = O(nlogn)$ 应用Toeplitz矩阵实现多项式的除法 两个多项式$ s(x) = \\sum{j=0}^{n-1}s_jx^j $和$ t(x) = \\sum{j=0}^{m-1}t_jx^j $,存在唯一的两个多项式, 商$q(x)$和余数$r(x)$使得$ s(x) = t(x)q(x) + r(x) $且$r(x)$的阶(degree)小于$t(x)$的阶(余数的最高次小于除数的最高次) 引理8.2: $t(x)$和$s(x)$是两个阶分别为n-1和m-1的多项式(n&gt;m)。 如果商$q(x)$已知，$r(x)$可以在O(logn)的时间内用O(nlogn)的计算量求出来。 如果余数$r(x)$已知，$q(x)$可以在O(log(n-m))的时间内用O((n-m)log(n-m))的计算量算出来。 $q(x)$的阶为n-m，两个矩阵$t(x)q(x)$相乘可以在O(logn)时间内用O(nlogn)计算量复杂度的基于FFT的算法。$r(x) = s(x) - t(x)q(x)$可以在O(1)时间内由O(n)计算量完成 $s(x) - r(x)$可在O(1)时间内由O(n)操作完成。通过多项式求值/差值和DFT的关系求$q(x) = \\frac{s(x)-r(x)}{t(x)}$: 计算$s(\\omega^l) - r(\\omega^l)$和$t(\\omega^l), 0 \\leq l \\leq n-m+1$, 其中$\\omega$是第(n+m-1)本原单位根。FFT算法可以在O(log(n-m))的时间内用O((n-m)log(n-m))计算量计算出来。因此$q(\\omega^l)$能在这个上界内求得，再使用快速傅里叶逆变换算法能求得$q(x)$ 计算多项式的商: 设$q(x) = \\sum{j=0}^{n-m}q_jx^j$是两个多项式$s(x) = \\sum{j=0}^{n-1}sjx^j$和$t(x) = \\sum{j=0}^{m-1}t_jx^j$的商。 不失一般性假设$t{m-1}s{n-1} \\not= 0$, $t(x)q(x)$可表示为$\\sum{k=0}^{n-1}a_kx^k$, 其中$a_k = \\sum{j=0}^ktjq{k-j}$ 设r(x)为$s(x)$除以$t(x)$的余数，给定$r(x)$的阶小于m-1; 则$\\sum{k=m-1}^{n-1}s_kx^k = \\sum{k=m-1}^{n-1}akx^k$, 故$s_k = a_k, m-1 \\leq k \\leq n-1$ , 从而$s_k = \\sum{j=0}^ktjq{k-j}, m-1 \\leq k \\leq n-1$ 由$t_j = 0, j \\geq m$和$q_j = 0, j \\geq n-m+1$可得: 关于$s(x)$和$t(x)$的系数的矩阵T是一个(n-m+1)*(n-m+1)下三角托普利茨矩阵 两个多项式(n阶和m阶, n &gt; m)相除的并行算法的复杂度$T(n) = O(log^2(n-m) + logn)$;$W(n) = O(nlogn)$ 多项式求值和插值多项式求值(polynomial evaluation): n-1阶多项式$p(x) = \\sum_{j=0}^{n-1}a_jx^j$ ${a_l | 0 \\leq l \\leq n-1}$是一组相异点的集合 计算$p(\\alpha_l), 0 \\leq l \\leq n-1$ Horner’s algorithm并发地求，$T = O(logn), W = O(n^2)$ 多项式求值的分治算法 令$q_l = x - \\alpha_l, 0 \\leq l \\leq n-1$ $Q1(x) = \\prod{i=0}^{\\frac{n}{2}-1}ql(x)$$Q_2(x) = \\prod{l=\\frac{n}{2}}^{n-1}q_l(x)$ 设定n为2的幂，$Q_1(x)$和$Q_2(x)$是阶为$\\frac{n}{2}$的多项式 $p_1(x) = p(x) mod Q_1(x)$; $p_2(x) = p(x) mod Q_2(x)$ 对某个多项式$t_1(x)$和$t_2(x)$有$p(x) = t_1(x)Q_1(x) + p_1(x)$和$p(x) = t_2(x)Q_2(x) + p_2(x)$ ($deg(p_1(x)), deg(p_2(x)) &lt; \\frac{n}{2}$) $p(\\alpha_l) = p_1(\\alpha_l), 0 \\leq l \\leq \\frac{n}{2}-1$; $p(\\alpha_l) = p_2(\\alpha_l), \\frac{n}{2} \\leq l \\leq n-1$ algorithm 8.31234567891011121314151617(Polynomial Evaluation)Input: (1)A polynomial p(x) of degree n-1 specified by its coefficients, and (2)a set of n distinct points a_j, where 0 &lt;= j &lt;= n-1 and n = 2^k for some integer k.Output: The values p(a_j), where 0 &lt;= j &lt;= n-1begin1. for 0 &lt;= j &lt;= n-1 pardo Set Q_&#123;0, j&#125;(x) := x - a_j2. for h = 1 to log n-1 do for 0 &lt;= j &lt;= (n/2^h) - 1 pardo Set Q_&#123;h,j&#125;(x) := Q_&#123;h-1,2j&#125;(x) * Q_&#123;h-1,2j+1&#125;(x)3. Set p_&#123;k,0&#125;(x) := p(x)4. for h = log n-1 to 0 do for 0 &lt;= j &lt;= (n/2^h)-1 pardo j even : Set p_&#123;h,j&#125;(x) := p_&#123;h+1,j/2&#125;(x) mod Q_&#123;h,j&#125;(x) j odd : Set p_&#123;h,j&#125;(x) := p_&#123;h+1,(j-1)/2&#125;(x) mod Q_&#123;h,j&#125;(x)5. for 0 &lt;= j &lt;= n-1 pardo Set p(a_j) := p_&#123;0,j&#125;end $ T(n) = O(log^3n) $; $ W(n) = O(nlog^2n) $ 多项式插值的分治算法 集合$ { \\betaj = p(\\alpha) }{j=0}^{n-1} $ 拉格朗日插值公式(Lagrange interpolation formula):$ p(x) = \\sum{j=0}^{n-1}\\beta_j \\frac{\\prod{l=0,l \\not= j}^{n-1}(x - \\alphaj)}{\\prod{l=0,l \\not= j}^{n-1}(\\alpha_j-\\alpha_l)} $ $ql(x) = x - \\alpha_l$; $Q(x) = \\prod{i=0}^{n-1}ql(x)$; $Q^{‘}(\\alpha_j) = \\prod{l=0,l \\not= j}^{n-1}(\\alpha_j) - \\alpha_l$ $\\gammaj = Q^{‘}(\\alpha_j), 0 \\leq j \\leq n-1$, $c_j = \\beta_j/\\gamma_j, 0 \\leq j \\leq n-1$; $p(x) = Q(x)\\sum{j=0}^{n-1}\\frac{c_j}{x - \\alpha_j}$ $\\sum{j=0}^{n-1}\\frac{c_j}{x-\\alpha_j}$可用平衡树方法求得$ \\frac{p(x)}{Q(x)} = \\frac{p{k-1,0}(x)}{Q{k-1,0}(x)} + \\frac{p{k-1,1}(x)}{Q{k-1,1}(x)} = \\frac{p{k-1,0}(x)Q{k-1,1}(x) + p{k-1,1}(x)Q_{k-1,0}(x)}{Q(x)} $ Algorithm 8.412345678910111213141516(Polynomial Interpolation)Input: A set of pairs of numbers (a_j, b_j), where 0 &lt;= j &lt;= n, the a_j&apos;s are distinct, and n = 2^k for some integer k.Output: The coefficients of the (n-1)st-degree polynomial p(x) such that p(a_j) = b_j, for all 0 &lt;= j &lt;= n-1.begin1. for 0 &lt;= j &lt;= n-1 pardo Set Q_&#123;0,j&#125;(x) := x - a_j2. for h = 1 to logn do for 0 &lt;= j &lt;= (n/2^h)-1 pardo Set Q_&#123;h,j&#125;(x) := Q_&#123;h-1,2j&#125;(x) * Q_&#123;h-1,2j+1&#125;(x)3. Compute Q_&#123;k,0&#125;(x), and user Algorithm 8.3 to compute y_j = Q&apos;_&#123;k,0&#125;(a_j), for all 0 &lt;= j &lt;= n-14. for 0 &lt;= j &lt;= n-1 pardo Set p_&#123;0,j&#125;(x) := b_j/y_j5. for h = 1 to logn do for 0 &lt;= j &lt;= (n/2^h)-1 pardo Set p_&#123;h,j&#125;(x) := p_&#123;h-1,2j&#125;(x)Q_&#123;h-1,2j+1&#125;(x) + p_&#123;h-1,2j+1&#125;(x)Q_&#123;h-1,2j&#125;(x)6. Set p(x) := p_&#123;k,0&#125;(x) $ T(n) = O(log^3n) $; $ W(n) = O(nlog^2n) $","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"字符串匹配的并行算法","slug":"parellel_and_distributed_computing/paralell_compute7","date":"2017-04-10T16:00:00.000Z","updated":"2017-04-16T07:49:39.578Z","comments":true,"path":"2017/04/11/parellel_and_distributed_computing/paralell_compute7/","link":"","permalink":"https://chenfeng.github.io/2017/04/11/parellel_and_distributed_computing/paralell_compute7/","excerpt":"(并行与分布式计算六) 字符串的预备知识字符串: 有限长度的字符序列 字符表(或字母表 alphabet) 字符串Y的长度: |Y| 两条字符串X和Y的连接为 XY 字符串Y中第i个字符: Y(i)(1 &lt;= i &lt;= |Y|) 字符串Y的子字符串: Y(i:j)(1 &lt;= i &lt;= j &lt;= |Y|) 字符串Y的前缀(prefix): Y(1:i)(1 &lt;= i &lt;= m) 字符串Y的后缀(suffix): Y(j:m)(1 &lt;= j &lt;= m)","text":"(并行与分布式计算六) 字符串的预备知识字符串: 有限长度的字符序列 字符表(或字母表 alphabet) 字符串Y的长度: |Y| 两条字符串X和Y的连接为 XY 字符串Y中第i个字符: Y(i)(1 &lt;= i &lt;= |Y|) 字符串Y的子字符串: Y(i:j)(1 &lt;= i &lt;= j &lt;= |Y|) 字符串Y的前缀(prefix): Y(1:i)(1 &lt;= i &lt;= m) 字符串Y的后缀(suffix): Y(j:m)(1 &lt;= j &lt;= m) 字符串匹配问题及其串行算法 字符串X在字符串Y中出现，是指存在位置i，使得X(j)=Y(i+j-1)对所有1 &lt;= j &lt;= |X|成立 字符串X在位置i与Y匹配(match) KMP算法：O(|X|+|Y|)复杂度 字符串的周期性(periodicities in string) 如果$Y = X^kX’$，其中$X’$是$X$的一个前缀，则$|X|$是$Y$的一个周期 如果p是Y的最短周期，则简称p是Y的周期(没有加“一个”在前面): The period(周期)，a period(一个周期) 如果Y的周期不大于|Y|/2，就称Y是周期的(periodic) e.g: abcaabcab不是周期的(最短周期是abcaabc)，abcabcab是周期的(周期p = 3) 字符串的周期引理: 如果p和q都是Y的一个周期且p+q &lt;= |Y|, 则p和q的最大公约数也是Y的一个周期 证明: 由p和q都是Y的一个周期，可得|p-q|也是Y的一个周期: Y(i) = Y(i-p) = Y(i-q) ==&gt; Y(j) = Y(j+p-q) 由最大公约数的欧几里德算法gcd(p, q) = gcd(p-q, q)可以得到结论 推论1：如果X的周期为p且X在Y的i和j位置出现，则|i-j| &gt;= p推论2：如果X的周期为p且在Y的i和i+d(d &lt;= m-p)位置出现, 则d是p的倍数; 如果0 &lt;= d &lt;= |X|/2, 则X也在i+kp出现(其中k是满足kp &lt;= d的整数) (区别)见证数组(Witness Array) 长度为m，周期为p的字符串Y，定义Pi(Y) = min{p, $\\lceil \\frac{m}{2} \\rceil$} 见证函数Wit(i)定义： Wit(1) = 0 Wit(i) = k($2 \\leq i \\leq Pi(Y)$), k是满足$Y(k) \\not= Y(i + k - 1)$的一个下标 见证函数数组WITNESS(1:r)(r = Pi(Y)) e.g: abcaabcab，见证数组WITNESS = (0,3,2,2,5) e.g: abcabcab，见证数组WITNESS = (0,3,2) (区别)见证数组的基本思想: 如果匹配两个位置的子字符串时，可以由某个特定的位置排除这两个位置的其中一个的匹配性，就可以减少字符串匹配的复杂度 这个特定的位置，称为（区别）见证位置(如果在见证位置不同，则不可能匹配) 见证位置与对决 Z字符串为文本字符串，Y为模式；利用见证位置排除掉Z中两处潜在的匹配中的一处的过程称为对决： 对决算法 Algorithm 7.1123456789101112(Duel(i, j))Input:(1)A string Z of length n;(2)a WITNESS array of another string Y of length m &lt;= n;(3)two indices i and j, where 1 &lt;= i &lt; j &lt;= n - m, such that j - i &lt; Pi(Y) = min&#123;p, $\\lceil \\frac&#123;m&#125;&#123;2&#125; \\rceil$&#125; and p is the period of Y.Output: One of i or j(that may match); string Y cannot occur in Z at the eliminated position.begin1. Set k := WITNESS(j - i + 1)2. if Z(j + k - 1) != Y(k) then return(i) else return(j)end T = O(1), W = O(1) e.g. (example 7.5) 字符串Y = abcabcab, 见证数组WITNESS = (0, 3, 2) 字符串Z = abcaabcabaa 考虑Z的位置i = 5和j = 7 WITNESS(7 - 5 + 1) = 2, Y(2) = b != Z(8) = a, 对决算法输出下标i = 5(可能匹配的位置) 字符串匹配(string matching)的两种分析string-matching problem: 在Y中找X的所有出现的位置 称Y为待匹配的文本(text)，X为待匹配的模式(pattern) 解决字符串匹配问题的经典范式包含两个步骤: 模式分析 Pattern Analysis 只对模式进行处理 将模式的部分信息压缩并保存在一个表中 文本分析 Text Analysis 用模式以及模式分析中产生的信息对文本进行处理 文本分析 文本T(1:n)，模式P(1:m)，模式的见证数组WITNESS(1:r)(r = Pi(P) = min{p, $\\lceil \\frac{m}{2} \\rceil$})，P周期为p 文本分析算法：非周期模式Algorithm 7.2123456789(Text Analysis, Nonperiodic Pattern)Input: Three arrays T(1:n), P(1:m), and WITNESS(1:m/2) corressponding to a text, a pattern and a witness function of the pattern, respectively. It is assumed that P is nonperiodic, and m is even.Output: The array MATCH, indicating all the positions where the pattern occurs in the text.begin1. Partition T into $\\lceil 2n/m \\rceil$(up integer) blocks T_i, each block containing no more than m/2 consecutive characters.2. For each block T_i, eliminate all but one position as a possible candidate for matching by using a balanced binary tree, where each internal node u contains the index returned by the function duel(i, j), and i and j are the indices stored in the children of u.3. For each candidate position, verify where P occurs at that position in T by using the brute-force algorithm.end T = O(log m) W = O(n) e.g: T = babaababaaba, P = abaab 见证数组WITNESS = (0,1,2) 分块: $T_1 = bab,T_2 = aab,T_3 = aba,T_4 = aba$, 对每个块并发处理 第一轮对决(WINESS(2) = 1): Duel(1,2)=2, Duel(4,5)=5, Duel(7,8)=7, Duel(10,11)=10 第二轮对决: Duel(2,3)=2, Duel(5,6)=5,Duel(7,9)=7, Duel(10,12)=10 对T的位置2, 5, 7, 10用暴力算法尝试匹配: 2和7能匹配 文本分析算法：周期模式 基本思想： 用周期模式的最大非周期前缀来作为初始模式 查找文本中初始模式的位置 要找出文本中周期模式的位置，可以用初始模式的位置来筛选 只有周期重复次数足够的位置才能在筛选中存活下来 周期重复次数可以用分段后缀和算法来并行计算 P(1:m) = $u^kv$, v是u的一个前缀(可空), |u| = p是P的周期, 见证数组WITNESS长度为p 将P(1:2p-1)作为一个新的模式(P的最大非周期前缀)在T中在O(logp)时间内用O(n)操作找出所有匹配 检查$u^2v$是否出现在(T的)位置i, i+p, …, i+(k-2)p(k是P(1:m)=$u^kv$中的k) Algorithm 7.312345678910(Text Analysis, Periodic Case)Input: Three arrays T(1:n), P(1:m), and WITNESS(1:p) representing respectively a text, a pattern, and a WITNESS array corresponding to P(1:2p-1). We also know that the pattern is periodic and has period p.Output: The array MATCH identifying all the positions in the text where the pattern occurs.begin1. Use Algorithm 7.2 to determine the occurrences of the prefix P(1:2p-1) in T.2. For each occurence of P(1:2p-1) in T(at position i), find whether u^2v occurs at i, where u = P(1:p), v = P(kp+1:m, and k = $\\lfloor m/p \\rfloor$(lower integer)). If it does, set M(i) := 1. For all the other positions i such that 1 &lt;= i &lt;= n, set M(i) := 0. 3. For each i such that 1 &lt;= i &lt;= p, let S_i be the subarray of M consisting of the bits (M(i), M(i+p), M(i+2p), ...). For each position l of S_i that contains a 1, set C(i, l) := 1 if there are at least k-1 consecutive 1's starting at this position. For all the remaining positions l of S_i, set C(i, l) := 0.4. For each 1 &lt;= j &lt;= n - m + 1, let j = i + lp, where 1 &lt;= i &lt;= p and l &gt;= 0. Then, set MATCH(j) := C(i, l+1).end T = O(logm), W = O(n) e.g. (example 7.8) T = babababababaabab = (ba)^6(ab)^2, P = abababa = (ab)^3a p = 2, P(1:2p-1) = P(1:3) = aba T中出现P(1:3)的位置2, 4, 6, 8, 10, 13 (ab)^2a在T中出现位置2, 4, 6, 8; M = (0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0) S_1 = (0, 0, 0, 0, 0, 0, 0, 0), S_2 = (1, 1, 1, 1, 0, 0, 0, 0) C(1, l) = 0(1 &lt;= l &lt;= 8) C(2, 1) = C(2, 2) = C(2, 3) = 1, C(2, l) = 0(4 &lt;= l &lt;= 8) MATCH(2) := C(2, 1) = 1, MATCH(4) := C(2, 2) = 1, MATCH(6) := C(2, 3) = 1, MATCH(i) := 0 otherwise. P 出现在T的2, 4, 6位置 模式分析算法 目标：计算见证数组WITNESS WITNESS(i)(1 &lt;= i &lt;= r, r = min{p, $\\lceilm/2\\rceil$}) = k != 0, k满足P(i + k - 1) P(1:i-1)不是模式的周期 基本思想: 迭代算法，每一迭代令模式的短子模式长度翻倍 从模式的短子模式开始，通过短子模式来计算长子模式见证数组的部分元素 剩余的元素在后面的迭代中计算 简单算法 lemma 7.7:Suppose that we are given WITNESS(2:t) of the string P(1:m), for some t &lt; min(p, m/2), where p is the period of P. Then, given any pair of distinct indices i and j, such that t &lt; i, j &lt;= $\\lceil\\frac{m}{2}\\rceil$ and |j - i| &lt; t, we can compute at least one of WITNESS(i) or WITNESS(j) in O(1) sequential time. Algorithm 7.512345678910111213(Simple Pattern Analysis)Input: A pattern P(1:m), where m = 2^s.Output: The array WITNESS(1:r), where r = min(p, 2^(s-1)), and p is the period of P.begin1. for 1 &lt;= i &lt;= m/2 pardo Set WITNESS(i) := 02. for i = 1 to s - 1 do 2.1 Let j != 1 be the candidate in the first i-block. Compute WITNESS(j) using the brute force algorithm. 2.2 if WITNESS(j) = 0 then exit 2.3 for all i_blocks B(except the first) pardo Apply duel(k, s), where k and s are the candidates in B.end T = O(log m) W = O(m log m) …","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"搜索、归并与排序的并行算法","slug":"parellel_and_distributed_computing/paralell_compute5","date":"2017-03-27T16:00:00.000Z","updated":"2017-04-22T13:11:26.047Z","comments":true,"path":"2017/03/28/parellel_and_distributed_computing/paralell_compute5/","link":"","permalink":"https://chenfeng.github.io/2017/03/28/parellel_and_distributed_computing/paralell_compute5/","excerpt":"(并行与分布式计算三) 并行搜索的基本思想在升序数组中采用与二分搜索类似的p+1分搜索: 使用递归按比例缩小搜索范围的办法 二分搜索每层递归中加入一次比较，p+1分搜索每层递归中加入p次比较 上述的每层p次比较可以用p个处理器同时进行 长度为n的升序数组，用p个处理器做p+1分搜索，并行时间为$O(log_{p+1}(n+1))$","text":"(并行与分布式计算三) 并行搜索的基本思想在升序数组中采用与二分搜索类似的p+1分搜索: 使用递归按比例缩小搜索范围的办法 二分搜索每层递归中加入一次比较，p+1分搜索每层递归中加入p次比较 上述的每层p次比较可以用p个处理器同时进行 长度为n的升序数组，用p个处理器做p+1分搜索，并行时间为$O(log_{p+1}(n+1))$ 例：p+1分并行搜索:X=(2,4,6,…,30)，X[1]=2, X[15]=30; Y=9 作p+1分并行搜索，p=2: 迭代1：q0=0, q1=5, q2=10, q3=16 迭代2：q0=5, q1=6, q2=7, q3=10 迭代3：q0=7, q1=8, q2=9, q3=10 快速并行搜索算法Algorithm 4.112345678910111213141516171819202122232425(Parallel Search for Processor P_j)Input: (1)An array X = (x_1, x_2, ..., x_n) such that x_1 &lt; x_2 &lt; ... &lt; x_n; (2)an element y; (3)the number p of processors, where p &lt;= n; (4)the processor number j, where 1 &lt;= j &lt;= p.Output: An index i such that x_i &lt;= y &lt; x_i+1.begin1. if (j = 1) then do 1.1 Set l := 0; r := n + 1; x_0 := -∞; x_n+1 := +∞ 1.2 Set c_0 := 0; c_p+1 := 12. while (r - 1 &gt; p) do 2.1 if (j = 1) then &#123;set q_0 := l; q_p+1 := r&#125; 2.2 Set q_j := l + j*floor((r-1)/(p+1)) 2.3 if (y = x_q_j) then &#123;return (q_j); exit&#125; else &#123;set c_j := 0 if y &gt; x_q_j and c_j := 1 if y &lt; x_q_j&#125; 2.4 if (c_j &lt; c_j+1) then &#123;set l := q_j; r := q_j+1&#125; 2.5 if (j = 1 and c_0 &lt; c_1) then &#123;set l := q_0; r := q_1&#125;3. if (j &lt;= r - l) then do 3.1 Case statement: y = x_l+j : &#123;return (l + j); exit&#125; y &gt; x_l+j : set c_j := 0 y &lt; x_l+j : set c_j := 1 3.2 if (c_j-1 &lt; c_j) then return (l + j - 1)end 初始化 外层搜索递归调用内层搜索 最内层搜索 $T = O(log_{p+1}(n+1)) = O(\\frac{log(n+1)}{log(p+1)}) = O(1)$ 并行归并的基本思想 并行地归并两个升序数组，可以等价为计算：1.归并序=自序+交叉序2.自序=数组元素在自己所在数组中的序3.交叉序=数组元素在另一个数组中的序 自序是已知的，交叉序可以用快速并行搜索算法来计算 交叉序的并行搜索的两层并行性: 单个元素的快速搜索内部并行 不同元素的搜索之间并行 例：并行归并中的交叉序计算 A=(-5,0,3,4,17,18,24,28)B=(1,2,15,21)分两个迭代并行搜索 迭代1：定位b2和b4。b_2=2在a_2=0和a_3=3之间，b_4=21在a_6=18和a_7=24之间(rank(b_2:A)=2, rank(b_4:A)=6)迭代2：在b_2前的A元素中搜索b_1的位置，在b_2后、b_4前的A元素中搜索b_3的位置(rank(b_1:A)=2, rank(b_3:A)=4) 并行归并的加速技巧思路：双层对数树，利用处理器的冗余性加速 设要计算长度为m的数组B的元素在长度为n的数组A中的交叉序，则由加速层叠法： 最上层分叉成长度为$\\sqrt{m}$的段计算，每往下一层长度再开根号 最上层每段使用\\sqrt{n}个处理器来并行搜索(共\\sqrt{mn}个处理器)，从而分划数组A供下层递归使用 全局来说，每一层都使用不超过(m+n)/2个处理器，并且每层搜索时间T=O(1) 迭代1分割的A段长短不一不会影响加速算法中的处理器上界 最上层$\\sqrt(m)$段，对段的右端点在长度为n的A中搜索，求交叉序(能用$\\sqrt(n)$个处理器) $T = O(log{\\sqrt(n)+1}(n+1)) = O(log{\\sqrt(n)}n) = O(2) = O(1)$ 处理器个数$\\sqrt m\\sqrt n \\leqslant \\frac{m+n}{2}$ 第二层设B中第i段的右端点切到的A的段的长度为n，B分成$m^{\\frac{1}{4}}n^{\\frac{1}{4}}$段。第i段用$\\sqrt{n_{|\\frac{i-1}{\\sqrt{m}}|+1}}$个处理器 总处理器数 = $\\sum{i=1}^{m^{\\frac{3}{4}}}\\sqrt{n{|\\frac{i-1}{\\sqrt{m}}|+1}} = \\sum{j=1}^{\\sqrt{m}}m^{\\frac{1}{4}}\\sqrt{n_j} \\leqslant \\sum{j=1}^{\\sqrt{m}}\\frac{\\sqrt{m}+nj}{2} = (\\sum{j=1}^{\\sqrt{m}}\\sqrt{m} + \\sum_{j=1}^{\\sqrt{m}}n_j)/2 = (m+n)/2$ 第三层处理器个数 = $\\sum_{j=1}^{m^{\\frac{3}{4}}}m^{\\frac{1}{8}}\\sqrt{n_j^{(1)}} \\leqslant = (\\sum m^{\\frac{1}{4}} + n_j^{(1)})/2 = (m+n)/2$ 其中$n^(1)$是第二层分出的A的$m^{\\frac{3}{4}}$段的长度 并行求交叉序Algorithm 4.2123456789(Ranking a Sorted Sequence in Another Sorted Sequence)Input: Two arrays A = (a_1, ..., a_n) and B = (b_1, ..., b_m) in increasing order. Assume that sqrt(m) is an integer; otherwise, replace sqrt(m) whenever it occur by floor(sqrt(m)).Output: The array rank(B : A)begin1. If m &lt; 4, then rank the elements of B by applying the parallel-search algorithm(Algorithm 4.1) with p = n, and exit.2. Concurrently rank the elements b_sqrt(m), b_2sqrt(m), ..., b_i*sqrt(m), ..., b_m in A by using the parallel-search algorithm(Algorithm 4.1) with p = sqrt(n). Let rank(b_i*sqrt(m) : A) = j(i), for 1 &lt;= i &lt;= sqrt(m). set j(0) = 0.3. For 0 &lt;= i &lt;= sqrt(m)-1, let B_i = (b_i*sqrt(m)+1, ..., b_(i+1)*sqrt(m)-1) and let A_i = (a_j(i)+1, ..., a_j(i+1)); if j(i) = j(i+1), then set rank(B_i : A_i) = (0, ..., 0), else recursively compute rank(B_i: A_i).4. Let 1 &lt;= k &lt;= m be an arbitrary index that is not a multiple of sqrt(m), and let i = floor(k/sqrt(m)). Then rank(b_k : A) = j(i) + rank(b_k : A_i)end |A| = n, |B| = m, T = O(log logm), W = O((n + m)log logm) 最优的并行求交叉序前一个算法的问题： 运算量O((m+n)log log m)不是最优 最优运算量应该是O(m+n) 解决办法： 在两边数组均匀步长地抽取元素，缩短求交叉序的并行算法的输入数组 用前述并行算法求交叉序 利用抽取的点把两边的数组分段，这边的段一一对应地归并 两个长度都为n的升序数组，可以在O(log log n)的并行时间内用O(n)的运算量归并 在A和B中都先均匀采样，对两边采样点计算缩短的数组的交叉序，然后再利用该交叉序来进一步计算原来的数组的交叉序 T = O(log logn), W = O(n) 一个快速并行归并排序算法 从长度为较小常数的数组开始，逐层两两归并，共log n层 每层用O(log log n)的并行时间和O(n)的运算量来归并 总共O(log n log log n)的并行时间和O(n log n)的运算量 Algorithm 4.312345678910(Simple Merge Sort)Input: An array X of order n, where n = 2^l for sime integer l.Output: A balanced binary tree with n leaves such that, for each 0 &lt;= h &lt;= logn, L(h, j) contains the sorted subsequence consisting of the elements stored in the subtree rooted at node(h, j), for 1 &lt;= j &lt;= n/2^h. That is node(h, j) contains the sorted list of the elements X(2^h*(j-1) + 1), X(2^h*(j-1) + 2), ..., X(2^h*j)begin1. for 1 &lt;= j &lt;= n pardo Set L(0, j) := X(j)2. for h = 1 to logn do for 1 &lt;= j &lt;= n/2^h pardo Merge L(h-1, 2j-1) and L(h-1, 2j) into the sorted list L(h, j)end","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"平面几何的并行算法","slug":"parellel_and_distributed_computing/paralell_compute6","date":"2017-03-27T16:00:00.000Z","updated":"2017-05-01T01:13:09.225Z","comments":true,"path":"2017/03/28/parellel_and_distributed_computing/paralell_compute6/","link":"","permalink":"https://chenfeng.github.io/2017/03/28/parellel_and_distributed_computing/paralell_compute6/","excerpt":"(并行与分布式计算五) computational geometry: design efficient algorithms to handle computational problems dealing with collections of objects in Euclidean space three technique: divide-and-conquer 分治 plane-sweep tree 平面扫描树 pipelined divide-and-conquer 凸包(Convex-Hull)计算","text":"(并行与分布式计算五) computational geometry: design efficient algorithms to handle computational problems dealing with collections of objects in Euclidean space three technique: divide-and-conquer 分治 plane-sweep tree 平面扫描树 pipelined divide-and-conquer 凸包(Convex-Hull)计算 欧几里得空间中两点p_1 = (x_1, y_1)和p_2 = (x_2, y_2)s = $p_1p_2$定义为满足$q = ap_1 + (1-a)p_2$(0 &lt;= a &lt;= 1)的q点的集合s consists of all the points lying on the straight-line segment joining $p_1$ and $p_2$， including $p_1$ and $p_2$ 称p_1和p_2为s端点 凸包(CH(S))可以按上凸包(upper hull UH(S))和下凸包(lower hull LH(S))两部分来分别算 设p和q分别是输入的点集S中x坐标最小和最大的点，则凸包被p和q两点分割成两部分，分别是上凸包和下凸包 上凸包是从p顺时针到q的凸包子列 下凸包是从q顺时针到p的凸包子列 凸包计算(串行算法)为了串行地算凸包，把输入点集用线段pq分成上、下两部分，上部分用来算上凸包，下部分用来算下凸包 为了计算上凸包，对上部分的点集进行关于x坐标的排序，然后按x坐标从小到大逐点扫描该点集：设当前上凸包为v_1,v_2,…,v_k，则当从v_k到被扫描到的点v的线段角度比v_k-1到v_k的线段角度小时，把v作为v_k+1插入到上凸包最后面，再让k的值加1，否则的话去掉当前上凸包最后的点（k的值减1），并重新判断，如果还不行则继续让k的值减1，直到v能加入到上凸包中 下凸包的计算与上凸包的类似 上凸包计算(快速串行算法)对上部分的点集进行关于x坐标的排序（O(n log n)复杂度） 按x坐标从小到大逐点扫描该点集(n次外迭代): 用二分法确定正在被扫描的点v究竟是上凸包中第几个点(O(log n)复杂度) 把v插入到上凸包中（O(1)复杂度） 整体复杂度为O(n log n), 意味着并行算法的W要做到O(n log n)才是optimal算法 上凸包计算(并行计算思路)分治法: 分：把输入点集分成左、右点数基本均等的两组 治：在左、右两组中分别用分治法来计算上凸包 合：把左、右两组的上凸包合在一起 左右上凸包合并串行算法: 外循环：用二分法搜索切线段的左端点 内循环：固定切线段的左端点，用二分法搜索切线段的右端点 复杂度：O(log^2 n) 并行算法: 并行外循环：用p+1分法搜索切线段的左端点 并行内循环：固定切线段的左端点，用p+1分法并行搜索切线段的右端点 取p=根号n T=O(1)，W=O(n) Algorithm 6.1123456789(Upper Common Tangent)Input: The upper hulls UH(S_1) = (r_1, r_2, ..., r_s) and UH(S_2) = (q_1, q_2, ..., q_t) in sorted order from left to right, where S_1 = (p_1, p_2, ..., p_n/2) and S_2 = (p_(n/2+1), p_(n/2+2), ..., P_n) such that x(p_1) &lt; x(p_2) &lt; ... &lt; x(p_n). Assume that sqrt(s) and sqrt(t) are integers. Output: Points u and v such that the line determined by u and v is the upper common tangent between UH(S_1) and UH(S_2).begin1. For each i such that 1 &lt;= i &lt;= sqrt(s), find q_(j(isqrt(s))) such that r_(i*sqrt(s))q_(j(i*sqrt(s))) is the tangent to UH(S_2).2. For each i such that 1 &lt;= i &lt;= sqrt(s), determine whether u is to the left of, is equal to, or is to the right of r_(i*sqrt(s)). If u = r_(i*sqrt(s)), for some i, then we are done. Otherwise, deduce the block A = (r_(l*sqrt(s)+1), ..., r_((l+1)sqrt(s)-1)) containing u.3. For each r_i in block A, determine q_(j(i)) such that r_i*q_(j(i)) is the tangent to UH(S_2), set u := r_i and v := q_(j(i)) if r_i*q_(j(i)) if r_i*q_(j(i)) is also tangent to UH(S_1).end 上凸包计算(快速并行算法)假设输入点集已经按x坐标排好序 分：把输入点集分成左、右点数基本均等的两组，T=O(1), W=O(n) 治：在左、右两组中分别用分治法来计算上凸包，假设$T=T{n/2}, W=2W{n/2}$ 合：把左、右两组的上凸包合在一起，T=O(1), W=O(n) 总体并行复杂度：$Tn=T{n/2}+O(1)=O(log n), Wn=2W{n/2}+O(n)=O(n log n) 凸集求交(Intersections of Convex Sets)intersection of half-planes(半平面的交) 每条直线方程L: y=ax+b都把二维平面分成两个半空间: $H^+(L)$和$H^-(L)$，分别对应y&gt;=ax+b和y&lt;=ax+b 多条直线，每条选一个半空间，这些半空间的交可以看作凸集的交 思路: 把凸集求交转化为凸包计算 点转换为线：T(a, b) -&gt; y = ax + b 线转换为点：T(y = cx + d) -&gt; (-c,d) 如果d &gt;= -ca + b，那么b &lt;= ca + d 如果d &lt;= -ca + b，那么b &gt;= ca + d 为了求出凸集的边界依次在哪些直线上，可以转为求这些直线的转换点的凸包 把凸集求交转化为凸包计算原理: 平面扫描(Plane Sweeping)树 Plane Sweep: 给定平面上的集合对象的一个集合，想象一条垂直线(竖直线)从左到右扫过平面；从扫描线的关键位置(critical points)得出某些问题的解 Plane-Sweep Tree 输入数据：s_i: (a_i, b_i)与(c_i, d_i)的连线 假设：s_i组成二维平面的分划 构建一树状数据结构，对平面上任意点都可以快速找出包含该点的分划面 模型简化: 构造过程中，线段的角度不重要，线段的上下关系才是关键 不妨去掉角度信息，只保留上下关系 所以可以把这些线段都简化为水平线，用y值来记录其相互间的上下关系 数据结构: 图中的树，叶节点是线段端点的x把二维空间垂直分割的部分，其它节点是这些部分的两两合并 节点的W是每一垂直分割部分中，至少有一个端点在该部分中，并且从该部分穿过的线段的集合 节点的H是覆盖节点的垂直分割部分但不覆盖父节点的线段集 构造平面扫描树的并行算法 引理6.5: 令T为不相交的n段水平段的集合的平面扫描树，H(v)和W(v)为每个结点v存储的链表；则$\\sum_v|H(v)|$和$\\sum_v|W(v)|$都为O(nlogn) 父节点的W由其子节点的W合并而成，可以用并行归并算法 除了根节点的H必然是空集外，其它节点的H必然是其父节点的W的子集 通过检验一条线段在兄弟节点的覆盖性，可以确定该线段是否在H中 通过并行前缀和算法，可以从W快速压缩得到H 并行复杂度:T = O(logn), W = O(nlogn), a set S of n horizontal segments 可视性问题(Visibility Problems) 给定平面上由禁止曲线(forbidden curves)和点p组成的集合F，点q对p是可视的，如果线段pq和F中的任意曲线不相交 如果F由直线段组成，则对p可视的点组成多边形，称为p的可视多边形 线段集合的下包络(the lower envelope of a set of segments) 假定p点是任意一个负无穷点 p的可视多边形由集合的线段的下包络指定 并行解法: L的计算可以用并行归并算法 在L的基础上，合并vis数组可以用T=O(1)时间 使用算法4.4的流水线归并排序算法， T = O(logn), W = O(nlogn)","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"图的并行算法","slug":"parellel_and_distributed_computing/paralell_compute4","date":"2017-03-20T16:00:00.000Z","updated":"2017-04-22T13:10:32.396Z","comments":true,"path":"2017/03/21/parellel_and_distributed_computing/paralell_compute4/","link":"","permalink":"https://chenfeng.github.io/2017/03/21/parellel_and_distributed_computing/paralell_compute4/","excerpt":"(并行与分布式计算四) 连通分量 顶点之间的连通性：在无向图G中，若从顶点$v_i$到顶点$v_j$有路径(当然从$v_j$到$v_i$也一定有路径)，则称$v_i$和$v_j$是连通的(Connected) 连通图：若V(G)中任意两个不同的顶点$v_i$和$v_j$都连通(即有路径)，则称G为连通图(Connected Graph) 连通分量：无向图G的极大连通子图称为G的连通分量(Connected Component) 寻找连通分量的串行算法","text":"(并行与分布式计算四) 连通分量 顶点之间的连通性：在无向图G中，若从顶点$v_i$到顶点$v_j$有路径(当然从$v_j$到$v_i$也一定有路径)，则称$v_i$和$v_j$是连通的(Connected) 连通图：若V(G)中任意两个不同的顶点$v_i$和$v_j$都连通(即有路径)，则称G为连通图(Connected Graph) 连通分量：无向图G的极大连通子图称为G的连通分量(Connected Component) 寻找连通分量的串行算法 深度优先搜索 1.令k=1 2.当图中有顶点未被标记时： 任取一个未被标记的顶点v 深度优先标记（v, k）：把v标记为第k个连通分量中的顶点 遍历v的未被标记的相邻顶点u： 递归地深度优先标记（u,k） 3.令k=k+1 广度优先搜索 1.令k=1 2.当图中有顶点未被标记时： 任取一个未被标记的顶点v 把v标记为第k个连通分量中的顶点 用v的相邻顶点组成集合U 当U非空时：把U中的顶点v都标记为第k个连通分量中的顶点;更新U，用旧的U中的顶点的未被标记的相邻顶点组成新的U 3.令k=k+1 算法可并行化程度分析深度优先搜索算法： 外循环用到连通分量编号k，不可并行 内循环用到前一个访问的顶点的标记，不可并行 广度优先搜索算法： 外循环用到连通分量编号k，不可并行 内循环只用到上一次内循环的标记，可以并行 广度优先搜索的并行性更好 改进寻找连通分量的算法的并行性 广度优先搜索算法 外循环的不可并行性问题是否可以解决 问题在于连通分量的编号方式: 连通分量的连续整数编号 需要依次搜索各个连通分量来保证：连通分量内编号相同，连通分量外编号不同 采用其它方式来为连通分量编号: 同一连通分量内的深度和广度优先探索都形成搜索树 用树根顶点作为连通分量的编号 不需要依次搜索各个连通分量 全并行连通分量搜索算法基本思想: 相邻的顶点可以合并为超顶点 相邻的超顶点可以继续合并为更大的超顶点 继续合并，直到把同一连通分量中的顶点都合并为一个超顶点 最终的结果是一个连通分量一个超顶点，用超顶点内编号最小的顶点来标记这个超顶点即可 顶点合并技巧: 合并方向函数 编号是极小值点的顶点或超顶点合并其它顶点或超顶点 定义合并方向函数$C(u) = min{v: v是u的邻居}$ 上述合并方向函数C(u)形成伪森林，同一伪树包含在同一个连通分量里，但是同一连通分量里可能有多个伪树 伪树:A pseudoforest is a directed graph in which each vertex has an outdegree less than or equal to 1. 顶点合并技巧：伪树的星化 每棵伪树内都只有一个环 根是环内编号更小的节点 如果用指针跳转法来跳转，当跳转步数大于或等于伪树的高度时，伪树上的所有节点都跳到环内的两个顶点之一 如果在使用指针跳转法之前先把伪树的环修改为从根指向根(loop)的回路，则当跳转步数大于或等于伪树的高度时，伪树上的所有节点都跳到伪树的根上 星化伪树： A rooted star is a directed tree that each vertex is directly connected to the root r. 顶点合并技巧：星化伪树的超顶点合并 星化的伪树合并为以根为标记的超顶点 当且仅当两个超顶点中的顶点有跨越超顶点的边连接时，这两个超顶点是相邻的 超顶点使用前面同样的合并方向函数来构造更高级别的伪树 更高级别的伪树又可以用同样的指针跳转法来星化，从而合并成更高级别的超顶点 继续合并，直到每个连通分量只剩一个超顶点 无向图G=(V, E)，定义函数C: C(v)=min{u | A(u, v) = 1}(A为图G邻接矩阵)，C(v)=v当且仅当v是孤立点;C定义了一棵伪树;树根定义为伪树中编号最小顶点 用指针跳转法(pointer jumping)将每个伪树收缩为超顶点(supervertex)，每个超顶点都孤立时算法停止 如果超顶点$r_i$和$r_j$邻接(存在连接两个顶点集的两个顶点的边)，则插入边($r_i$, $r_j$); 继续进行收缩 Algorithm 5.1 12345678910111213(Connected Components for Dense Graphs)Input: The n*n adjacency Matrix A of an undirected graph.Output: An array D of size n such that D(i) is equal to the smallest vertex in the connected component of i.begin1. Set A_0 := A, n_0 := n, k := 0.2. while n_k &gt; 0 do 2.1 Set k := k + 1 2.2 Set C(v) := Min&#123;u | A_k-1(u, b) = 1, u != v&#125; if none then v, 2.3 Shrink each tree of the pseudoforest defined by C to a rooted star. The root of each star containing more than one vertex defines a new supervertex. 2.4 Set n_k to be the number of the new supervertices, and set A_k to be the n_k * n_k adjancy matrix of the new supervertex graph.3. For each vertex v, determine D(v) as follows. If, at the end of step2, C(v) = v, then set D(v) = v; otherwise, reverse the process preformed at step 2 by expanding each supervertex r (of the supervertices formed during an iteration) into the set V_r of vertices of its directed tree, and making the assignment D(v) = D(r) for each v belongto V_r.end A是邻接矩阵，D是每个顶点所在的连通分量中标号最小的顶点 $T = O(log^2n)$, $W = O(n^2)$ W的主要部分是计算超顶点之间的边 该算法并行复杂度的最优性分析 串行算法的复杂度是O(m+n)，其中m是边数， n是顶点数 如果$m=O(n^2)$，那么前述并行算法就是最优的 当图是稠密的时候，$m=O(n^2)$ 然而，也有很多图是稀疏的 针对稀疏图改进连通分量并行算法改进$T(O(log^2n) -&gt; O(logn))$: 不用等一个级别内的所有伪树都星化了再做下一级别 嫁接法(Grafting): 伪森林中两棵相异的树$T_i$和$T_j$由D定义，$T_i$的根$r_i$，v是$T_j$一个顶点，将$T_i$嫁接到$T_j$是指D(r_i) = v的操作 非对称嫁接：当发现伪树的根大于伪树上某个节点的邻居的(不在原伪树上的)父结点时，把该根连接到该父结点上 if D(u) = D(D(u)) and D(v) = D(D(v)), which will result in an attempt to graft $T_i$ onto $T_j$ and $T_j$ onto $T_i$ simultaneously. To avoid such a difficulty we insist on grafting a tree onto a smaller vertex of another tree:Given an edge (u, v) belongs to E, we check whether D(u) = D(D(u)) and D(v) = D(D(u)) and D(v) &lt; D(u), and, if they are, we graft $T_i$ onto $T_j$, that is we set D(D(u) = D(v)) 星嫁接：(在非对称嫁接完成之后)如果一颗伪树已星化且非对称嫁接失败(伪树的根小于所有伪树上的节点的邻居的父结点)，就检查伪树上的节点有没有邻居不在伪树上，如果有则任选一个不在伪树上的邻居，把伪树根连接到该邻居的当前父结点 嫁接后续工作：继续用指针跳转法星化伪树(连通分量内的伪树之高总和不会因为嫁接变大，并且，每个指针跳转迭代都至少乘以2/3) 改进$W(O(n^2) -&gt; O((m + n)logn))$: Algorithm 5.212345678910111213141516171819(Connected Components for Sparse Graphs)Input: (1)A set of edges (i, j) given in an arbitrary order, and (2) a pseudoforest defined by a function D such that all the vertices in each tree belong to the same connected component.Output: The pseudoforest obtained after (1) grafting trees onto smaller vertices of other trees, (2) grafting rooted stars onto other trees if possible, and (3) performing the pointer jumping operation on each vertex. Description of a general iterationbegin1. perform a grafting operation if trees onto smaller vertices of other trees as follows(非对称嫁接):for all (i, j) belong to E pardo if (D(i) = D(D(i)) and D(j) &lt; D(i)) then set D(D(i)) := D(j)2. Graft rooted stars onto other trees if possible, as follows(星嫁接):for all (i, j) belong to E pardo if (i belongs to a star and D(j) != D(i)) then set D(D(i)) := D(j)3. If all the vertices are in rooted stars, then exit. Otherwise, perform the pointer jumping operation on each vertex as follows:for all i pardo set D(i) := D(D(i))end 非对称嫁接不会使连通分量里的伪树的高度总和变大 星嫁接不会使连通分量里的伪树的高度总和变大 (一遍)指针跳转法压缩伪树把不是星化伪树的高度降为至少原来的2/3(高度为1的不再降、高度为2的降为1、高度为3的降为2、高度为4的将为2……) 最小生成树 在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边，而 w(u, v) 代表此边的权重 若存在 T 为 E 的子集且为无循环图，使得 的 w(T) 最小，则此 T 为 G 的最小生成树 最小生成树其实是最小权重生成树的简称 最小生成树串行算法输入：一个加权连通图，其中顶点集合为V，边集合为E 初始化：$V{new} = {x}$，其中x为集合V中的任一节点(起始点)，$E{new}= {}$,为空 重复下列操作，直到$V_{new} = V$: 在集合E中选取权值最小的边，其中u为集合$V{new}$中的元素，而v不在$V{new}$集合当中，并且$v∈V$(如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一) 将v加入集合$V{new}$中，将边加入集合$E{new}$中 输出：使用集合$V{new}$和$E{new}$来描述所得到的最小生成树 Prim’s algorithm kruskal’s algorithm 最小生成树并行算法基本思想: 如果(u,C(u))是从u出发的最小权边，则(u,C(u))必在最小生成树中;若不然，设最小生成树中从u到C(u)的路径是u,x_1,x_2,…,x_s,C(u)，则另一路径u,C(u),x_s,…,x_2,x_1串连了这些节点，并且权和更小 函数C定义了一个伪森林，使得其中的每棵伪树上有且仅有一个环 用指针跳转法可以把每棵伪树星化，并聚合成超顶点 取超顶点之间的边权为它们的跨伪树的连接边的最小权，并用C(.)来生成另一级别的伪森林，从而可以继续星化和合并超顶点 Sollin’s MST algorithm $T = O(log^2n), W = O(n^2)$ Algorithm 5.312345678910111213(Minimum Spanning Tree)Input: An n*n array W, representing a weighted connected graph such that no two edges have the same weight.Output: A label for each edge belonging to the MST.begin1. Set W_0 := W, n_0 := n, k := 02. while (n_k &gt; 1) do 2.1 Set k := k + 1 2.2 Set C(v) := u, where W_k-1(v, u) = min&#123;W_k-1(v, x)|x != v&#125;. Mark (v, C(v)). 2.3 Shrink each directed tree of the pseudoforest defined by C to a rooted star. 2.4 Set n_k to be equal to the number of the rooted stars, and set W_k to the n_k * n_k weight matrix of the graph induced by viewing each star as a single vertex.3. Restore each marked edge to its original name. end","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"列表和树","slug":"parellel_and_distributed_computing/paralell_compute3","date":"2017-03-13T16:00:00.000Z","updated":"2017-03-25T03:39:38.176Z","comments":true,"path":"2017/03/14/parellel_and_distributed_computing/paralell_compute3/","link":"","permalink":"https://chenfeng.github.io/2017/03/14/parellel_and_distributed_computing/paralell_compute3/","excerpt":"(并行与分布式计算二) 列表排序The list-ranking problem is to determine the distance of each node i from the end of the list 指针跳转法(pointer jumping technique)思想： 链表中的指针跳转可以由一次跳转一步改为一次跳转多步 如果能在O（1）时间内一次跳转k步，那么一次跳转2k步只需要双倍时间 如果为每个节点，把一次跳转2k步的跳转结果记录下来，那么以后一次跳转2k步也只需要O（1）时间 反复利用跳转步数翻倍和跳转结果记录的技巧，可以在O（log N）的时间内把跳转步数扩大为N","text":"(并行与分布式计算二) 列表排序The list-ranking problem is to determine the distance of each node i from the end of the list 指针跳转法(pointer jumping technique)思想： 链表中的指针跳转可以由一次跳转一步改为一次跳转多步 如果能在O（1）时间内一次跳转k步，那么一次跳转2k步只需要双倍时间 如果为每个节点，把一次跳转2k步的跳转结果记录下来，那么以后一次跳转2k步也只需要O（1）时间 反复利用跳转步数翻倍和跳转结果记录的技巧，可以在O（log N）的时间内把跳转步数扩大为N T = O(logn); W = O(nlogn)并不比串行算法(linear, O(n))更优 Algorithm 3.112345678910111213141516# List Ranking Using Pointer JumpingInput: A linked list of n nodes such that (1)the successor of each node i is given by S(i), and (2)the S value of the last node on the list is euqal to 0.Output: For each 1 &lt;= i &lt;= n, the distance R(i) of node i from the end of the list.begin1. for 1 &lt;= i &lt;= n pardo if (S(i) != 0) then set R(i):= 1 else set R(i):= 02. for 1 &lt;= i &lt;= n pardo set Q(i) := S(i) while (Q(i) ！= 0 and Q(Q(i)) != 0) do set R(i) := R(i) + R(Q(i)) set Q(i) := Q(Q(i))end 优化思路: 用快速并行算法把链表长度缩短为n/log n 要求：缩短和恢复都可以用很小的T，并且W=O(n) 方法：通过删除链表中的独立顶点集来缩短链表 在缩短的链表上用指针跳转法来求序，只需W=O(n) 最后用快速并行算法来恢复链表的长度 也即： 把列表分成约n/logn块{ $B_{i}$ }, 每块包含O(logn)个节点 在每块内对每个节点用最优串行算法求序(preliminary rank) 用O(logn)的平行算法把所有排好序的块组合 List-Ranking Strategy Shrink the linked list L until only O(n/logn) nodes remain. Apply the pointer jumping technique(Algorithm 3.1) on the short list of the remaining nodes. Restore the original list and rank all the nodes removed in step 1. independent sets A set I of nodes is independent if, whenever i belongs to I, S(i) not belongs to I. 缩减的列表结点必须构成一个独立集，即不相邻 Algorithm 3.21234567891011121314# removing nodes of an independent setInput: (1)Arrays S and P of length n representing, respectively, the successor and predecessor relations of linked list; (2)an independent set I of nodes such that P(i), S(i) != 0; (3)a value R(i) for each node i.Output: The list obtained after removal of all the nodes in I with the updated R values.begin1. Assign consecutive serial numbers N(i) to the elements of I, where 1 &lt;= N(i) &lt;= |I| = n'.2. for for all i belongs to I pardo set U(N(i)) := (i, S(i), R(i)) set R(P(i)) := R(P(i) + R(i)) set S(P(i)) := S(i) set P(S(i)) := P(i)end 删除独立顶点集并合并其权重到剩余顶点的并行复杂度: T=O(1) W=O(n) Determination of an Independent Set独立集合充分大：存在常数c，c属于(0, 1)，使集合包含顶点数不少于c×n 保证快速地迭代缩短链表 把长度为n的链表缩短为n/logn只需不超过log_1-c(logn)的T 最理想但没有快速算法：用序的奇偶性确定独立顶点集合，c=1/2 (存在快速算法)对链表使用三色着色算法，把局部最小色数(或最大)的节点作为独立集元素 从一个局部极小到下一个局部极小着色点，中间经过的点数最多为3，因此C=1/4 3-color 算法收敛很快，每次调用算法，着色的色数都变小为原色数的对数比例，这里的对数以2为基底 要把色数变小为3，T几乎是O(1) Algorithm 3.312345678910111213141516# simple optimal list rankingInput: A linked list with n nodes suc that the successor of each node i is given by S(i).Output: For each node i, the distance of i from the end of the list.begin1. set n_0 := n, k := 02. while n_k &gt; n/logn do 2.1 set k := k + 1 2.2 color the list with three colors and identify the set I of local minima. 2.3 remove the nodes in I, and store the appropriate information regarding the removed nodes(Algorithm 3.2). 2.4 let n_k be the size of the remaining list. compact the list into consecutive memory locations.3. apply the pointer jumping technique (Algorithm 3.1) to the resulting list.4. restore the original list and rank all the removed nodes by reversing the process performed in step2.end 缩短链表和恢复链表：T = O(log logn), W = O(n) 把长度为n的链表缩短为n/logn，只需不超过log_1-c(logn)的T 第一次迭代W = O(n), 第二次迭代W = O((1 - c)*c), … W = O(n + (1 - c)n + (1 - c)^2 *n + …) = O(n/c) = O(n) 恢复和缩短是对称的，T和W都相同 指针跳转是在长度为n/logn的已缩短链表上zuo做的，T = O(logn), W = O(n) 算法的并行复杂度: T = O(loglogn); W = (n) *一个优化的时间复杂度为O(logn)的列表求序算法…… 欧拉回路(the Euler-Tour Technique)树的欧拉回路是指：将一棵树的每一条边换成两条指向相反的有向边，成为一个欧拉图，就存在欧拉回路；可以定义一个论域为所有有向边的函数s(successor function)，描述这棵树的欧拉回路 Lemma 3.6: Given a tree T = (V, E) and an ordering of the set of vertices adjacent to each vertex v belongs to V, the function s defined previously specifies an Euler circuit in the directed graph T’ = (V, E’), where E’ is obtained by replacement of each e belongs to E by two arcs of opposite directions. we call the Euler circuit of T’ the Euler tour of T 每棵树都有欧拉回路 如果欧拉回路从树的根节点出发，则它实际上是树的节点深度优先遍历路径 给出一个由邻接表及附加的指针信息描述的树，求得一条欧拉回路的T = O(1), W = O(n), |V| = n(指针信息: data field + pointer * 2(描述下一个邻接点 + 描述该点在邻接表中指向此顶点的item)) 树求根(rooting a tree): 树根结点为r，对于每个非根结点v，寻找其父父结点p(v) 一对顶点之间的两条弧，先出后进的顶点是父节点，先进后出的是子节点 弧的顺序的确定：-把欧拉回路从其中一点处断开（例如去除回路路径列表中的最前与最后的弧的相邻关系） 用链表求序来对这些弧定序 树的一个欧拉回路为L[r] = &lt; u_0, u_1, … , u_d-1 &gt; 设s(&lt; u_d-1, r &gt;) = 0，将欧拉回路从r处截断，得到一条始于r，遍历所有顶点一次，终于r的欧拉路径 Algorithm 3.51234567891011# rooting a treeInput: (1)a tree T defined by the adjacency lists of its vertices, (2)an Euler tour defined by the successor function s, and (3)a special vertex rOutput: For each vertex v != r, the parent p(v) of v in the tree rooted at r.begin1. Identify the last vertex u appearing on the adjacency list of r. set s(&lt;u, r&gt;) = 02. Assign a weight of 1 to each arc &lt;x, y&gt;, and apply parallel prefix on the list of arcs defined by s.3. For each arc &lt;x, y&gt;, set x = p(y) whenever the prefix sum of &lt;x, y&gt; is smaller than the prefix sum of &lt;y, x&gt;.end 并行复杂度与链表求序相同： T=O(log n log log n) ？？？ W=O(n) 这里n是顶点数（树的边数是顶点数减一） 1、Postorder Numbering 后序遍历的序数 往下走的弧的权重为0，往上走的弧的权重为1，然后用链表中求前缀和的方法来算出后序遍历编号 Algorithm 3.61234567891011# Postorder NumberingInput: (1)A rooted binary tree with root r, and (2)the coresponding Euler path defined by the function sOutput: The postorder number post(v) of each vertex vbegin1. For each vertex v != r, assign the weights w(&lt;v, p(v)&gt;) = 1 and w(&lt;p(v&gt;, v) = 02. Perform parallel prefix on the list of arcs defined by s.3. For each vertex v != r, set post(v) equal to the prefix sum of &lt;v, p(v)&gt;. For v = r, set post(v) = n, where n is the number of vertices in the given tree.end 2、Computing the Vertex level 结点层数 可用类似Algorithm 3.6的算法，1和3做改动: w() = +1; w() = -1。level(v) = 的前缀和 3、Computing the preorder Number w(&lt; p(v), v &gt;) = 1; w(&lt; v, p(v) &gt;) = 0; preorder(v) = &lt; p(v), v &gt;前缀和 + 1; preorder(r) = 1 4、Computing the Number of Descendants w(&lt; p(v), v &gt;) = 1; w(&lt; v, p(v) &gt;) = 0; desc(v) = &lt; v, p(v) &gt;前缀和 - &lt; p(v), v &gt;前缀和; desc(r) = n - 1 以上四个并行算法:T = O(logn); W = O(n)（由平衡树方法求前缀和的平行算法所决定） *Tree Contraction(树收缩) …… *Lowest Common Ancestors ……","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"计算机网络和因特网","slug":"computer_network/computer_network_1","date":"2017-02-27T16:00:00.000Z","updated":"2017-04-23T12:33:50.854Z","comments":true,"path":"2017/02/28/computer_network/computer_network_1/","link":"","permalink":"https://chenfeng.github.io/2017/02/28/computer_network/computer_network_1/","excerpt":"因特网连接到因特网的设备：主机(host)或端系统(end system) 端系统通过通信链路(communication link)和分组交换机(parket switch)连接到一起 路由器(router) 链路层交换机(link-layer switch) 端系统通过因特网服务提供商(Internet Service Provider, ISP)接入因特网 因特网部件运行一系列协议(protocol),协议控制因特网中信息的接受和发送","text":"因特网连接到因特网的设备：主机(host)或端系统(end system) 端系统通过通信链路(communication link)和分组交换机(parket switch)连接到一起 路由器(router) 链路层交换机(link-layer switch) 端系统通过因特网服务提供商(Internet Service Provider, ISP)接入因特网 因特网部件运行一系列协议(protocol),协议控制因特网中信息的接受和发送 Reliable Stream Transport Service:Sends a large amount of data across a reliable “connection” Connectionless Packet Delivery Service:Routes small messages from one computer to another TCP(Transmission Control Protocol, 传输控制协议) IP(Internet Protocol, 网际协议)定义在路由器和端系统之间发送和接受的分组格式 因特网标准(Internet standard)由因特网工程任务组(Internet Engineering task Force, IETF)研发 IETF标准文档称请求评论(Request For Comment, RFC) 分布式应用程序(distributed application)涉及多台相互交换数据的端系统 应用程序编程接口(Application Programming Interface, API) 网络边缘主机(hosts) = 端系统: 客户(client)和服务器(server) 数据中心(data center)由许多服务器构成 接入网(access network)指将端系统连接到其边缘路由器(edge router)的物理链路 residential access nets institutional access networks (school, company) mobile access networks bandwidth(bit per second, bps); shared / dedicated(专用) 数字用户线(Digital Subscriber Line, DSL): existing telephone line to central office DSLAM &lt; 2.5 Mbps upstream transmission rate (typically &lt; 1 Mbps) &lt; 24 Mbps downstream transmission rate (typically &lt; 10 Mbps) frequency division multiplexing: different channels transmitted in different frequency bands 电缆因特网接入(cable Internet access) 有线电视 HFC: hybrid fiber coax asymmetric: up to 30Mbps downstream transmission rate, 2 Mbps upstream transmission rate 以太网Ethernet 光纤到户(Fiber To The Home, FTTH) 光纤分布体系结构：主动光纤网络(Active Optical Network, AON)和被动光纤网络(Passive Optical Network, PON) 光纤网络端接器(Optical Network Terminator, ONT) 分配器(splitter) 光纤线路端接器(Optical Line Terminator, OLT) 无线网络wireless network wireless LANs: within building (100 ft.) 802.11b/g/n (WiFi): 11, 54, 450 Mbps transmission rate wide-area wireless access provided by telco (cellular) operator, 10’s km between 1 and 10 Mbps 3G, 4G: LTE host sending function: takes application message breaks into smaller chunks, known as packets, of length L bits transmits packet into access network at transmission rate R link transmission rate, aka link capacity, aka link bandwidth 物理媒体(physical medium): 双绞铜线、同轴电缆、多模光纤缆、陆地无线电频谱、卫星无线电频谱 bit: propagates between transmitter/receiver pairs physical link: what lies between transmitter &amp; receiver 导引型媒体(guided media): signals propagate in solid media: copper, fiber, coax 非导引型媒体(unguided media): signals propagate freely, e.g., radio 双绞铜线 twisted pair (TP): two insulated copper wires Category 5: 100 Mbps, 1 Gbps Ethernet Category 6: 10Gbps 两根隔离的铜线以规则的螺旋形式排列组成；两根线绞合起来以减少邻近类似双绞线的电气干扰 一对电线构成一个通信链路；通常许多双绞线捆扎在一起成电缆 无屏蔽双绞线(Unshielded Twisted Pair, UTP) 常用于建筑物内网络 同轴电缆 coaxial cable: two concentric copper conductors bidirectional broadband: multiple channels on cable HFC 光纤 fiber optic cable: glass fiber carrying light pulses, each pulse a bit high-speed operation: high-speed point-to-point transmission (e.g., 10’s-100’s Gbps transmission rate) low error rate: repeaters spaced far apart immune to electromagnetic noise(不受电磁干扰) 单模光纤速率高，价格贵; 多模光纤速率低，价格便宜 电磁波 ratio signal carried in electromagnetic spectrum no physical “wire” bidirectional propagation environment effects: reflection obstruction by objects interference adio link types: terrestrial microwavee.g. up to 45 Mbps channels LAN (e.g., WiFi)54 Mbps wide-area (e.g., cellular)4G cellular: ~ 10 Mbps satellite Kbps to 45Mbps channel (or multiple smaller channels) 270 msec end-end delay geosynchronous versus low altitude 同步卫星(geostationary satellite); 近地轨道(Low-Earth Orbiting, LEO)卫星 编码(encoding)Non-return to Zero Inverted (NRZI): make a transition from current signal to encode a one; stay at current signal to encode a zero solves the problem of consecutive ones 经网络传输数据会产生时钟同步问题 Manchester: transmit XOR of the NRZ encoded data and the clock only 50% efficient (bit rate = 1/2 baud rate) 包含丰富的时钟信息 4B/5B: every 4 bits of data encoded in a 5-bit code 5-bit codes selected to have no more than one leading 0 and no more than two trailing 0s thus, never get more than three consecutive 0s resulting 5-bit codes are transmitted using NRZI achieves 80% efficiency 数据帧化Framing Break sequence of bits into a frame Typically implemented by network adaptor Sentinel-based: delineate frame with special pattern: 01111110 e.g., HDLC, SDLC, PPP Beginning sequence(8) + Header(16) + Body + CRC(16) + Ending sequence(8) problem: special pattern appears in the payload solution: bit stuffing sender: insert 0 after five consecutive 1s receiver: delete 0 that follows five consecutive 1s Counter-based: include payload length in header e.g., DDCMP SYN(8) + SYN(8) + Class(8) + Count(14) + Header(42) + Body + CRC(16) problem: count field corrupted solution: catch when CRC fails Clock-based: each frame is 125us long e.g., SONET: Synchronous Optical Network STS-n (STS-1 = 51.84 Mbps) 网络核心Communication networks can be classified based on the way in which the nodes exchange information: Communication Network: Broadcast Communication Network Switched Communication Network Circuit-Switched Communication Network Packet-Switched Communication Network Datagram Network Virtual Circuit Network Connection Oriented(面向连接)Has connection establish and release procedures Similar to circuit switched Transmission in order Bandwidth may be guaranteed Flow control may exist Error control may exist Connectionless(无连接)Each datagram may take a different path Datagrams may arrive out of order Link failures not a problem problem in a Generic Switch incoming links : how to demultiplex switch : how to switch outgoing links : how to multiplex Packet Switching(分组交换)各种网络应用中，端系统彼此交换报文(message) 分组(packet swicth): 源端系统像目的端系统发送报文，源将报文划分为较小的数据块 每个分组通过通信链路和分组交换机(packet switch)传送 两类交换机: 路由器和链路层交换机 packet-switching: hosts break application-layer messages into packets Data from any conversation can be transmitted at any given time A single conversation can use the entire link capacity if it is alone How to demultiplex? Use meta-data (header) to describe data Data are sent as formatted bit-sequences so-called packets. Packets have the following structure: Header + Data + Tailer Header and Trailer carry control information e.g., destination address, check sum 输出缓存(output buffer)(输出队列 output queue): 用于存储路由器准备发往相连的链路的分组; Store-and-Forward Networks(存储转发传输): At each node the entire packet is received, stored briefly, and then forwarded to the next node based on the header information Allows statistical(统计的) multiplexing 在接收完所有的比特后进行查错，无误在再进行转发 “热土豆”传输: 一边接收，一边转发 适用于网络质量好，出错概率低的情况 通过N条速率均为R的链路组成的路径(源和目的地之间有N-1台路由器)发送一个分组，端到端时延: d_{EndToEnd} = N \\frac{L}{R}takes L/R seconds to transmit L-bit packet into link at R bps one-hop numerical example: L = 7.5 Mbits R = 1.5 Mbps one-hop transmission delay = 5 sec packet-switching forward packets from one router to the next across links on path from source to destination Each packet is independently switched header contains destination address Two key network-core functions routing: determines source-destination route taken by packets routing algorithms forwarding: move packets from router’s input to appropriate router output 排队时延(queue delay):到达的分组在链路忙于传输其他分组时必须在输出缓存中等待; 分组丢失(丢包 packet lost): 一个分组到达时缓存已被其他等待传输的分组完全充满，到达的分组或已经排队的分组之一将被丢弃 queuing and loss: if arrival rate exceeds transmission rate of link for a period of time packets will queue, wait to be transmitted on link can be dropped (lost) if memory (buffer) fills up Circuit Switching(电路交换)两台主机通信时网络在两台主机之间创建一条专用的端到端连接(end-to-end connection) 频分复用(Frequency-Division Multiplexing, FDM): 链路的频谱由跨越链路创建的所有连接所共享; 在连接期间链路为每条连接专用一个频段 时分复用(Time-Division Multiplexing, TDM): 时间被划分为固定区间的帧(frame)，每帧划分为固定数量的时隙; 网络跨越一条链路创建一条连接时在每个帧中为该连接指定一个时隙(slot) Time divided in frames and frames divided in slots Relative slot position inside a frame determines which conversation the data belongs to Needs synchronization(同步) between sender and receiver If a conversation does not use its circuit the capacity is lost Three phases(三个阶段) circuit establishment data transfer circuit termination If circuit not available: busy Examples Telephone networks ISDN (Integrated Services Digital Networks)(综合业务数字网) end-end resources allocated to, reserved for “call” between source &amp; dest dedicated resources: no sharing circuit-like (guaranteed) performance circuit segment idle(闲置) if not used by call (no sharing) Packet-Switching vs. Circuit-SwitchingMost important advantage of packet-switching: Ability to exploit statistical multiplexing More efficient bandwidth usage However, packet-switching needs to buffer and deal with congestion More complex switches Harder to provide good network services (e.g., delay and bandwidth guarantees) packet switching allows more users to use network example: 1 Mb/s linkeach user: 100 kb/s when “active” active 10% of time circuit-switching: 10 users packet switching: with 35 users, probability &gt; 10 active at same time is less than .0004 * packet switching: great for bursty data resource sharing simpler, no call setup excessive congestion possible: packet delay and loss protocols needed for reliable data transfer, congestion control Q: How to provide circuit-like behavior? bandwidth guarantees needed for audio/video apps Virtual-Circuit Packet Switching(虚电路交换) Hybrid of circuit switching and packet switching Data is transmitted as packets All packets from one packet stream are sent along a pre-established path (=virtual circuit) Guarantees in-sequence delivery of packets Packet header only contains local virtual circuit identifier (VCI) Demultiplexing and switching based on VCI Note: packet headers don’t need to contain the full destination address of the packet Example: ATM networks Communication with virtual circuits takes place in three phases VC establishment data transfer VC disconnect Internet structure: network of networks(网络的网络)End systems connect to Internet via access ISPs (Internet Service Providers) residential, company and university ISPs Access ISPs in turn must be interconnected. so that any two hosts can send packets to each other Resulting network of networks is very complex evolution was driven by economics and national policies Question: given millions of access ISPs, how to connect them together?Option: connect each access ISP to every other access ISP?Option: connect each access ISP to one global transit ISP? Customer and provider ISPs have economic agreement. at center: small # of well-connected large networks “tier-1” commercial ISPs (e.g., Level 3, Sprint, AT&amp;T, NTT), national &amp; international coverage content provider network (e.g., Google): private network that connects it data centers to Internet, often bypassing tier-1, regional ISPs 分组交换网中的时延、丢包和吞吐量(delay, loss, throughput in networks)时延 结点处理时延(nodal processing delay): 检查分组首部和决定出口链路、查错校验 排队时延(queuing delay): 分组在出口链路队列上等待传输 传输时延(transmission delay): L/R(分组长度/链路传输速率); 将所有分组比特推(传输)向链路所需时间 传播时延(propagation delay): d/s(距离/传播速率)，介质相关 结点总时延(total nodal delay) d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}How do loss and delay occur:packets queue in router buffers packet arrival rate to link (temporarily) exceeds output link capacity packets queue, wait for turn $d_{proc}$: nodal processing check bit errors determine output link typically &lt; msec $d_{queue}$: queueing delay time waiting at output link for transmission depends on congestion level of router $d_{trans}$: transmission delay L: packet length (bits) R: link bandwidth (bps) $d_{trans} = L/R$ $d_{prop}$: propagation delay d: length of physical link s: propagation speed (~2x108 m/sec) $d_{prop} = d/s$ $d{trans}$ and $d{prop}$ are very different 排队时延和丢包流量强度(traffic intensity): La/R; a: 分组到达队列的平均速率(pkt/s)(a: average packet arrival rate) R: link bandwidth (bps) L: packet length (bits) La/R ~ 0: avg. queueing delay small La/R -&gt; 1: avg. queueing delay large La/R &gt; 1: more “work” arriving than can be serviced, average delay infinite! 设计系统时流量强度不能大于1 随着流量强度接近于1，平均排队时延迅速增加 丢包: 分组到达时路由器链路队列已满，路由器丢弃(drop)该分组，该分组会丢失(lost) queue (aka buffer) preceding link in buffer has finite capacity packet arriving to full queue dropped (aka lost) lost packet may be retransmitted by previous node, by source end system, or not at all 吞吐量(throughput)瞬时吞吐量(instantaneous throughput): 主机接收到文件的速率(bps) 平均吞吐量(average throughput): F/T秒; 接收总共F比特用去T秒 瓶颈链路(bottleneck link): 系统中传输速率最小的链路 throughput: rate (bits/time unit) at which bits transferred between sender/receiver instantaneous: rate at given point in time average: rate over longer period of time bottleneck link:link on end-end path that constrains end-end throughput 协议层次 服务模型(protocol layers, service models)分层(layer) layers: each layer implements a service via its own internal-layer actions relying on services provided by layer below 协议栈(protocol stack) 应用层(第七层): 报文(message) 运输层(四层): 报文段(segment) 网络层(三层): 数据报(datagram) 链路层(二层): 帧(frame) 物理层(一层): 将帧中的比特一个一个从一个结点移动到下一个结点 OSI(Open System Interconnect Reference Model, 开放系统互联参考模型) 表示层: 数据压缩、数据加密、数据描述 会话层: 数据交换定界、同步功能，建立检查点和恢复方案 Internet protocol stack: application: supporting network applications FTP, SMTP, HTTP transport: process-process data transfer TCP, UDP network: routing of datagrams from source to destination IP, routing protocols link: data transfer between neighboring network elements Ethernet, 802.111 (WiFi), PPP physical: bits “on the wire ISO/OSI reference model: (two more layer) presentation: allow applications to interpret meaning of data, e.g., encryption, compression, machine-specific conventions session: synchronization, checkpointing, recovery of data exchangeInternet stack “missing” these layers! these services, if needed, must be implemented in application 封装(encaosulation): 应用层报文(application-layer message) -&gt; 运输层报文段(transport-layer segment) -&gt; 网络层数据报(network-layer datagram) -&gt; 链路层帧(link-layer frame) 分组 : 首部字段 + 有效载荷字段(payload field)(来自上一层的分组) 面对攻击的网络(networks under attack: security)Internet not originally designed with (much) security in mind original vision: “a group of mutually trusting users attached to a transparent network”  Internet protocol designers playing “catch-up” security considerations in all layers! 恶意软件(malware) 僵尸网络(botnet) 病毒(virus): 需要某种形式的用户交互感染用户设备的恶意软件 蠕虫(worm): 无需任何明显用户交互就能进入设备的恶意软件 malware can get in host from: virus: self-replicating infection by receiving/executing object (e.g., e-mail attachment) worm: self-replicating infection by passively receiving object that gets itself executed spyware malware can record keystrokes, web sites visited, upload info to collection site infected host can be enrolled in botnet, used for spam. DDoS attacks 拒绝服务攻击(Denial-of-Service (DoS) attack) 弱点攻击: 向一台目标主机上运行的易受攻击的应用程序或操作系统发送制作精细的报文 带宽洪泛: 向目标主机发送大量的分组使目标接入链路拥塞 连接洪泛: 在目标主机中创建大量半开或全开TCP连接 分布式Dos(Distributed DoS, DDoS): 攻击者控制多个源向目标发送大量流量 Denial of Service(DoS): attackers make resources (server, bandwidth) unavailable to legitimate traffic by overwhelming resource with bogus traffic select target break into hosts around the network (see botnet) send packets to target from compromised hosts 分组嗅探器(packet sniffer) packet “sniffing”: broadcast media (shared Ethernet, wireless) promiscuous network interface reads/records all packets (e.g., including passwords!) passing by wireshark software is a (free) packet-sniffer IP哄骗(IP spooning) IP spoofing: send packet with false source address ~ history","categories":[],"tags":[{"name":"computer network","slug":"computer-network","permalink":"https://chenfeng.github.io/tags/computer-network/"}]},{"title":"并行计算基础知识及基本并行算法","slug":"parellel_and_distributed_computing/paralell_compute1&2","date":"2017-02-27T16:00:00.000Z","updated":"2017-04-03T08:27:31.927Z","comments":true,"path":"2017/02/28/parellel_and_distributed_computing/paralell_compute1&2/","link":"","permalink":"https://chenfeng.github.io/2017/02/28/parellel_and_distributed_computing/paralell_compute1&2/","excerpt":"(并行与分布式计算一) 基础知识设计分布式并行算法基本流程1.1发现计算问题的内在并行性 1.2设计与硬件无关的并行算法","text":"(并行与分布式计算一) 基础知识设计分布式并行算法基本流程1.1发现计算问题的内在并行性 1.2设计与硬件无关的并行算法 让算法设计者专注于挖掘问题相关的内在并行性而不是被繁琐的硬件特性所干扰 便于不同硬件环境下的开发者移植算法 便于算法到硬件的映射的自动匹配和优化 为并行和分布式计算的系统库(中间件)研发提供一套高层语义抽象 PRAM(Parallel Random Access Machine, 随机存取并行机器): 一个简单的并行算法模型 Parallel: 可以自由分布任意个处理器并行地读、写和计算 Random Access: 处理器可以按下面其中一条规则自由地访问“共享内存” 规则一: Exclusive Read Exclusive Write(EREW)(不允许同时读和同时写) 规则二: Concurrent Read Exclusive Write(CREW)(允许同时读但不允许同时写) 规则三: Concurrent Read Concurrent Write(CRCW)(允许同时读和同时写) 算法复杂度框架: work(计算量(operation)), time(计算时间) 2.1发现硬件的网络拓扑和处理能力 网络拓扑: 静态: 环、星、树、超立方、图 动态: 互联网或移动网络中的分布式计算 处理能力: 指标: 处理速度和处理规模 结构: 同构、异构 方式: 内存计算还是内外存混合计算，计算密集型还是数据密集型 发现网络拓扑的算法: 目的一: 建立数据通信的路由 目的二: 死锁检测和解除 目的三: 优化数据传播和交换 发现处理能力的方法: 测试程序 人工检测 2.2设计与计算问题无关的分布式计算协议 (所需计算协议包括以下但不止) 广播、多播和数据收集 同步和异步控制 终止检测和全局谓词(条件)检测 快照保存与检查点恢复 3.把并行算法映射到硬件上，匹配、优化 匹配: 与硬件相关的具体并行算法 数据分划和任务指派方案(静态或动态) 并行和分布式计算的程序 优化: 面向硬件体系结构的算法复杂度分析 针对硬件特性的算法改进和程序调优 并行计算的基本方法平衡树方法(Balanced Trees) 例: 设*是满足结合律的二元运算符，考虑计算S_i = x_1 * x_2 * ... * x_i, 1 \\leq i \\leq n Algorithm 2.112345678910111213141516# Prefix SumsInput: An array of n = 2^k elements (x_1, x_2, ..., x_n), where k is a nonnegative integer.Output: The prefix sums s_i, for 1 &lt;= i &lt;= n.begin1. if n = 1 then &#123;set s_1 := x_1; exit&#125;2. for 1 &lt;= i &lt;= n/2 pardo set y_i := x_2i-1 * x_2i3. Recursively, compute the prefix sums of &#123;y_1, y_2, ..., y_n&#125;, and store them in z_1, z_2, ..., z_n/24. for 1 &lt;= i &lt;= n pardo &#123;i even : set s_i := z_i/2 i = 1 : set s_1 := x_1 i odd &gt; 1 : set s_i := z_(i-1)/2 * x_i&#125;end 复杂度分析T(n) = T(\\frac{n}{2}) + aW(n) = W(\\frac{n}{2}) + bn求解递归方程T(n) = O(logn)W(n) = O(n) Algorithm 2.2123456789101112131415161718# Nonrecursive Prefix SumsInput: An array A of size n = 2^k, where k is a nonnegative integer.Output: An array C such that C(0, j) is the jth prefix sum, for 1 &lt;= j &lt;= nbegin1. for 1 &lt;= j &lt;= n pardo set B(0, j) := A(j)2. for h = 1 to logn do for 1 &lt;= j &lt;= n/2^h pardo set B(h, j) := B(h - 1, 2j - 1) * B(h - 1, 2j)3. for h = logn to 0 do for 1 &lt;= j &lt;= n/2^h pardo &#123;j even : set C(h, j) := C(h + 1, j/2) j = 1 : set C(h, 1) := B(h, 1) j odd &gt; 1 : set C(h, j) := C(h + 1, (j - 1)/2)*B(h, j)&#125;end 指针跳转法(Pointer Jumping) 例一: 存储在数组中的链表求序 串行算法: 线性复杂度 并行复杂度: T = O(logn), W = O(nlogn) 例二: 为森林里的每个节点找所在的那棵树的根节点 Algorithm 2.4123456789101112# Pointer JumpingInput: A forest of rooted directed trees, each with a self-loop at its root, such that each arc is specified by (i, P(i)), where 1 &lt;= i &lt;= n.Output: For each vertex i, the root S(i) of the tree containing i.begin1. for 1 &lt;= i &lt;= n pardo set S(i) := P(i) while (S(i)) != S(S(i)) do set S(i) := S(S(i))end T = O(logh); W = O(nlogh) Algorithm 2.512345678910111213# Parallel Prefix on Rooted Directed TreesInput: A forest of rooted directed trees, each with a self-loop at its root such that (1)each arc is specified by (i, P(i)), (2)each vertex i has a weight W(i), and (3)for each root r, W(r) = 0Output: For each vertex i, W(i) is set equal to the sum of the weights of vertices on the path from i to the root of its tree.begin1. for 1 &lt;= i &lt;= n pardo set S(i) := P(i) while (S(i)) != S(S(i)) do set W(i) := W(i) + W(S(i)) set S(i) := S(S(i))end T = O(logn); W = O(nlogn) 分而治之法(Divide and Conquer)例: 找二维平面上的点的凸包(planar convex hull) 分: 把这些顶点按由左到右平均分成两组 治: 在这两组内分别求凸包(求解两个规模相对较小的问题，递归) 合: 把两组凸包用快速算法合为一个 Algorithm 2.61234567891011# Simple Upper HullInput: A set S of n points in the plane, no two of which have the same x or y coordinates such that x(p_1) &lt; x(p_2) &lt; ... &lt; x(p_n), where n is a power of 2.Output: The upper hull of S.begin1. If n &lt;= 4, then use a brute-force method to determine UH(S), and exit.2. Let S_1 = (p_1, p_2, ..., P_n/2) and S_2 = (p_n/2+1, ..., p_n). Recursively, compute UH(S_1) and UH(S_2) in parallel.3. find the upper common tangent between UH(S_1) nad UH(S_2), and deduce the upper hull of S.end T(n) \\leq T(\\frac{n}{2}) + alognW(n) \\leq 2W(\\frac{n}{2} + bn)并行复杂度: $ T = O(log^2 n); W = O(nlogn) $ 数据划分法(partition strategy) 例: 归并排序 1.数据均分为若干等分 2.在每一等分内用其它方法排序 3.平衡树快速并行合并这些等分 Algorithm 2.7123456789101112131415# PartitionInput: Two arrays A = (a_1, a_2, ..., a_n) and B = (b_1, b_2, ..., b_m) in increasing order, where both logm and k(m) = m/logm are integers.Output: k(m) pairs (A_i, B_i) of subsequences of A and B such that (1)|B_i| = log m, (2)\\sum |A_i| = n, and (3)each element of A_i and B_i is larger than each element of A_i-1 or B_i-1, for all 1 &lt;= i &lt;= k(m)-1begin1. set j(0) := 0, j(k(m)) := n2. for 1 &lt;= i &lt;= k(m) - 1 pardo 2.1. Rank b_ilogm in A using binary search method, and let j(i) = rank(b_ilogm : A)3. for 0 &lt;= i &lt;= k(m) - 1 pardo 3.1. set B_i := (b_ilogm+1, ..., b_(i+1)logm) 3.2. set A_i := (a_j(i) + 1, ..., a_j(i+1)) (A_i is empty if j(i) = j(i+1))end 合并后的序 = 自序 + 交叉序 自序(a_i) = {a_0, a_1, …, a_n-1}中有多少a_j 排在a_i前面(在这里即i) 交叉序(a_i) = {b_0, b_1, …, b_n-1}中有多少b_j排在a_i前面 并行复杂度: T = O(logn); W = O(n) 流水线方法(Pipelining) 例: 2-3树的数据插入 批量插入多个点及其并行复杂度T = O(logn); W = O(klogn) breaking up a task into a sequence of subtask t_1, t_2, …, t_m…… 加速层叠法(Accelerated Cascading) 例: 数组找最大值 常数的并行时间复杂度 Algorithm 2.8123456789101112# Basic MaximumInput: An array A of p distinct elements.Output: A Boolean array M such that M(i) = 1 if and only if A(i) is the maximum element of A.begin1. for 1 &lt;= i, j &lt;= p pardo if (A(i) &gt;= A(j)) then set B(i, j) := 1 else set B(i, j) := 02. for 1 &lt;= i &lt;= p pardo set M(i) := B(i, 1) &amp; B(i, 2) &amp; ... B(i, p)end $ T = O(1); W = O(p^2) $ 双层log深度树(doubly logarithmic-depth tree): 最底层节点数 为 n，根节点的孩子节点数 为 $n^{\\frac{1}{2}}$，下一层每个节点的孩子节点数 $n^{\\frac{1}{2^2}}$，… 假设$n = 2^{2^k}$, 树根有$2^{2^{k-1}}$个孩子, 第一层有$2^{2^{k-2}}$个孩子, …, 第i层有$2^{2^{k-i-1}}$个孩子, … 倒数第二层每个节点有常数个子节点 向上合并用常数复杂度求最大值方法 整体并行复杂度: T(n) = O(log log n) W(n) = O(n log log n) accelerated cascading: start with the optimal algorithm until the size of the problem is reduced to a centain threshold value. 双层log深度树加速 Then, shift to the fast but nonoptimal algorithm. 常数时间算法层叠 对称破坏法(Symmetry Breaking) 例: 环的三色着色问题 要求: 相邻的点不能是相同的颜色 串行算法: 在环上随机选一点把环打开得到一个队列；从队首开始除队尾外以0，1相间着色，队尾着色为2(确保队尾和队首、对中倒数第二节点的颜色都不同) 并行算法大致思想: 从以节点编号为颜色的着色方案开始，通过迭代算法，逐步减少着色数量 Algorithm 2.91234567891011# Basic ColoringInput: A directed cycle whose arcs are specified by an array S of size n and a coloring c of the vertices.Output: Another coloring c' of the verteces of the cycle.beginfor 1 &lt;= i &lt;= n pardo 1. set k to the least significant bit position in which c(i) and c(S(i)) disagree. 2. set c'(i) := 2k + c(i)_kend T = O(1); W = O(n) definition: $log^{(1)}x = logx$, and $log^{(i)}x = log(log^{(i-1)}x)$ Fast Coloring反复运用这个算法使得从颜色序号{0, 1, 2}中重新选择颜色给每个顶点着色且相邻顶点色不同, 整体并行复杂度为: T = O(log*n); W = O(nlog*n) Algorithm 2.10123456789101112131415# 3-coloring of a CycleInput: A directed cycle of length n whose arcs are specified by an array S.Output: A 3-coloring of the vertices of the cycle.begin1. for 1 &lt;= i &lt;= n pardo set C(i) := i2. Apply Algorithm 2.9 once.3. Sort the vertices by their colors.4. for i = 3 to 2 \\ceiling(logn) do for all vertices v of color i pardo color v with the smallest color from &#123;0, 1, 2&#125; that is diffrrent from the colors of its two neighbors.end T = O(logn); W = O(n) 三色环着色过程 迭代调用算法2.9，把颜色降至c种以下(c是较小常数，如10等) 遍历从3到c-1种颜色:for(color = 3; color &lt; c; ++color) { 环中结点号i if i的颜色为color pardo 根据左右邻居占用3颜色0,1,2中的哪几种，决定结点i可以取得颜色({0,1,2}中的某一个) } 在1.中，设迭代t的颜色数为$nt$，则$n{t+1} \\leqslant 2(\\ulcorner log_2n_t \\urcorner - 1) + 1$","categories":[],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://chenfeng.github.io/tags/并行计算/"}]},{"title":"类设计者的核查表","slug":"Cplusplus_thinking/类设计者的核查表","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:45:07.437Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/类设计者的核查表/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/类设计者的核查表/","excerpt":"","text":"构造函数简单的类 结构就是接口 不需要构造函数 数据成员私有阻止类的使用者私自改动提供相应接口 供使用者执行修改或访问等操作 无参构造函数声明对象数组必需 初始化数据成员每个构造函数都要负责为所有的数据成员设置经过明确定义的值除非该数据成员在类的对象存在一定时间后才有意义或其它特殊情况 析构函数该类分配了不会被成员函数自动释放的资源（动态内存）时必需 虚析构函数(类B派生的子类D，若可能对D类型对象的B*指针执行delete表达式时必需)例如:123456789101112class B &#123; string s;&#125;;class D : public B &#123; string t; // virtual ~B() &#123;&#125;;&#125;;int main() &#123; B* bp = new D; // no problem delete bp; // unless B has a virtual destructor // or the wrong dstructor would be called&#125; 拷贝构造函数当复制类的对象并非复制其数据成员和基类对象时必需 若不想使用者能够复制类的对象，就声明复制构造函数(赋值操作符)为私有的 赋值操作符当赋值类的对象并非复制其数据成员和基类对象时必需 考虑赋值给对象本身的情况例如: 1234567891011121314class String &#123;public: string&amp; operator=(const String &amp;s);private: char *data;&#125;;String&amp; String::operator=(const String&amp; s) &#123; if (&amp;s != this) &#123; // do nothing with self-assignment delete [] data; // delete old array data = new char[strlen(s.data) + 1]; strcpy(data, s.data); &#125; return *this;&#125; 若不想使用者能够设置类中的对象，就将赋值操作符私有化 析构函数、拷贝构造函数、赋值操作符= 通常为同时必需的 关系操作符类逻辑上支持相等操作则提供 operator== 和 operator!=类具有某种排序关系则提供余下的关系操作符(&lt; &gt; &lt;= &gt;=) 拷贝构造函数和赋值操作符的参数类型加上constlike X::X(const X&amp;) X::operator=(const X&amp;) 函数的const引用参数除非函数用来改变参数的值否则应为const引用例如: Complex operator+(const Complex&amp; x, const Complex&amp; y); 适当声明成员函数为const成员函数不用修改它的对象时 const对象只能使用声明为const的函数 设计理念：C++不可能自动处理所有这些事情(难以保证做得对)始终加入的话增加太多的额外负担，开销过大如给所有类自动添加一个虚析构函数，当类较小时开销明显作为变通方法，让编译器指出什么时候类该有什么必需的","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"面向对象编程","slug":"Cplusplus_thinking/面向对象编程","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:45:56.989Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/面向对象编程/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/面向对象编程/","excerpt":"一个面向对象程序范例 面向对象对象编程三要素： 数据抽象 继承 动态绑定 适用于大型程序 以算术表达式树形表示的面向对象解决方案为例","text":"一个面向对象程序范例 面向对象对象编程三要素： 数据抽象 继承 动态绑定 适用于大型程序 以算术表达式树形表示的面向对象解决方案为例 创建和打印表达式 定义表达式树节点类每个节点可能有一到三个子节点，可用一个联合加上一个指示节点类型的专门字段表示节点 三种节点： 包含一个整数值，无子节点 包含一个操作符，一个子节点 包含一个操作符，两个子节点 当需要用到一个类型字段时可以考虑定义一系列类并用继承组织起来能否更有效 用一个类表示“节点”概念 12345678910111213class Expr_node &#123; // print the expression friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr_node&amp;);protected: virtual void print(ostream&amp;) const = 0; virtual ~Expr_node() &#123;&#125;&#125;;ostream&amp; operator&lt;&lt;(ostream&amp; o, const Expr_node&amp; e) &#123; e.print(o); return o;&#125; 用继承声明具体类型 12345678910111213141516171819202122232425262728293031323334353637// save first node-typeclass Int_node: public Expr_node &#123; friend class Expr; int n; Int_node(int k): n(k) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; n &#125;;&#125;;// svae second typeclass Unary_node: public Expr_node &#123; friend class Expr; string op; Expr_node* opnd; Unary_node(const string&amp; a, Expr_node* b): op(a), opnd(b) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; op &lt;&lt; *opnd &lt;&lt; \")\"; &#125;&#125;;// save third typeclass Binary_node: public Expr_node &#123; friend class Expr; string op; Expr_node* left; Expr_node* right; Binary_node(const string&amp; a, Expr_node* b, Expr_node* c): op(a), left(b), right(c) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; *left &lt;&lt; op &lt;&lt; *right &lt;&lt; \")\"; &#125;&#125;; 用句柄类管理指针避免使用者管理内存的麻烦使用者关心的只是树和子树而非单个节点，定义句柄类Expr隐藏Expr_node继承层次 12345678910111213141516171819202122232425class Expr &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); Expr_node* p;public: Expr(int); Expr(const string&amp;, Expr); Expr(const string&amp;, Expr, Expr); Expr(const Expr&amp;); Expr&amp; operator=(const Expr&amp;); ~Expr() &#123; delete p; &#125;&#125;;Expr::Expr(int n) &#123; p = new Int_node(n);&#125;Expr::Expr(const string&amp; op, Expr t) &#123; p = new Unary_node(op, t);&#125;Expr::Expr(const string&amp; op, Expr left, Expr right) &#123; p = new Binary_node(op, left, right);&#125; 改进 可在Expr_node派生层次加入虚函数copy 加入引用计数避免复制下层Expr_node会更有效率123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687class Expr_node &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); friend class Expr; // add a use count int use;protected: Expr_node(): use(1) &#123;&#125; virtual void print(ostream&amp;) const = 0; virtual ~Expr_node() &#123;&#125;&#125;;class Expr &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); Expr_node* p;public: Expr(int n) &#123; p = new Int_node(n); &#125; Expr(const string&amp; op, Expr t) &#123; p = new Unary_node(op, t); &#125; Expr(const string&amp; op, Expr left, Expr right) &#123; p = new Binary_node(op, left, right); &#125; Expr(const Expr&amp; t) &#123; p = t.p; ++p-&gt;use; &#125; ~Expr() &#123; if (--p-&gt;use == 0) delete p; &#125; Expr&amp; operator=(const Expr&amp;);&#125;;// assignment operator increase use count of the right objectExpr&amp; Expr::operator=(const Expr&amp; rhs) &#123; rhs.p-&gt;use++; if (--p-&gt;use == 0) delete p; p = rhs.p; return *this;&#125;ostream&amp; operator&lt;&lt;(ostream&amp; o, const Expr&amp; t) &#123; t.p-&gt;print(o); return o;&#125;// save first typeclass Int_node: public Expr_node &#123; friend class Expr; int n; Int_node(int k): n(k) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; n &#125;;&#125;;// svae second typeclass Unary_node: public Expr_node &#123; friend class Expr; string op; Expr opnd; Unary_node(const string&amp; a, Expr b): op(a), opnd(b) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; op &lt;&lt; opnd &lt;&lt; \")\"; &#125;&#125;;// save third typeclass Binary_node: public Expr_node &#123; friend class Expr; string op; Expr left; Expr right; Binary_node(const string&amp; a, Expr b, Expr c): op(a), left(b), right(c) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; left &lt;&lt; op &lt;&lt; right &lt;&lt; \")\"; &#125;&#125;; 扩展新操作：表达式求值方法和打印表达式相同 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107class Expr_node &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); friend class Expr; int use;protected: Expr_node(): use(1) &#123;&#125; virtual void print(ostream&amp;) const = 0; virtual ~Expr_node() &#123;&#125; // add a pure virtual function virtual int eval() const = 0;&#125;;class Expr &#123; friend class Expr_node; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); Expr_node* p;public: Expr(int n) &#123; p = new Int_node(n); &#125; Expr(const string&amp; op, Expr t) &#123; p = new Unary_node(op, t); &#125; Expr(const string&amp; op, Expr left, Expr right) &#123; p = new Binary_node(op, left, right); &#125; Expr(const Expr&amp; t) &#123; p = t.p; ++p-&gt;use; &#125; ~Expr() &#123; if (--p-&gt;use == 0) delete p; &#125; Expr&amp; operator=(const Expr&amp; t); // new function: calculate the evaluation int eval() const &#123; return p-&gt;eval(); &#125;&#125;;// save first typeclass Int_node: public Expr_node &#123; friend class Expr; int n; Int_node(int k): n(k) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; n &#125;; // new function int eval() const &#123; return n; &#125;&#125;;// svae second typeclass Unary_node: public Expr_node &#123; friend class Expr; string op; Expr opnd; Unary_node(const string&amp; a, Expr b): op(a), opnd(b) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; op &lt;&lt; opnd &lt;&lt; \")\"; &#125; // new function int eval() const;&#125;;int Unary_node::eval() const &#123; // only consider certain operands if (op == \"-\") return -opnd.eval(); throw \"error, bad op \" + op + \" int UnaryNode\";&#125;// save third typeclass Binary_node: public Expr_node &#123; friend class Expr; string op; Expr left; Expr right; Binary_node(const string&amp; a, Expr b, Expr c): op(a), left(b), right(c) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; left &lt;&lt; op &lt;&lt; right &lt;&lt; \")\"; &#125; // new function int eval() const;&#125;;int Binary_node::eval() const &#123; int op1 = left.eval(); int op2 = right.eval(); if (op == \"-\") return op1 - op2; if (op == \"+\") return op1 + op2; if (op == \"*\") return op1 * op2; if (op == \"/\" &amp;&amp; op2 != 0) return op1 / op2; throw \"error, bad op \" + op + \"in BinaryNode\";&#125; 类的抽象对算术表达式进行了精确建模 扩展程序以计算表达式所需要增加的代码较少 扩展增加新节点类型如增加Ternary_node表示三元操作符(?:) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Ternary_node: public Expr_node &#123; friend class Expr; string op; Expr left; Expr middle; Expr right; Ternary_node(const string&amp; a, Expr b, Expr c, Expr d): op(a), left(b), middle(c), right(d) &#123;&#125; void print(ostream&amp; o) const &#123; o &lt;&lt; \"(\" &lt;&lt; left &lt;&lt; \" ? \" &lt;&lt; middle &lt;&lt; \" : \" &lt;&lt; right &lt;&lt; \")\"; &#125; // new function int eval() const;&#125;;int Ternary_node::eval() const &#123; if (left.eval()) return middle.eval(); else return right.eval();&#125;// add a constructor for Ternary_node in Exprclass Expr &#123; friend class Expr_node; friend ostream&amp; operator&lt;&lt;(ostream&amp;, const Expr&amp;); Expr_node* p;public: Expr(int n) &#123; p = new Int_node(n); &#125; Expr(const string&amp; op, Expr t) &#123; p = new Unary_node(op, t); &#125; Expr(const string&amp; op, Expr left, Expr right) &#123; p = new Binary_node(op, left, right); &#125; Expr(const string* op, Expr left, Expr middle, Expr right) &#123; p = new Ternary_node(op, left, middle, right); &#125; Expr(const Expr&amp; t) &#123; p = t.p; ++p-&gt;use; &#125; ~Expr() &#123; if (--p-&gt;use == 0) delete p; &#125; Expr&amp; operator=(const Expr&amp; t); // new function: calculate the evaluation int eval() const &#123; return p-&gt;eval(); &#125;&#125;; 总结面向对象编程能简化程序的设计和更新过程 对下层系统中的对象进行建模 保证修改时耦合度低","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"不应当使用虚函数的情况","slug":"Cplusplus_thinking/不应当使用虚函数的情况","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:49:01.667Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/不应当使用虚函数的情况/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/不应当使用虚函数的情况/","excerpt":"关于是否应该所有成员函数缺省为虚函数的争论 只有涉及继承时，才需要考虑与此相关的问题 适用的情况 基类派生出的子类需要重写(or 覆盖，override)，基类中相应的成员和函数应声明为虚函数 不适用的情况 虚函数代价并不是非常高，当时会带来一定的额外开销 有些情况下非虚函数能够正确运行而虚函数不能 有些类并非为继承而设计(设计时并不兼容被继承)","text":"关于是否应该所有成员函数缺省为虚函数的争论 只有涉及继承时，才需要考虑与此相关的问题 适用的情况 基类派生出的子类需要重写(or 覆盖，override)，基类中相应的成员和函数应声明为虚函数 不适用的情况 虚函数代价并不是非常高，当时会带来一定的额外开销 有些情况下非虚函数能够正确运行而虚函数不能 有些类并非为继承而设计(设计时并不兼容被继承) 效率程序调用显式提供的对象的虚拟成员函数，优秀的编译器不带来额外的开销(与调用非虚函数相同)如：12T x;x.f(); 在这里，f是否虚函数应该没有影响；产生对T::f的直接调用 若所有对成员函数的调用都是通过显式指定的对象进行的则成员函数是否是虚函数就无关紧要了 一旦通过指针或引用进行调用就是有意义的 虚函数会产生额外的开销 用内存引用(memory reference)计数衡量大概的开销 随着微处理器的速度越来越快，内存应用耗时占比会越高，此项指标更精确；但高速缓存的更广泛更大量的使用也使得这项粗糙的估计更不准确；但在这儿这样估计是必要的。 如：12345int&amp; IntArray::operator[](unsigned n) &#123; if (n &gt;= arraysize) throw \"subscript out of range\"; return data[n];&#125; 设函数为内联函数，好的实现在直接通过对象使用operator[]时不引入新开销 通过指针或引用调用operator[]的开销与三个内存引用相关: 对指针本身 为此成员函数初始化this指针 用于调用返回序列 调用虚函数则通常需要多出另外的三个内存应用: 从对象取出描述对象类型的表的地址值 取出虚函数的地址 在可能的较大外围对象中，取出本对象的偏移量 成员函数很大时，这样的开销远小于函数执行所需开销，额外的开销不成问题 一个潜在开销很大的例子及改进策略：1234567891011121314151617181920212223242526272829303132333435363738class InputBuffer &#123;public: //... virtual int get(); //...&#125;;// all derived class of InputBuffer can override get()int countlines(InputBuffer&amp; b) &#123; int n = 0; int c; // get() would be called a lot of times while ((c = b.get()) != EOF) &#123; if (c == '\\n') ++n; &#125; return n;&#125;// imroved versionclass InputBuffer &#123;public: //... int get() &#123; // call a virtual function only in specified condition if (next &gt;= limit) return refill(); return *next++; &#125;protected: // read in plenty of characters virtual int refill();private: char* next; char* limit;&#125;; 行为当派生类并不严格扩展基类行为时，成员函数定义为虚函数会导致不正确的结果 123456789101112131415161718192021222324class IntArray &#123;public: IntArray(unsigned); int&amp; operator[] (unsigned); unsigned size() const; //...&#125;;class IntBlock: public Int Array &#123;public: IntBlock(int l, int h): low(l), high(h), IntArray(l &gt; h ? 0 : h - l + 1) &#123;&#125; int&amp; operator[](int n) &#123; return IntArray::operator[](n - low); &#125;private: int low, high;&#125;;int sum(IntArray&amp; x) &#123; int result = 0; for (int i = 0; i &lt; x.size(); ++i) result += x[i]; return result;&#125; 当将一个实际类型为IntBlock的对象传给sum()时，只有operator[]为非虚函数才有正确的行为 有些函数只为特定有限制的用途而设计 类的接口可以有两种用户：使用该类对象的人和从这个类派生新类的人 有的类会故意不考虑其他人如何通过继承改变它的行为 虚析构函数 有需要自定义的析构函数 存在此种情形：指向基类的指针或引用都有其静态类型，并实际上都指向派生类的对象","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"句柄类(handle)","slug":"Cplusplus_thinking/句柄类(handle)","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:47:41.789Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/句柄类(handle)/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/句柄类(handle)/","excerpt":"创建代理会复制所代理的对象，如何避免复制(保持多态性的前提下避免复制对象的代价) 某些类应当避免复制： 对象很大，资源消耗多 每个对象代表一种不能被轻易复制的资源，如文件 其它数据结构已经存储对象的地址，把副本地址插入那些数据结构中代价会非常大 对象代表位于网络连接另一端的其他对象 多态性环境中只知对象基类类型而不知对象本身类型","text":"创建代理会复制所代理的对象，如何避免复制(保持多态性的前提下避免复制对象的代价) 某些类应当避免复制： 对象很大，资源消耗多 每个对象代表一种不能被轻易复制的资源，如文件 其它数据结构已经存储对象的地址，把副本地址插入那些数据结构中代价会非常大 对象代表位于网络连接另一端的其他对象 多态性环境中只知对象基类类型而不知对象本身类型 避免使用指针复制对象： 使用对象指针比直接使用对象要困难 未初始化的指针非常危险且难以防范 管理内存的硬件总要检查被复制的指针是否真的指向程序所分配的内存位置上 复制未初始化指的针会导致硬件陷阱例如: 123456void f() &#123; // copy a pointer without initialization // would crash a program int* p; // without initialization int* q = p; // not being definited&#125; 多个指针指向同一个对象时应考虑何时删除此对象 handle classe(句柄类) 有时也称为smart pointer(智能指针) 绑定到所控制的类的对象上 简单示例类表示点平面坐标的类123456789class Point &#123;public: Point(): xval(0), yval(0) &#123;&#125; Point(int x, int y): xval(x), yval(y) &#123;&#125; int x() const &#123; return xval; &#125; int y() const &#123; return yval; &#125; Point&amp; x(int xv) &#123; xval = xv; return *this; &#125; Point&amp; y(int yv) &#123; yval = yv; return *this; &#125;&#125;; 使用一个无参构造函数和一个两个参数的构造函数而非一个缺省参数的构造函数Point(int x = 0, int y = 0): xval(x), yval(y) {}后者允许只用一个参数(另一个缺省为零)构造Point对象，而这几乎是错的 绑定到句柄将句柄h直接绑定到对象上Point p;Handle h(p); 删除p后应该使handle无效 handle应该控制它所绑定的对象(创建和销毁) 从效果上说handle就是一种只包含单个对象的容器 获取对象 handle行为上类似一个指针 应阻止使用者直接获得对象的实际地址 过多暴露内存分配策略，不利于改变分配的策略 隐蔽真正的对象地址，避免直接重载 operator-&gt;1234567class Handle &#123;public: Point* operator-&gt;(); // ...&#125;;Point* addr = h.operator-&gt;(); // get the object address // overloading operator-&gt; is to blame 引用计数型句柄(UPoint) 了解有多少句柄绑定在同一个对象上以确定何时删除对象 引用计数(use count)不能是句柄的一部分或对象的一部分 定义新的类容纳引用计数和Point对象 12345678910class UPoint &#123; // all the members are private friend class Handle; Point p; int u; UPoint(): u(1) &#123;&#125; UPoint(int x, int y): P(x, y), u(1) &#123;&#125; UPoint(const Point&amp; p0): p(p0), u(1) &#123;&#125;&#125;; 一个简单的Handle类实现 123456789101112131415161718192021222324252627282930313233343536373839404142class Handle &#123;public: Handle(); Handle(int, int); Handle(const Point&amp;); Handle(const Handle&amp;); Handle&amp; operator=(const Handle&amp;); ~Handle(); int x() const; int y() const; Handle&amp; x(int); Handle&amp; y(int);private: Upoint * up;&#125;;Handle::Handle(): up(new UPoint) &#123;&#125;Handle::Handle(int x, int y): up(new UPoint(x, y)) &#123;&#125;Handle::Handle(const Point&amp; p): up(new UPoint(p)) &#123;&#125;Handle::~Handle() &#123; if (--up-&gt;u == 0) delete up;&#125;// just increase the use count by 1Handle::Handle(const Handle&amp; h): up(h.up) &#123; ++up-&gt;up; &#125;// make sure it works when two handles use the same UPoint objectHandle&amp; Handle::operator=(const Handle&amp; h) &#123; ++h.up-&gt;u; if (--up-&gt;u == 0) delete up; up = h.up; return *this;&#125;int Handle::x() const &#123; return up-&gt;p.x(); &#125;int Handle::y() const &#123; return up-&gt;p.y(); &#125; 写时复制(copy on write)handle改动性函数两种不同语义Handle h(3, 4);Handle h2 = h;h2.x(5);int n = h.x(); // 3 or 5 ? 句柄为指针语义，n = 5 handle表现像指针或引用，h和h2绑定到同一对象 12345678Handle&amp; Handle::x(int x0) &#123; up-&gt;p.x(x0); return *this;&#125;Handle&amp; Handle::y(int y0) &#123; up-&gt;p.y(y0); return *this;&#125; 句柄为值语义，n = 3 改变h2的内容不该影响h的值 必须保证所改动的UPont对象不同时被其它Handle所引用，否则复制UPoint12345678910111213141516Handle&amp; Handle::x(int x0) &#123; if (up-&gt;u != 1) &#123; --up-&gt;u; up = new UPoint(up-&gt;p); &#125; up-&gt;p.x(x0); return *this;&#125;Handle&amp; Handle::y(int y0) &#123; if (up-&gt;u != 1) &#123; --up-&gt;u; up = new UPoint(up-&gt;p); &#125; up-&gt;p.y(y0); return *this;&#125; if (up-&gt;u != 1) {--up-&gt;u;up = new UPoint(up-&gt;p);} 此代码片段需要在每个改变UPoint对象的成员函数中重复(可设计为Handle的私有成员函数) 写时复制优点：在绝对必要时才进行复制，额外开销小 句柄类的改进 前述实现的缺点：把句柄捆绑到类T的对象上必须先定义具有类型T的成员的新类 当捆绑句柄到继承自T的静态类型未知的类的对象上时难以实现 将应用计数从数据中分离出来作为独立的对象 抽象地表示应用计数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class UseCount &#123;public: UseCount(); UseCount(const UseCount&amp;); ~UseCount(); // judge whether use count would become zero bool only(); // judge whether use count should be deleted bool reattach(const UseCount&amp;); // provide a method to make this handle to be the only one bool makeonly();private: int* p; // make assignment illegal UseCount&amp; operator=(const UseCount&amp;);&#125;;UseCount::UseCount(): p(new int(1)) &#123;&#125;UseCount::UseCount(const UseCount&amp; u): p(u.p) &#123; ++*p; &#125;UseCount::~UseCount() &#123; if (--*p == 0) delete p;&#125;bool UseCount::only() &#123; return *p == 1; &#125;bool UseCount::reattach(const UseCount&amp; u) &#123; // increase u.p first to make it work when self-assignment ++*u.p; if (--*p == 0) &#123; delete p; p = u.p; return true; &#125; p = u.p; return false;&#125;bool UseCount::makeonly() &#123; if (*p == 1) return false; --*p; p = new int(1); return true;&#125; 重写Handle类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Handle &#123;public: // the same with previous definition Handle(); Handle(int, int); Handle(const Point&amp;); Handle(const Handle&amp;); Handle&amp; operator=(const Handle&amp;); ~Handle(); int x() const; int y() const; Handle&amp; x(int); Handle&amp; y(int);private: Point* p; UseCount u;&#125;;Handle::Handle(): p(new Point) &#123;&#125;Handle::Handle(int x, int y): p(new Point(x, y)) &#123;&#125;Handle::Handle(const Point&amp; p0): p(new Point(p0)) &#123;&#125;Handle::Handle(const Handle&amp; h): u(h.u), p(h.p) &#123;&#125;Handle::~Handle() &#123; if (u.only()) delete p;&#125;Handle&amp; Handle::operator=(const Handle&amp; h) &#123; if (u.reattach(h.u)) delete p; p = h.p; return *this;&#125;int Handle::x() const () &#123; return p-&gt;x();&#125;int Handle::y() const () &#123; return p-&gt;y();&#125;Handle&amp; Handle::x(int x0) &#123; if (u.makeonly()) p = new Point(*P); p-&gt;x(x0); return *this;&#125;Handle&amp; Handle::y(int y0) &#123; if (u.makeonly()) p = new Point(*P); p-&gt;y(y0); return *this;&#125; 总结 通过引入引用计数使得handle类能灵活地设计出来，而将引用计数抽象化表示使handle类能协同不同数据结构工作 UseCount类简化了实现中特定的子问题：接口设计只为简化引用计算句柄实现，而不为终端用户(end user)所用","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"模板（一）","slug":"Cplusplus_thinking/模板（一）","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:48:36.204Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/模板（一）/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/模板（一）/","excerpt":"容器类设计容器：保存值的集合的数据结构 语言内建容器：数组、结构体 C++没有提供更多的内建容器：不将容器的设计限定到某种单一的方法上(可能不存在唯一正确的方法) 容器包含对象 复制容器意味复制存储在容器中的值(而不是容器本身) 函数传参数方式 void f(const Container&amp;)避免大对象的复制 区分读和写 operator[]只用于取数 用成员函数update(i, x)修改索引为i的元素为x","text":"容器类设计容器：保存值的集合的数据结构 语言内建容器：数组、结构体 C++没有提供更多的内建容器：不将容器的设计限定到某种单一的方法上(可能不存在唯一正确的方法) 容器包含对象 复制容器意味复制存储在容器中的值(而不是容器本身) 函数传参数方式 void f(const Container&amp;)避免大对象的复制 区分读和写 operator[]只用于取数 用成员函数update(i, x)修改索引为i的元素为x 1234567891011121314151617template &lt;class T&gt; class Container &#123; // ...public: T operator[](Index) const; void update(Index, const T&amp;); // ...&#125;;Container&lt; Container&lt;int&gt; &gt;c;Index i, j;int k = c[i][j];// only way to modify the element in Container// c[i][j]void update(Index, const T&amp;);void update(Index, Index, const T&amp;);// hard to deal with much more dimension// c[i] return type T instead of T&amp;// c[i].update(j, new_value) does not work 获取容器的元素严格分清类型T(作右值)和类型T&amp;(作左值) 容器增长：按区块(chunk)增加容器大小的分配策略 容器操作容器数组：必须有缺省构造函数“顺序地”遍历容器中所有元素：先给元素强制规定顺序(解决方案：迭代器(iterator)) 容器元素的类型 类型为T的元素可以进行行为正确的复制、赋值和销毁T::T(const T&amp;) 可以判定两个元素是否相等operator==(const T&amp;, cosnt T&amp;) 为增加性能，有关于偏序关系或全序关系的定义(如set)operator&lt;(const T&amp;, const T&amp;) 考虑是否重载operator&lt;&lt;(ostream&amp;, const Container&amp;)兼顾不使用标准输入输出操作库或不用输入输出操作的用户，提供遍历整个容器的机制 容器不可通过继承关联起来1234567// if Container&lt;Airplane&gt; is derived from Container&lt;Vehicle&gt;Vehicle v;Container&lt;Airplane&gt; ca;Container&lt;Vehicle&gt;&amp; vp = ca;vp.insert(v);// that does not make any sence Demo : an array-like class 使用指针和使用下标的差别 12345678910111213// by indexint i;for (i = 0; i &lt; N; ++i) f(x[i]);// by pointerT* p;for (p = x; p &lt; x + N; ++p) f(*p);// a simplified versionT* p;while (p &lt; x + N) f(*p++); 区别： 下标值本身就有意义，与是否用作下标无关：通过下标进行元素访问的程序要另外知道正在使用的数组(才能访问整个数组) 要访问容器的元素没必要知道容器的标识，指针本身就包含所有的必要信息：程序只要拥有拥有一个指向数组元素的指针就能访问整个数组 这些影响设计，比”下标易于理解，指针效率高”的区别更为重要 禁止(数组)复制和赋值 使用operator[]存取元素 关于扩展：定长 缺省构造函数：可以创建包含数组的数组 123456789101112131415161718192021222324252627282930313233template&lt;class T&gt;class Array &#123;public: Array(): data(0), sz(0) &#123;&#125; Array(unsigned size): sz(size), data(new T(size)) &#123;&#125; ~Array() &#123; delete [] data; &#125; const T&amp; operator[](unsigned n) const &#123; if (n &gt;= sz || data == 0) throw \"Array subscript out of range\"; return data[n]; &#125; T&amp; operator[](unsigned n) &#123; if (n &gt;= sz || data == 0) throw \"Array subscript out of range\"; return data[n]; &#125; operator const T*() const &#123; return data; &#125; operator T*() &#123; return data; &#125;private: T* data; unsigned sz; Array(const Array* a); Array&amp; operator=(const Array&amp;);&#125;; 缺陷 (也存在于内建数组中)包含元素的Array消失后，它的元素地址还在 12345678void f() &#123; int *p; &#123; Array&lt;int&gt; x(20); p = &amp;x[10]; &#125; cout &lt;&lt; *p; // no exist&#125; 允许用户访问它的元素地址，透露太多内部运作的信息，违背了封装理念 允许Array被构造后改变长度会导致旧指针失效","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"供给与需求的基本原理","slug":"economics/供给与需求的基本原理","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:52:01.314Z","comments":true,"path":"2017/01/21/economics/供给与需求的基本原理/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/economics/供给与需求的基本原理/","excerpt":"需求表 在其他条件相同时，一种物品的价格越高，人们愿意购买的数量就越少；而市场价格越低，人们愿意购买的数量就越多 价格与需求之间的关系可以用一张需求表(demand schedule)或一条需求曲线(demand curve)表示 需求曲线：数量和价格呈反比关系","text":"需求表 在其他条件相同时，一种物品的价格越高，人们愿意购买的数量就越少；而市场价格越低，人们愿意购买的数量就越多 价格与需求之间的关系可以用一张需求表(demand schedule)或一条需求曲线(demand curve)表示 需求曲线：数量和价格呈反比关系 需求向下倾斜规律(law of downward-sloping demand): 当一种商品的价格上升时(同时其他条件保持不变)，购买者便会趋向于购买更少的数量；当价格下降、其他条件保持不变时，需求量会增加 替代效应(substitution effect): 当一种物品的价格上升时，人们会用其他类似的物品替代它 收入效应(income effect): 当价格上升时，人们会发现自己比以前穷了一些 市场需求 市场需求曲线是将在每一价格水平下所有个人的需求量加总而得到的 市场需求曲线符合需求向下倾斜规律 需求曲线背后的因素 消费者的平均收入是需求的重要决定因素。个人收入上升，即使价格不变，人们也会倾向于购买更多数量的几乎任何物品。 市场规模(用人口衡量)影响市场需求曲线 相关物品的价格及其可获得性会影响对该物品的需求，尤其是替代品之间存在着重要的联系 爱好或偏好的主观因素。代表文化、历史因素，反映心理、生理需要或人为造成的需要或者传统、宗教的因素 其他特殊的因素 需求的移动：除物品价格以外的其他因素(非价格变量)发生了变化 需求变动：商品价格之外的因素变化引起购买数量发生变化 需求增加，需求曲线向右移动，每一价格水平人们会购买更多物品 需求减少，需求曲线向左移动，每一价格水平人们会购买更少物品 供给表 一种商品的供给表(supply schedule)或供给曲线(supply curve)体现在其它条件下，该商品的市场价格与生产者愿意生产和销售的数量之间的关系 应当保持不变的条件包括生产成本、相关物品的价格和政府政策 供给曲线 供给曲线向上倾斜的重要原因之一是边际收益递减规律：每一个新增加的劳动(要素)所增添的数量是递减的 供给曲线背后的因素 一个关键因素是生产成本 生产成本主要取决于投入品(劳动、能源或机器等)价格和技术进步(降低生产同量产出所需的投入品数量的变化)(从应用科学突破到现有技术的更新与挖潜、生产流程的重新组织) 供给受相关物品价格的影响 一种替代品的价格上升，另一种替代品的供给就会下降 政府政策会对供给曲线产生重大影响 特殊因素(气候条件之类)也会影响供给曲线 供给的移动：价格之外的其他因素发生变动而引起供给数量发生变动 在市场的每一价格水平，当供给的数量都增加(或减少)时，供给增加(或减少) 供给和需求的平衡 市场均衡(market equilibrium)：供给和需求的力量相互作用，产生均衡的价格和均衡的数量。 在该点买者所愿意购买的数量正好等于卖者所愿意出售的数量。 当供求力量平衡时，只要其他条件保持不变，价格就没有理由继续波动 市场出清价格(market-clearing price)：需求量与供给量相等的价格水平(均衡价格) 供给曲线与需求曲线的均衡 均衡价格与均衡数量发生在愿意供给的数量等于愿意购买的数量的水平上 在竞争市场上，均衡发生在供给曲线与需求曲线的交点 在均衡价格水平上，市场上不存在短缺或过剩 供给或需求的移动对均衡的影响 当影响需求或供给的诸因素发生变化时就会导致需求或供给发生变动，并引起市场上的均衡价格和均衡数量也发生变动 解释价格和数量的变动：供给变化或需求变化；需求变化或沿着需求曲线移动 供给、需求和移民：移民对于当地劳工市场影响微弱;人口流动性强，新移民流向最可能找到工作的城市，迁入城市对劳工需求已经上升;移民迁入，当地居民迁出，劳动总供给实际上没变动 通过价格进行分配 用钱包进行配给(rationing by the purse)：市场通过供求的相互作用决定所有投入和产出的均衡价格和均衡数量，将社会的稀缺品配置或配给到各种用途中","categories":[],"tags":[{"name":"微观经济学","slug":"微观经济学","permalink":"https://chenfeng.github.io/tags/微观经济学/"}]},{"title":"代理类","slug":"Cplusplus_thinking/代理类","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:49:04.379Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/代理类/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/代理类/","excerpt":"如何设计C++容器，能够包含类型不同而彼此相关的对象如何将继承自同一父类的属于不同子类的对象装入同一个容器（如vector）之中？(将容器和继承运用在一起) 代理 surrogate允许将整个派生层次压缩在一个对象类型中 surrogate是handle(句柄)类中最简单的一种","text":"如何设计C++容器，能够包含类型不同而彼此相关的对象如何将继承自同一父类的属于不同子类的对象装入同一个容器（如vector）之中？(将容器和继承运用在一起) 代理 surrogate允许将整个派生层次压缩在一个对象类型中 surrogate是handle(句柄)类中最简单的一种 一个表示不同交通工具的类派生层次1234567891011class Vehicle &#123;public: virtual double weight() const = 0; virtual void start() = 0; // pure virtual function // ...&#125;class RoadVehicle: public Vehicle &#123;/*...*/&#125;class AutoVehicle: public Vehicle &#123;/*...*/&#125;class Aircraft : public Vehicle &#123;/*...*/&#125;class Helicopter : public Vehicle &#123;/*...*/&#125; 一个容器123Vehicle parking_lot[1000]; // errorAutoVehicle x;parking_lot[num_vehicles++] = x; Vehicle是虚基类，不能实例化 子类对象转化为父类对象会丢失父类中没有的成员 parking_lot是Vehicle的集合而不是所有继承自Vehicle的对象的集合 间接层 indirection存储指针替代存储对象本身123Vehicle* parking_lot[1000];AutoVehicle x;parking_lot[num_vehicles++] = &amp;x; x是局部变量，释放之后parking_pot指向未知 存储副本的指针而非原对象的指针 12AutoVehicle x;parking_lot[num_vehicles++] = new AutoVehicle(x); 带来动态内存管理的负担 必须知道要放入parking_lot中的对象的静态类型1234if (p != q) &#123; delete parking_pot[p]; parking_pot[p] = new Vehicle(parking_pot[q]);&#125; // virtual base class has no instance 虚复制函数在Vehicle中增加合适的纯虚函数来复制编译时类型未知的对象12345678class Vehicle &#123;public: virtual double weight() const = 0; virtual void start() = 0; virtual Vehicle* copy() const = 0; virtual ~Vehicle() &#123;&#125; // virtual destructor // ...&#125; 在Vehicle的所有派生类中添加成员函数copy，若vp指向Vehicle不确定的子类的对象，vp-&gt;copy()返回指向该对象新建副本的指针。例如：123Vehicle* Trunk::copy() const &#123; return new Truck(*this);&#125; 定义代理类 用类表示概念避免显示处理内存分配且能保持父类在运行时绑定的属性 定义一个行为与Vehicle对象相似而又潜在地表示所有继承自Vehicle对象的东西 —— 代理（surrogate） 1234567891011121314class VehicleSurrogate &#123;public: VehicleSurrogate(); VehicleSurrogate(const Vehicle&amp;); ~VehicleSurrogate(); VehicleSurrogate(const VehicleSurrogate&amp;); VehicleSurrogate&amp; operator=(const VehicleSurrogate&amp;); // object fuctions of Vehicle double weight() const; void start(); // ...private: Vehicle* vp;&#125; 空代理(empty surrogate)的行为类似于空指针123456789101112131415161718192021222324252627282930VehicleSurrogate::VehicleSurrogate(): vp(0) &#123;&#125; // empty surrogateVehicleSurrogate::VehicleSurrogate(const Vehicle&amp; v): vp(v.copy()) &#123;&#125;VehicleSurrogate::~VehicleSurrogate() &#123; delete vp;&#125;VehicleSurrogate::VehicleSurrogate(const VehicleSurrogate&amp; v): vp(v.vp ? v.vp-&gt;copy() : 0) &#123;&#125;VehicleSurrogate&amp; VehicleSurrogate::operator=(const VehicleSurrogate&amp; v) &#123; if (this != &amp;v) &#123; delete vp; vp = (v.vp ? v.vp-&gt;copy() : 0); &#125; return *this;&#125;// call the corresponding object functionsdouble VehicleSurrogate::weight() const &#123; if (vp == 0) throw \"empty VehicleSurrogate.weight()\"; return vp-&gt;weight();&#125;void VehicleSurrogate::start() &#123; if (vp == 0) throw \"empty VehicleSurrogate.start()\"; vp-&gt;start();&#125; tip: 每次对copy的调用都是一个虚拟调用。类Vehicle的对象并不存在 赋值构造函数和赋值操作符中v.vp非零的检测是必需的 赋值操作符确保没有将代理赋值给自身 总结最开始的parking_pot容器可设计为：123VehicleSurrogate parking_lot[1000];Automobile x;parking_pot[num_vehicles++] = x; 将继承和容器共用需要处理两个问题： 控制内存分配 把不同类型的对象放进同一个容器中 采用基础C++技术，在现有的继承层次上加上一层抽象，合适地解决了这些问题。","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"宏观经济现象鸟瞰","slug":"economics/宏观经济现象鸟瞰","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T04:12:28.225Z","comments":true,"path":"2017/01/21/economics/宏观经济现象鸟瞰/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/economics/宏观经济现象鸟瞰/","excerpt":"三个重要的宏观经济变量 实际国内生产总值(real GDP):经济体内所有人的实际总收入。人均国内生产总值(GDP per capita): 经济体内平均而言每个人的实际收入。 通货膨胀率(inflation rate):物价水平变动的百分比。(物价指数)用消费者价格指数(consumer price index, CPI)或GDP缩减指数(GDP deflator index)衡量。 失业率(unemployment rate):经济体中没有工作当正在积极找工作的劳动力比重。","text":"三个重要的宏观经济变量 实际国内生产总值(real GDP):经济体内所有人的实际总收入。人均国内生产总值(GDP per capita): 经济体内平均而言每个人的实际收入。 通货膨胀率(inflation rate):物价水平变动的百分比。(物价指数)用消费者价格指数(consumer price index, CPI)或GDP缩减指数(GDP deflator index)衡量。 失业率(unemployment rate):经济体中没有工作当正在积极找工作的劳动力比重。 GDP：衡量经济活动创造的价值经济体在既定时期内生产的所有的最终产品和服务的当期市场总值 核算GDP三种方法 生产法把GDP作为经济体里当期所生产的最终产品与服务的总值 收入法把GDP作为经济体中所有人的总收入国内顾客的购买总值=企业的总收益=工资+资本所得+中间投入品的购买最终消费=增加值=工资+资本所得(in China)增加值=劳动者报酬+生产税净额+固定资产折旧+营业盈额 支出法把GDP作为经济体里对产品与服务的总支出Y=C+I+G(GDP、消费、投资、政府购买)开放经济条件下Y=Cd+Id+Gd+EX(国内产品和服务的消费、国内产品和服务的投资、国内产品和服务的政府采购、国内产品和服务的出口)国外产品和服务的消费Cf=C-Cd国外产品和服务的投资If=I-Id国外产品和服务的政府采购Gf=G-Gd国外产品和服务的进口IM=Cf+If+Gf净出口(net export)NEX=EX-IM国民经济核算表达式Y=C+I+G+NEX 国民生产总值(gross national product,GNP)一国居民在一个既定时期内所获得的总收入GNP=GDP+来自国外的生产要素收入-对国外的生产要素支付 物价水平：衡量生活费用通货膨胀：物价水平上升 消费者价格指数(CPI)最常用的度量物价水平的指标 选定一个开始时期(基期) 选定一个典型消费者所购买的一篮子产品和服务的种类和数量 计算每一期购买同样一篮子产品和服务的支出 计算每一期的CPI(CPI=当期与基期一篮子产品和服务支出的比值) 通货膨胀率 = (CPI(后一期)-CPI(前一期))/CPI(前一期) 生产者价格指数(producer price index, PPI)度量物价水平的另一指标 典型生产者购买的一篮子产品和服务 GDP缩减指数 名义GDP(nominal GDP)：按照当期价格度量的GDP实际GDP(real GDP)：按照不变价格度量的GDP(尽可能反映经济体生产能力的变化) GDP缩减指数=名义GDP/实际GDP * 100% 名义GDP剔除通货膨胀的影响得到实际GDP 失业率：度量经济体痛苦程度就业：在一定年龄段的经济活动主体从事有报酬的活动 失业者：有劳动能力并愿意就业但找不到工作的经济活动主体 劳动力人口 = 劳动年龄(16~65)人口 - 不在劳动力(not in labor force)人口 劳动参与率 = 劳动力人口 / 劳动年龄人口 失业率 = 失业人口 / 劳动力人口 测算失业人口两种方法 收集失业者在劳动行政部门申报的数据大多数失业者有申报动机：失业申报可以领取失业救济金、获得再就业信息等 定期抽样调查估计失业人口 数据查找 中国国家统计局网站 http://www.stats.gov.cn 中国经济学教育科研网 http://www.cenet.org.cn/cn/ 美国 总统经济报告 www.access.gpo.gov/eop/ 美国统计概要 www.census.gov/compendia/statab 经济合作与发展组织 www.oecd.org 宾夕法尼亚大学国际比较中心 http://pwt.econ.upenn.edu/ 哈佛商学院宏观经济学资源网站 www.hbs.edu/units/bgie/internet","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]},{"title":"现代经济中的市场和政府","slug":"economics/现代经济中的市场和政府","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:51:22.818Z","comments":true,"path":"2017/01/21/economics/现代经济中的市场和政府/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/economics/现代经济中的市场和政府/","excerpt":"什么是市场 市场(market)是买者和卖者相互作用并共同决定商品和劳务的价格和交易数量的机制","text":"什么是市场 市场(market)是买者和卖者相互作用并共同决定商品和劳务的价格和交易数量的机制 在市场中，是价格在协调生产者和消费者的决策。较高的价格趋于抑制消费者购买，同时会刺激生产；而较低的价格则鼓励消费，同时抑制生产。价格(price)在市场机制中起着平衡的作用 市场不断地解决生产什么、如何生产和为谁生产的问题，当平衡了所有影响经济的力量时，市场就达到了供给和需求的市场均衡(market equilibrium of supply and demand)。 市场均衡代表了所有不同的买者和卖者之间的一种平衡。在某一价格水平上，买者所愿意购买的数量正好等于卖者所愿意出售的数量，这一价格就达成了供给和需求的均衡。 市场如何解决三大经济问题 生产什么商品和劳务取决于消费者的货币选票——每天的购买决策。企业会受到利润(profit，净收益，等于总销售额和总成本之间的差额)最大化愿望的驱使。 如何生产取决于不同生产者之间的竞争。生产者的最佳方法是采用效率最高的生产技术以将成本降到最低点。 为谁生产主要取决于生产要素市场上的供给与需求。要素市场决定了工资、地租、利息和利润的水平(要素价格)。收入在消费者之间的分配取决于他们所拥有的要素的数量和价格。 经济的核心控制者是偏好和技术。消费者根据自己先天或后天的偏好(并以其货币选票加以表达)解决社会资源的最终用途，即在生产可能性边界上的各个点之间作决定。 可供利用的资源和技术对消费者的选择构成了一种基本的约束，经济不能超越于它的生产可能性边界。经济资源与可供利用的科学技术加在一起，限定了消费者花钱消费的对象 追逐个人利益的结果，是经常地增进社会的利益，其效果要比真的想要增进社会的利益时更好。(“看不见的手”在引导)(亚当·斯密《国富论》) 在一定条件下，完全竞争经济是有效率的(经济效率指的是无法在不损害其他人经济福利的前提下增进某个人的经济福利) 市场不灵的一种情况是垄断以及其他形式的不完全竞争。 第二种不灵表现为市场的外溢效果或外部性：正面的外部性包括科学发现等，而负面的外溢效果应包括环境污染。 市场的收入分配的后果在政治上或道义上时无法接受的。 贸易、货币和资本 发达经济以细密的贸易网络(基于大量的专业化和精细的劳动分工)为特征 当今的经济都大量使用货币(支付手段) 现代工业技术依赖于大规模的资本运用: 精密的机器、大型的工厂和库存 贸易、专业化和劳动分工 专业化是指让个人或国家各自集中精力去完成某一种(或一系列)任务，使得每个人或国家都能够发挥其特殊技能和资源优势 发达经济致力于专业化和劳动分工，因而能提高其资源的生产率。个人和国家用自己专业化生产的物品自愿地交换其他人的产品，能极大地增加消费品的范围和数量，并提高每个人的生活水平。 货币(money)是一种支付手段或交换媒介，即购物时所支付的现金和支票。 货币是供应适度是各国宏观经济政策的主要任务之一。 资本(capital)，一种被生产出来的要素，一种本身就是由经济过程产出的耐用的投入品 三大生产要素：资本、土地和劳动。 基本生产要素：土地和劳动，其供给主要取决于非经济要素。 资本使用之前必须首先被生产出来。资本在本质上意味着时间的耗费和间接的生产手段。 靠牺牲当前消费而获得的增长 许多经济活动都涉及到放弃现时消费以增加资本，提高经济未来的生产率，进而增加未来的消费 资本和私有财产 在市场经济中资本主要归私人拥有，从投资中得到的收益也归个人所有 产权赋予资本使用者使用、交换、装修、挖掘、钻探等利用其资本品的权利 个人占有资本并能从中获取利润，是资本主义的实质之所在 最有价值的经济资源，即劳动，不能像私人财产那样成为可以买卖的商品。人不能自由地卖出自己，只能在某个工资价位上将自己租借出去 政府的经济职能 现实世界中还不曾有一种经济能够完全依照“看不见的手”的原则而顺利地运行 政府对市场经济主要行使三项职能：提高效率、增进公平以及促进宏观经济的稳定与增长 政府通过促进竞争、控制诸如污染这类外部性问题，以及提供公共品等活动来提高经济效率 政府通过财政税收和预算支出等手段，向某些团体进行有倾斜的收入再分配，从而增进公平 政府通过财政政策和货币政策促进宏观经济的稳定和增长，在鼓励经济增长的同时减少失业和降低通货膨胀 效率 只有在完全竞争成立时，市场机制的优点才能充分体现出来 完全竞争(perfect competition)指的是所有的物品和劳务都有一个价格并都在市场上交易。意味着没有一家企业或一位消费者足以影响整个市场的价格 不完全竞争(imperfect competition)，当买者或卖者能够左右一种商品的价格时；社会的产出将会从生产可能性边界上移至边界之内，物品的产出就会低于有效率的水平。 不完全竞争导致价格高于成本，消费者购买量低于效率水平。过高的价格和过低的产出是伴随不完全竞争而来的非效率的标志 不完全竞争的极端情况是垄断，唯一的卖者独自决定某种物品或劳务的价格水平 外部性(溢出效应) 外部性(externalities)指的是企业或个人向市场之外的其他人所强加的成本或效益 一个行动可能在市场交易之外有助于或有损于其他人的利益，也即存在着根本不发生经济支付的经济交易 负的外部性已逐渐由微小的麻烦变成巨大的威胁，是政府进行干预的地方。 公共品 正外部性的极端情况是公共品 公共品(public goods)指一类商品：将该商品的效用扩展与他人的成本为零(非相克性)；无法排除他人参与共享(非相斥性)。 税收：政府对个人和公司的收入、工资、消费品销售额和其他项目所征收的税款。政府的收入来源，以提供公共品和实施收入再分配计划 公平 市场并不必然能够带来公平的收入分配。市场经济可能会产生令人难以接受的收入水平和消费水平的巨大差异 收入取决于一系列因素，包括努力程度、教育、继承权、要素价格和运气；由此导致的收入分配可能会同公平的结果相悖 物品追随的是货币选票而不是最大满足 累进税 转移支付，帮助根本没有收入的人 宏观经济增长与稳定 资本主义自产生以来不时地受通货膨胀(价格上升)和萧条(高失业率)的周期性困扰。这些波动被称为商业周期。 通过审慎地运用财政和货币政策，政府能够影响产出、就业和通货膨胀的水平 政府的财政政策是税收权力和预算支出权力 货币政策涉及到货币供应量和利率水平， 进而影响到资本品的投资和其他利率敏感性的支出(影响利率和信贷条件)","categories":[],"tags":[{"name":"微观经济学","slug":"微观经济学","permalink":"https://chenfeng.github.io/tags/微观经济学/"}]},{"title":"经济学基础知识","slug":"economics/经济学基础知识","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:49:51.899Z","comments":true,"path":"2017/01/21/economics/经济学基础知识/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/economics/经济学基础知识/","excerpt":"研究一个社会如何利用稀缺资源生产有价值的物品和劳务并将它们在不同人中间进行分配。 物品和资源是稀缺的 社会必须有效地加以利用 稀缺(sarcity)：相对于需求，物品总是有限的 效率(efficiency)：最有效地使用社会资源以满足人类的愿望和需要","text":"研究一个社会如何利用稀缺资源生产有价值的物品和劳务并将它们在不同人中间进行分配。 物品和资源是稀缺的 社会必须有效地加以利用 稀缺(sarcity)：相对于需求，物品总是有限的 效率(efficiency)：最有效地使用社会资源以满足人类的愿望和需要 经济学逻辑 后此谬误(the post hoc fallacy)仅仅因为一件事发生在另一件事之前就想当然地认为前者是后者的原因 不能保持其他条件不变(failure to hold other things constant)考虑某一问题是没能保持其他相关条件不变 合成谬误(the fallacy of composition)认为对局部成立的东西对总体也必然成立 经济组织三个经济问题基本经济问题： 生产什么(什么商品和多少)； 如何生产； 为谁生产(谁享用经济活动的成果) 实证经济学(positive economics)：讨论经济社会的事实规范经济学(normative economics)：提出价值判断，涉及伦理信条(应当是什么) 市场经济(market economy):主要由个人和私人企业决定生产和消费的经济制度 极端情况：自由放任(lasse-faire)经济 指令经济(command economy):由政府做出有关生产和分配的所有重大决策 政府通过它的资源所有权和实施经济政策的权力解答基本的经济问题 混合经济(mixed economy):既带有市场经济的成分又带有指令经济的成分 社会的技术可能性 投入和产出投入(inputs):指生产物品和劳务的过程中所使用的物品和劳务 产出(outputs):指生产过程中创造的各种有用的物品和劳务，可用于消费或进一步生产 投入也称生产要素(factors of production)，划分成三大基本范畴 土地(自然资源)，生产过程中大自然所赋予的 劳动，人们花费在生产过程中的时间和精力 资本资源，一个经济体为了生产其他的物品而生产出来的耐用品 生产可能性边界(production-possibility frontier, PPF)表示在技术知识和可投入品数量既定的条件下，一个经济体所能得到的最大产量。 PPF代表可供社会利用的物品和劳务的不同组合。 生产可能性边界说明许多基本的经济过程： 经济增长将边界向外推移(生产潜能的增长) 贫穷的国家必须将其大部分资源用于生产食品；富裕的国家能生产出更多奢侈品 贫穷的国家仅仅能承担很少的公共品；随着经济增长公共品及环境质量占产出量的比重势必加大 通过牺牲现在消费和生产更多的资本品，一国经济能更快速增长使未来有可能生产出更多两种物品 机会成本(opportunity cost)在存在稀缺的社会上，选择一种东西意味着需要放弃其他一些东西；一项选择的机会成本是相应的所放弃的物品和劳务的价值。 效率 有效率的生产(productive efficiency)必然位于生产可能性边界上；经济体无法在不减少一种物品产量的前提下生产出更多的另一种产品。 生产可能性边界表示社会为人们提供的各种选择 未利用资源和无效率 经济体中存在着未利用的资源(失业的劳动者、闲置的工厂、废弃的土地等)时，不可能处于生产可能性边界上，而是处于其边界之内的某个位置。 无资源的根源：商业周期(周期性经济危机)、罢工、政治动乱、革命等。","categories":[],"tags":[{"name":"微观经济学","slug":"微观经济学","permalink":"https://chenfeng.github.io/tags/微观经济学/"}]},{"title":"模板（三）","slug":"Cplusplus_thinking/模板（三）","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:48:11.979Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/模板（三）/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/模板（三）/","excerpt":"迭代器 已经定义Array、Pointer和Ptr_to_const使得能部分确保安全性避免使用指针 进一步取代指针，需实现加法、减法和关系运算符 ‘’’C++void f() { int a[10]; int pa = a; int end = pa + 10; while (pa != end) *pa++ = 0;}‘’’ 基类及派生类都要定义这些操作","text":"迭代器 已经定义Array、Pointer和Ptr_to_const使得能部分确保安全性避免使用指针 进一步取代指针，需实现加法、减法和关系运算符 ‘’’C++void f() { int a[10]; int pa = a; int end = pa + 10; while (pa != end) *pa++ = 0;}‘’’ 基类及派生类都要定义这些操作 ‘’’C++template class Pointer: public Ptr_to_const {public: Pointer&amp; operator++() { ++sub; return *this; } Pointer&amp; operator--() { --sub; return *this; } Pointer&amp; operator++(int) { Pointer ret = *this; ++sub; return ret; } Pointer&amp; operator--(int) { Pointer ret = *this; --sub; return ret; } Pointer&amp; operator+=(int n) { sub += n; return *this; } Pointer&amp; operator-=(int n) { sub -= n; return *this; } // ... }; template Pointer operator+(const Pointer&amp; p, int n) { Pointer ret = p; return ret += n;} template Pointer operator+(int n, const Pointer&amp; p) { Pointer ret = p; return ret += n;} // subtration is similar‘’’ 两个指针当且仅当指向同一个Array的同一个元素(或都不指向任何Array)时才相等 ‘’’C++template int operator==(const Ptr_to_const&amp; op1, cosnt Ptr_to_const&amp; op2) { if (op1.ap != op2.ap) return 0; return (op1.sub == op2.sub);} template int operator&lt;(const Ptr_to_const&amp; op1, const Ptr_to_const&amp; op2) { if (op1.ap != op2.ap) throw “&lt; on different Arrays”; return op1.sub &lt; op2.sub;}‘’’ 迭代器能在不暴露容器内部结构的情况下访问容器的元素 删除元素 当元素不存在时的处理方法 禁止从容器中删除单个元素(可以删除整个容器) 在每个容器对象中保存一个有效迭代器的列表，删除一个元素则正好删除刚好指向这个被删除元素的迭代器 对容器中每个元素采用引用计数，删除任何一个元素都必须等到最后一个指向该元素的引用都不存在 让迭代器指向容器中元素与元素之间的位置上(难以实现；影响先有代码) 删除容器 容器本身已不存在，还有活动的迭代器的解决方法 删除操作延后到最后一个迭代器失效 采用处理删除单个元素的思想 用户确保一旦容器删除就不再使用迭代器 只要有活动迭代器存在就禁止删除容器本身","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"模板（二）","slug":"Cplusplus_thinking/模板（二）","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:46:20.301Z","comments":true,"path":"2017/01/21/Cplusplus_thinking/模板（二）/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/Cplusplus_thinking/模板（二）/","excerpt":"访问容器中的元素保留Array和一个指向T的指针之间的密切关系要付出一定的代价 用户能够轻易得到一个指向Array内部的指针，即使Array本身不存在了，这个指针仍被保留 不得不暴露类的内部机制，一旦内存变化肯定导致用户错误；resize之类的扩展有诸多潜在错误 增加防止出错的中间层","text":"访问容器中的元素保留Array和一个指向T的指针之间的密切关系要付出一定的代价 用户能够轻易得到一个指向Array内部的指针，即使Array本身不存在了，这个指针仍被保留 不得不暴露类的内部机制，一旦内存变化肯定导致用户错误；resize之类的扩展有诸多潜在错误 增加防止出错的中间层 模拟指针1234567891011template &lt;class T&gt; class Pointer &#123;public： Pointer(Array&lt;T&gt;&amp; a, unsigned n = 0): ap(&amp;a), sub(n) &#123;&#125; Pointer(): ap(0), sub(0) &#123;&#125; // Array&lt;T&gt; cann't be default: reference should bind a objectprivate: Array&lt;T&gt;* ap; unsigned sub; // ...&#125;; 复制一个Pointer之后，原Pointer和其副本都指向一个位置 获取元素 最直接的方法会面临上述问题： 12345678template &lt;class T&gt; class Pointer &#123;public: T&amp; operator*() const &#123; if (ap == 0) throw \"* of unbound Pointer\"; return (*ap)[sub]; &#125;&#125;; 另一种解决方案会带来赋值不方便的新问题： 123456789101112template &lt;class T&gt; class Pointer &#123;public: T operator*() const &#123; if (ap == 0) throw \"* of unbound Pointer\"; return (*ap)[sub]; &#125;&#125;;// \"t = *p\" is allowed but \"*p = t\" is forbidden// the point is that it is hard to implement \"*p = t\"// while \"T* tp = &amp;*p\" is allowed 引进update操作 12345678910111213141516171819202122template &lt;class T&gt; class Pointer &#123;public： Pointer(Array&lt;T&gt;&amp; a, unsigned n = 0): ap(&amp;a), sub(n) &#123;&#125; Pointer(): ap(0), sub(0) &#123;&#125; T operator*() const &#123; if (ap == 0) throw \"* of unbound Pointer\"; return (*ap)[sub]; &#125; void update(const T&amp; t) &#123; if (ap == 0) throw \"update of unbound Pointer\"; (*ap)[sub] = t; &#125;private: Array&lt;T&gt;* ap; unsigned sub; // ...&#125;; 相应地，Array类使用update操作，但会带来无法实现包含Array的Array的功能的问题 12345678910111213template &lt;class T&gt; class Array &#123;public: T operator[](unsigned n) const &#123; if (n &gt;= sz) throw \"Array suubscript out of range\"; return data[n]; &#125; void update(unsigned n, const T&amp; t) &#123; if (n &gt;= sz) throw \"Array subscript out of range\"; data[n] = t; &#125;&#125;; 方便性和安全性之间的权衡问题 选择何种方法取决于类会被确切地怎样使用 遗留问题 如果Array不存在了还可能存在一个指向它的空悬Pointer “软件工程基本定理”(though it isn’t a real theory): 通过引进一个额外的中间层能够解决任何问题。’ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091template &lt;class T&gt; class Array_data &#123; friend class Array&lt;T&gt;; friend class Pointer&lt;T&gt;; Array_data(unsigned size = 0): data(new T[size]), sz(size), use(1) &#123;&#125; ~Array_data() &#123; delete [] data; &#125; const T&amp; operator[](unsigned n) const &#123; if (n &gt;= sz) throw \"Array subscript out of range\"; return data[n]; &#125; T&amp; operator[](unsigned n) &#123; if (n &gt;= sz) throw \"Array subscript out of range\"; return data[n]; &#125; // no implement that copy is no allowed Array_data(const Array_data&amp;); Array_data&amp; operator=(const Array_data&amp;); T* data; unsigned sz; int use;&#125;;template &lt;class T&gt; class Array &#123; friend class Pointer&lt;T&gt;;public: Array(unsigned size): data(new Array_data&lt;T&gt;(size)) &#123;&#125; ~Array() &#123; if (--data-&gt;use == 0) delete data; &#125; const T&amp; operator[](unsigned n) const &#123; return (*data)[n]; &#125; T* operator[](unsigned n) &#123; return (*data)[n]; &#125;private: Array(const Array&amp;); Array&amp; operator=(const Array&amp;); Array_data&lt;T&gt;* data;&#125;;template &lt;class T&gt; class Poiter: public Ptr_to_const&lt;T&gt; &#123;public: Pointer(Array&lt;T&gt;&amp; a, unsigned n = 0): ap(a.data), sub(n) &#123; ++ap-&gt;use; &#125; Pointer(): ap(0), sub(0) &#123;&#125; Pointer(const Pointer&lt;T&gt;&amp; p): ap(p.ap), sub(p.sub) &#123; if (ap) ++ap-&gt;use; &#125; ~Pointer() &#123; if (ap &amp;&amp; --ap-&gt;use == 0) delete ap; &#125; Pointer&amp; operator=(const Pointer&lt;T&gt;&amp; p) &#123; if (p.ap) ++p.ap-&gt;use; if (ap &amp;&amp; --ap-&gt;use == 0) delete ap; ap = p.ap; sub = p.sub; return *this; &#125; T&amp; operator*() const &#123; if (ap == 0) throw \"* of unbound Ptr_to_const\"; return (*ap)[sub]; &#125;private: Array_data&lt;T&gt;* ap; unsigned sub;&#125;;// the following code does workArray&lt;int&gt;* ap = new Array&lt;int&gt;(10);Pointer&lt;int&gt; p(*ap, 5);delete ap;*p = 42; 指向const Array的Pointer 还无法使Pointer指向const Array的元素 const Array的实际对象很少，但通过引用传递Array参数(const Array&amp;)时还是有用的 定义独立的类，提供类型转换操作符给这个类，通过继承获得两种类型间的相似性 类Pointer从Ptr_to_const继承而来，即使对象不是const类型也能把指针保存在Array_data中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950template &lt;class T&gt; class Ptr_to_const &#123;public: // catch a argument const Array&lt;T&gt;&amp; instead of Array&lt;T&gt;&amp; Ptr_to_const(const Array&lt;T&gt;&amp; a, unsigned n = 0): ap(a.data), sub(n) &#123; ++ap-&gt;use; &#125; Ptr_to_const(): ap(0), sub(0) &#123;&#125; Ptr_to_const(const Ptr_to_const&lt;T&gt;&amp; p): ap(p.ap), sub(p.sub) &#123; if (ap) ++ap-&gt;use; &#125; ~Ptr_to_const() &#123; if (ap &amp;&amp; --ap-&gt;use == 0) delete ap; &#125; Ptr_to_const&amp; operator=(const Ptr_to_const&lt;T&gt;&amp; p) &#123; if (p.ap) ++p.ap-&gt;use; if (ap &amp;&amp; --ap-&gt;use == 0) delete ap; ap = p.ap; sub = p.sub; return *this; &#125; const T&amp; operator*() const &#123; if (ap == 0) throw \"* of unbound Ptr_to_const\"; return (*ap)[sub]; &#125;private: Array_data&lt;T&gt;* ap; unsigned sub;&#125;;// redefine class Pointer to keep something about constanttemplate &lt;class T&gt; class Poiter: public Ptr_to_const&lt;T&gt; &#123;public: Pointer(Array&lt;T&gt;&amp; a, unsigned n = 0): Ptr_to_const&lt;T&gt;(a, n) &#123;&#125; Pointer() &#123;&#125; T&amp; operator*() const &#123; if (ap == 0) throw \"* of unbound Ptr_to_const\"; return (*ap)[sub]; &#125;&#125;; 增强操作重新设置Array大小 1234567891011121314151617181920212223242526272829303132333435363738394041424344template &lt;class T&gt; class Array &#123;public: void resize(unsigned n) &#123; // Array_data do the real operation data-&gt;resize(n); &#125; //...&#125;;template &lt;class T&gt;void Array_data&lt;T&gt;::resize(unsigned n) &#123; if (n == sz) return ; T* odata = data; data = new T[n]; copy(odata, sz &gt; n ? n : sz); delete [] odata; sz = n;&#125;template &lt;class T&gt;void Array_data&lt;T&gt;::copy(T* arr, unsigned n) &#123; for (int i = 0; i &lt; n; ++i) data[i] = arr[i];&#125;// another way of changing Array sizetemplate &lt;class T&gt; class Array &#123;public: void reverse(unsigned new_sz) &#123; if (new_sz &gt;= data-&gt;sz) data-&gt;grow(new_sz); &#125; //...&#125;;template &lt;class T&gt;void Array_data&lt;T&gt;::grow(unsigned new_sz) &#123; unsigned nsz = sz; if (nsz == 0) nsz = 1; whiel (nsz &lt;= new_sz) nsz *= 2; resize(nsz);&#125; 实现对Array的复制和赋值使包含Array的Array有效 不允许对Array_data对象复制，故不定义operator=调用Array_data::operator= 1234567891011121314151617181920template &lt;class T&gt; class Array &#123;public: Array(const Array&amp; a): data(new Array_data&lt;T&gt;(a.data-&gt;sz)) &#123; data-&gt;copy(a.data-&gt;data, a.data-&gt;sz); &#125; Array&amp; operator=(const Array&amp; a) &#123; if (this != &amp;a) data-&gt;clone(*a.data, a.data-&gt;data); return *this; &#125; // ...&#125;;template &lt;class T&gt;void Array_data&lt;T&gt;::clone(const Array_data&amp; a, unsigned n) &#123; delete [] data; data = new T[sz = a.sz]; copy(a.data, sz);&#125; 尚未完全消除指针的需求","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://chenfeng.github.io/tags/C/"}]},{"title":"宏观经济学鸟瞰","slug":"economics/宏观经济学鸟瞰","date":"2017-01-20T16:00:00.000Z","updated":"2017-03-25T03:50:30.299Z","comments":true,"path":"2017/01/21/economics/宏观经济学鸟瞰/","link":"","permalink":"https://chenfeng.github.io/2017/01/21/economics/宏观经济学鸟瞰/","excerpt":"研究对象：整体经济行为 个体行为的总体成果 不是研究特定部门或特定经济活动主体的行为 经济生活中的重大问题 基本研究方法：考察经济的总体趋势 收集不同时期、不同国家有关收入、通货膨胀和失业等变量的数据，尝试构建有助于理解这些数据的一般理论 发展历程","text":"研究对象：整体经济行为 个体行为的总体成果 不是研究特定部门或特定经济活动主体的行为 经济生活中的重大问题 基本研究方法：考察经济的总体趋势 收集不同时期、不同国家有关收入、通货膨胀和失业等变量的数据，尝试构建有助于理解这些数据的一般理论 发展历程 凯恩斯革命 系统收集、处理总量数据，为宏观经济学的研究提供科学基础 对经济波动的系统研究 始于1929年的“大萧条” 凯恩斯《就业、利息和货币通论》(General Theory of Employment, Interest and Money) 有效需求：总需求(aggregate demand) 构成现代宏观经济学的要素 乘数，解释需求冲击如何被放大以及如何导致产出更大的变化 流动性偏好，凯恩斯对货币需求的称谓，解释货币政策如何影响利率和有效需求 预期在影响消费和投资方面的重要性，动物精神，即预期的变化是造成需求和产出变化的主要因素 凯恩斯主义的发展 新古典综合(neoclassical synthesis)：整合凯恩斯思想和古典思想 IS-LM模型 用数学语言对凯恩斯的观点进行表述 预期没有起到任何作用 缺少对价格和工资的调整 消费理论：持久收入在消费决策中具有重要作用 投资理论 货币需求理论：基于流动性、投资报酬率和风险发展不同资产之间的选择理论 凯恩斯主义和货币主义(争论) 货币政策和财政政策(的效果) 凯恩斯强调，治理经济衰退中财政政策优于货币政策，IS曲线非常陡峭，推论货币政策作用不大 弗里德曼、施瓦茨考察货币史发现货币政策非常有效，可以解释大多数产出波动 IS曲线并没有想象的那样陡峭，财政政策和货币政策都会产生效果 菲利普斯曲线 失业和通胀之间存在可靠的交替关系 失业和通胀之间并不存在长期的交替关系：违背基本的经济规律 宏观经济管理模式(的作用) 凯恩斯主义：政府在宏观经济管理上要相机决策；经济学知识可用以稳定经济，政策制定者能够做正确的事情 弗里德曼质疑政府的良好初衷未必能可信地做正确的事情，建议政府在宏观经济管理上采取固定法则 理性预期批判 危机(20世纪70年代) 经济生活中发生石油危机 滞涨(stagflation): 高失业和高通胀同时存在 石油危机是一次不利的供给冲击 一部分经济学家开始从理论上质疑凯恩斯主义 凯恩斯主义经济学在石油危机中所表现出的漏洞：忽略预期影响经济活动主体行为的全面含义 解决办法：人们基于目前所有的信息理性地做出预期 凯恩斯主义经济学遭到严重破坏(经济活动主体是理性的，其预期也是理性的) 卢卡斯批判(Lucas Critique) 如果政策发生变化，人们会基于新的政策形成预期，其行为也会发生变化，从而导致原先的宏观经济(计量)模型可能会对在新政策下将要发生的事情做出糟糕的指导。 如20世纪70年代初期的菲利普斯曲线 理性预期与菲利普斯曲线 凯恩斯模型中，由于价格和工资将沿着菲利普斯曲线缓慢调整，产出是缓慢而不是迅速调整到潜在产出水平。 卢卡斯：供给和价格的调整很大程度上取决于工资制定者对通胀的预期方式，一旦我们假定工资制定是理性预期的，调整可能快得多 最优控制与博弈论 凯恩斯主义采用的(宏观经济政策)分析工具，最优控制等，忽视了宏观经济政策制定者与经济活动主体之间的互动 理性预期的第三个含义：如果经济活动主体是理性预期的，那么政策通常是政策制定者与经济活动主体之间的博弈 采用博弈论研究宏观经济政策 理性预期的整合(20世纪70年代和80年代) 消费随机游走假说(Random-Walk Model of Consumption) 理性预期引入到消费研究领域：如果消费者是理性预期的且非常有远见，那么对于下一年消费的最好预测就是今天的消费 消费的变化难以预测：消费者只有得知有关将来的新信息后才会改变消费行为，但将来的新信息是不可预测的 工资与价格的交错调整(staggered price adjustment) 工资和价格的调整过程不会出现突然的同步调整，而是交错调整，可能是缓慢的 即使经济活动主体是理性预期的，产出也是缓慢调整到其潜在产出水平的 政府有效需求管理的有效性并不依赖于理性预期的假定，而是依赖于市场瞬时出清的假定 政策理论 博弈不仅存在于政策制定者和经济活动主体之间，也存在与政策制定者(政党、央行和中央政府，或不同国家政府)之间 当前发展 新古典主义，新凯恩斯主义，新增长理论 实际商业周期理论(real business cycle, RBC)：经济体的产出通常处于其潜在水平，因此所有波动都是源于潜在产出水平自身的变动，而不是源于对潜在产出水平的偏离。 RBC强调经济波动的根源是技术进步 新凯恩斯主义(New Keynesians) 以最大化行为和理性预期为基础构建严密可信的工资、价格粘性模型 研究方向主要集中在劳动力市场的工资决定、信用市场的不完全以及名义刚性(nominal rigidities) 由于工资和价格决策的交错，产出会偏离潜在水平很长一段时间； 菜单成本理论(menu cost): 即使改变价格的成本很小也会导致交错的价格调整，产生名义价格刚性 新经济增长理论(new growth theory) 经济体增长速度取决于技术进步速度，决定技术进步的因素 规模报酬递增在增长中的作用，有效地分析框架 微观经济学经济学家如何思考 经济学家最基本的工具：数据、术语、思考问题的方式；利用这些工具构建模型(model)，用数学术语清晰地说明变量之间的关系。 外生变量(exogenous variables)：模型中给定的变量 内生变量(endogenous variables)：模型要解释的变量 模型界定外生变量如何影响内生变量 供求模型某种商品的竞争性市场，市场需求曲线单调下降，市场供给曲线单调上升，交点为市场均衡点。 内生变量：对应价格为均衡价格，对应商品数量为均衡交易数量 外生变量：消费习惯、原材料来源、技术水平、政治法律等的变化，市场规模或居民收入水平变化等 需求膨胀：需求方购买商品的愿望和能力增强，商品的需求量在每个价格水平上都有所增加；需求曲线向右平移，会导致市场均衡点上升，均衡价格和均衡交易量同时上升 需求收缩：需求方购买商品的愿望和能力减弱，商品的需求量在每个价格水平上都有所下降；需求曲线向左平移，会导致市场均衡点下降，均衡价格和均衡交易量同时下降 供给膨胀：供给方出售商品的愿望增强，商品的供给量在每个价格水平上都有所增加;供给曲线向右平移，市场均衡点下降，均衡价格下降，均衡交易量上升 供给收缩：供给方出售商品的愿望减弱，商品的供给量在每个价格水平上都有所减少；供给曲线向左平移，市场均衡点上升，均衡价格上升，均衡交易量下降 从微观到宏观宏观经济理论必须与微观经济活动主体的基本行为一致 试图在理论水平上理解单个家庭和企业的决策过程 试图通过加总经济体中微观主体的所有决定来解释整体经济行为 通过手机分析数据，实证检验宏观经济学模型是否与现实一致 基本假定一种产品或服务的价格可以迅速调整；市场可以自动走向供求均衡，市场迅速出清 现实中存在工资和价格缓慢调整的情况，价格黏性 价格并不总是黏性的，最终会随着供求的变动而变动；这一假定可以描述经济体的长期趋势 基本模型 总需求(aggregate demand, AD)：在货币政策、财政政策以及消费者信心不变的情况下，每给定一个价格水平，产品市场和货币市场同时处于均衡状态时的产量水平 总需求函数(aggregate demand function)：Y = D(P)，经济体中价格水平P，总需求量Y 总需求曲线(aggregate deamnd curve) 其它条件不变(ceteris paribus)：除价格水平之外其它与经济体的总需求相关的条件都保持不变 总供给(aggregate supply)：在经济体中，对于每一既定价格水平，厂商愿意提供的产量 总供给函数(aggregate supply function)：Y = S(P) 长期总供给曲线是垂直的。其它条件发生变化(技术进步等)，生产能力提高时总供给曲线向右平移 在短期，价格是黏性的，总供给曲线是水平线 通常情况下，短期总供给曲线是向右上方倾斜","categories":[],"tags":[{"name":"宏观经济学","slug":"宏观经济学","permalink":"https://chenfeng.github.io/tags/宏观经济学/"}]}]